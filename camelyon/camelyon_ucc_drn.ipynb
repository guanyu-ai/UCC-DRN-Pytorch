{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fIQPGyJnOntm"
      },
      "outputs": [],
      "source": [
        "# using optimization to find the optimal mean and variance for normal initialization\n",
        "from copy import deepcopy\n",
        "from hydra import compose, initialize\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import mlflow\n",
        "import optuna\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from typing import Tuple\n",
        "from omegaconf.omegaconf import OmegaConf\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from model import UCCDRNModel\n",
        "from dataset import CamelyonDatasetSeparatedBin, CamelyonDataset\n",
        "from utils import get_or_create_experiment, parse_experiment_runs_to_optuna_study\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "cfg_name = \"train_camelyon_ucc_drn\"\n",
        "with initialize(version_base=None, config_path=\"../configs\"):\n",
        "    cfg = compose(config_name=cfg_name)\n",
        "x = np.arange(-0.5,0.6,0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1jkA63IFRubM"
      },
      "outputs": [],
      "source": [
        "def set_random_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def init_model_and_optimizer(args, model_cfg, device):\n",
        "    model = UCCDRNModel(model_cfg).to(device)\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(), lr=args.learning_rate)\n",
        "    return model, optimizer\n",
        "\n",
        "def load_model_and_optimizer(experiment_id, run_id):\n",
        "    model = torch.load(f\"mlruns/{experiment_id}/{run_id}/artifacts/best_model/data/model.pth\", weights=False)\n",
        "    optimizer = torch.load(f\"mlruns/{experiment_id}/{run_id}/artifacts/optimizer.pt\", weights=False)\n",
        "    return model, optimizer\n",
        "\n",
        "def init_dataloader(args):\n",
        "    train_dataset_len = args.train_num_steps * args.batch_size\n",
        "    train_dataset = CamelyonDataset(\n",
        "        mode=\"train\",\n",
        "        patch_size=args.patch_size,\n",
        "        num_instances=args.num_instances,\n",
        "        dataset_len = 200000*args.batch_size\n",
        "    )\n",
        "    val_dataset_len = args.val_num_steps * args.batch_size\n",
        "    val_dataset = CamelyonDataset(\n",
        "        mode=\"val\",\n",
        "        patch_size=args.patch_size,\n",
        "        num_instances=args.num_instances,\n",
        "    )\n",
        "    # create dataloader\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        num_workers=args.num_workers,\n",
        "        shuffle=True,\n",
        "    )\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=args.batch_size,\n",
        "        num_workers=args.num_workers,\n",
        "        shuffle=False,\n",
        "    )\n",
        "    return train_loader, val_loader\n",
        "\n",
        "def evaluate(model, val_loader, device):\n",
        "    model.eval()\n",
        "    val_ae_loss_list = []\n",
        "    val_ucc_loss_list = []\n",
        "    val_acc_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch_samples, batch_labels in val_loader:\n",
        "            batch_samples = batch_samples.to(device)\n",
        "            batch_labels = batch_labels.to(device)\n",
        "\n",
        "            ucc_logits, reconstruction = model(batch_samples, return_reconstruction=True)\n",
        "\n",
        "            ucc_loss = F.cross_entropy(ucc_logits, batch_labels)\n",
        "            val_ucc_loss_list.append(ucc_loss.item())\n",
        "\n",
        "            ae_loss = F.mse_loss(batch_samples, reconstruction)\n",
        "            val_ae_loss_list.append(ae_loss.item())\n",
        "\n",
        "            # acculate accuracy\n",
        "            # _, batch_labels = torch.max(batch_labels, dim=1)\n",
        "            \n",
        "            _, ucc_predicts = torch.max(ucc_logits, dim=1)\n",
        "            acc = torch.sum(ucc_predicts == batch_labels).item() / len(batch_labels)\n",
        "            val_acc_list.append(acc)\n",
        "    return {\n",
        "                \"eval_ae_loss\": np.round(np.mean(val_ae_loss_list), 5),\n",
        "                \"eval_ucc_loss\": np.round(np.mean(val_ucc_loss_list), 5),\n",
        "                \"eval_ucc_acc\": np.round(np.mean(val_acc_list), 5)\n",
        "            }\n",
        "\n",
        "def train(args, model, optimizer, lr_scheduler, train_loader, val_loader, device, step=0):\n",
        "    print(\"training\")\n",
        "    # mlflow.pytorch.log_model(model, \"init_model\")\n",
        "    # output_dir = hydra.core.hydra_config.HydraConfig.get().runtime.output_dir\n",
        "\n",
        "    model.train()\n",
        "    best_eval_acc = 0\n",
        "    if step == 0:\n",
        "        mlflow.pytorch.log_model(\n",
        "            model,\n",
        "            artifact_path = \"best_model\"\n",
        "        )\n",
        "    for batch_samples, batch_labels in train_loader:\n",
        "        batch_samples = batch_samples.to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        ucc_logits, reconstruction = model(batch_samples, return_reconstruction=True)\n",
        "        ucc_loss = F.cross_entropy(ucc_logits, batch_labels)\n",
        "        ae_loss = F.mse_loss(batch_samples, reconstruction)\n",
        "        loss = (1-model.alpha)*ucc_loss + model.alpha*ae_loss\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        step += 1\n",
        "\n",
        "        if step%20 ==0:\n",
        "            with torch.no_grad():\n",
        "                metric_dict = {}\n",
        "                grad_log = {name: torch.mean(param.grad).cpu().item(\n",
        "                ) for name, param in model.named_parameters() if isinstance(param.grad, torch.Tensor)}\n",
        "                if step == 20:\n",
        "                    encoder_grad_log = [grad for name, grad in grad_log.items() if \"encoder\" in name and \"weight\" in name]\n",
        "                    if max(encoder_grad_log)<1e-9:\n",
        "                        break\n",
        "                mlflow.log_metrics(grad_log, step=step)\n",
        "                metric_dict[\"train_ae_loss\"] = np.round(ae_loss.detach().item(), 5)\n",
        "                _, pred = torch.max(ucc_logits, dim=1)\n",
        "                accuracy = torch.sum(pred.flatten() == batch_labels.flatten())/len(batch_labels)\n",
        "                metric_dict[\"train_ucc_loss\"] = np.round(ucc_loss.detach().item(), 5)\n",
        "                metric_dict[\"train_ucc_acc\"] = np.round(float(accuracy), 5)\n",
        "                metric_dict[\"loss\"] = np.round(float(loss), 5)\n",
        "                print(f\"Step {step}:\", metric_dict)\n",
        "            mlflow.log_metrics(metric_dict, step=step)\n",
        "\n",
        "        if step % args.save_interval == 0:\n",
        "            eval_metric_dict = evaluate(\n",
        "                model,\n",
        "                val_loader,\n",
        "                device)\n",
        "            print(f\"step: {step},\" + \",\".join([f\"{key}: {value}\"for key, value in eval_metric_dict.items()]))\n",
        "            mlflow.log_metrics(eval_metric_dict, step=step)\n",
        "            eval_acc = eval_metric_dict[\"eval_ucc_acc\"]\n",
        "            if eval_acc > best_eval_acc or eval_acc==1.0:\n",
        "                best_eval_acc = eval_acc\n",
        "                mlflow.log_metric(\"best_eval_acc\", best_eval_acc)\n",
        "                mlflow.pytorch.log_model(model, artifact_path=\"best_model\")\n",
        "                torch.save(optimizer, \"optimizer.pt\")\n",
        "                mlflow.log_artifact(\"optimizer.pt\")\n",
        "            if step == 200000:\n",
        "                break\n",
        "            model.train()\n",
        "\n",
        "    print(\"Training finished!!!\")\n",
        "    return best_eval_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2X5JTgp3qCLF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'num_bins': 11, 'hidden_q': 100, 'num_layers': 1, 'num_nodes': 12, 'init_method': 'uniform', 'init_upper_bound': -0.4, 'init_lower_bound': -0.5, 'output_bins': 2}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/02 14:55:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/02 14:55:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished!!!\n",
            "{'num_bins': 11, 'hidden_q': 100, 'num_layers': 1, 'num_nodes': 12, 'init_method': 'uniform', 'init_upper_bound': -0.30000000000000004, 'init_lower_bound': -0.5, 'output_bins': 2}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/02 14:56:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/02 14:56:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finished!!!\n",
            "{'num_bins': 11, 'hidden_q': 100, 'num_layers': 1, 'num_nodes': 12, 'init_method': 'uniform', 'init_upper_bound': -0.20000000000000007, 'init_lower_bound': -0.5, 'output_bins': 2}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/02 14:57:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/02 14:57:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 20: {'train_ae_loss': np.float64(1.00029), 'train_ucc_loss': np.float64(0.73202), 'train_ucc_acc': np.float64(0.375), 'loss': np.float64(0.86615)}\n",
            "Step 40: {'train_ae_loss': np.float64(1.0001), 'train_ucc_loss': np.float64(0.69207), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.84608)}\n",
            "Step 60: {'train_ae_loss': np.float64(0.9998), 'train_ucc_loss': np.float64(0.7093), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.85455)}\n",
            "Step 80: {'train_ae_loss': np.float64(1.00302), 'train_ucc_loss': np.float64(0.707), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.85501)}\n",
            "Step 100: {'train_ae_loss': np.float64(0.97623), 'train_ucc_loss': np.float64(0.71442), 'train_ucc_acc': np.float64(0.375), 'loss': np.float64(0.84532)}\n",
            "Step 120: {'train_ae_loss': np.float64(0.93069), 'train_ucc_loss': np.float64(0.71237), 'train_ucc_acc': np.float64(0.375), 'loss': np.float64(0.82153)}\n",
            "Step 140: {'train_ae_loss': np.float64(0.85447), 'train_ucc_loss': np.float64(0.69128), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.77288)}\n",
            "Step 160: {'train_ae_loss': np.float64(0.82857), 'train_ucc_loss': np.float64(0.69106), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.75982)}\n",
            "Step 180: {'train_ae_loss': np.float64(0.79483), 'train_ucc_loss': np.float64(0.69117), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.743)}\n",
            "Step 200: {'train_ae_loss': np.float64(0.79216), 'train_ucc_loss': np.float64(0.70191), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.74704)}\n",
            "Step 220: {'train_ae_loss': np.float64(0.78204), 'train_ucc_loss': np.float64(0.69135), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.73669)}\n",
            "Step 240: {'train_ae_loss': np.float64(0.79365), 'train_ucc_loss': np.float64(0.68522), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.73943)}\n",
            "Step 260: {'train_ae_loss': np.float64(0.79817), 'train_ucc_loss': np.float64(0.70248), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.75033)}\n",
            "Step 280: {'train_ae_loss': np.float64(0.78896), 'train_ucc_loss': np.float64(0.7013), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.74513)}\n",
            "Step 300: {'train_ae_loss': np.float64(0.80815), 'train_ucc_loss': np.float64(0.69688), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.75252)}\n",
            "Step 320: {'train_ae_loss': np.float64(0.76448), 'train_ucc_loss': np.float64(0.70033), 'train_ucc_acc': np.float64(0.375), 'loss': np.float64(0.73241)}\n",
            "Step 340: {'train_ae_loss': np.float64(0.77113), 'train_ucc_loss': np.float64(0.68682), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.72898)}\n",
            "Step 360: {'train_ae_loss': np.float64(0.76463), 'train_ucc_loss': np.float64(0.695), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.72982)}\n",
            "Step 380: {'train_ae_loss': np.float64(0.77004), 'train_ucc_loss': np.float64(0.68233), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.72619)}\n",
            "Step 400: {'train_ae_loss': np.float64(0.76048), 'train_ucc_loss': np.float64(0.6951), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.72779)}\n",
            "Step 420: {'train_ae_loss': np.float64(0.78966), 'train_ucc_loss': np.float64(0.69933), 'train_ucc_acc': np.float64(0.375), 'loss': np.float64(0.74449)}\n",
            "Step 440: {'train_ae_loss': np.float64(0.7894), 'train_ucc_loss': np.float64(0.69344), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.74142)}\n",
            "Step 460: {'train_ae_loss': np.float64(0.77428), 'train_ucc_loss': np.float64(0.69223), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.73325)}\n",
            "Step 480: {'train_ae_loss': np.float64(0.77026), 'train_ucc_loss': np.float64(0.69494), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.7326)}\n",
            "Step 500: {'train_ae_loss': np.float64(0.77568), 'train_ucc_loss': np.float64(0.70422), 'train_ucc_acc': np.float64(0.25), 'loss': np.float64(0.73995)}\n",
            "Step 520: {'train_ae_loss': np.float64(0.77881), 'train_ucc_loss': np.float64(0.69336), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.73608)}\n",
            "Step 540: {'train_ae_loss': np.float64(0.76589), 'train_ucc_loss': np.float64(0.68946), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.72767)}\n",
            "Step 560: {'train_ae_loss': np.float64(0.77646), 'train_ucc_loss': np.float64(0.69174), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.7341)}\n",
            "Step 580: {'train_ae_loss': np.float64(0.7986), 'train_ucc_loss': np.float64(0.69466), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.74663)}\n",
            "Step 600: {'train_ae_loss': np.float64(0.78602), 'train_ucc_loss': np.float64(0.69352), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.73977)}\n",
            "Step 620: {'train_ae_loss': np.float64(0.78455), 'train_ucc_loss': np.float64(0.69195), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.73825)}\n",
            "Step 640: {'train_ae_loss': np.float64(0.77376), 'train_ucc_loss': np.float64(0.68925), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.73151)}\n",
            "Step 660: {'train_ae_loss': np.float64(0.77692), 'train_ucc_loss': np.float64(0.69817), 'train_ucc_acc': np.float64(0.375), 'loss': np.float64(0.73754)}\n",
            "Step 680: {'train_ae_loss': np.float64(0.76646), 'train_ucc_loss': np.float64(0.69421), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.73034)}\n",
            "Step 700: {'train_ae_loss': np.float64(0.78286), 'train_ucc_loss': np.float64(0.69778), 'train_ucc_acc': np.float64(0.28125), 'loss': np.float64(0.74032)}\n",
            "Step 720: {'train_ae_loss': np.float64(0.77545), 'train_ucc_loss': np.float64(0.69285), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.73415)}\n",
            "Step 740: {'train_ae_loss': np.float64(0.7818), 'train_ucc_loss': np.float64(0.69355), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.73768)}\n",
            "Step 760: {'train_ae_loss': np.float64(0.76183), 'train_ucc_loss': np.float64(0.69234), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.72709)}\n",
            "Step 780: {'train_ae_loss': np.float64(0.77163), 'train_ucc_loss': np.float64(0.69343), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.73253)}\n",
            "Step 800: {'train_ae_loss': np.float64(0.77058), 'train_ucc_loss': np.float64(0.69305), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.73181)}\n",
            "Step 820: {'train_ae_loss': np.float64(0.77798), 'train_ucc_loss': np.float64(0.69315), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.73557)}\n",
            "Step 840: {'train_ae_loss': np.float64(0.7762), 'train_ucc_loss': np.float64(0.69334), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.73477)}\n",
            "Step 860: {'train_ae_loss': np.float64(0.78452), 'train_ucc_loss': np.float64(0.69251), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.73852)}\n",
            "Step 880: {'train_ae_loss': np.float64(0.78333), 'train_ucc_loss': np.float64(0.69258), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.73796)}\n",
            "Step 900: {'train_ae_loss': np.float64(0.78765), 'train_ucc_loss': np.float64(0.6942), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.74093)}\n",
            "Step 920: {'train_ae_loss': np.float64(0.77859), 'train_ucc_loss': np.float64(0.69338), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.73599)}\n",
            "Step 940: {'train_ae_loss': np.float64(0.75589), 'train_ucc_loss': np.float64(0.69202), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.72395)}\n",
            "Step 960: {'train_ae_loss': np.float64(0.77158), 'train_ucc_loss': np.float64(0.692), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.73179)}\n",
            "Step 980: {'train_ae_loss': np.float64(0.76419), 'train_ucc_loss': np.float64(0.69311), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.72865)}\n",
            "Step 1000: {'train_ae_loss': np.float64(0.76255), 'train_ucc_loss': np.float64(0.69313), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.72784)}\n",
            "step: 1000,eval_ae_loss: 0.77426,eval_ucc_loss: 0.69316,eval_ucc_acc: 0.49902\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/02 15:20:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 1020: {'train_ae_loss': np.float64(0.78434), 'train_ucc_loss': np.float64(0.69361), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.73898)}\n",
            "Step 1040: {'train_ae_loss': np.float64(0.76507), 'train_ucc_loss': np.float64(0.69307), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.72907)}\n",
            "Step 1060: {'train_ae_loss': np.float64(0.77669), 'train_ucc_loss': np.float64(0.69277), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.73473)}\n",
            "Step 1080: {'train_ae_loss': np.float64(0.75577), 'train_ucc_loss': np.float64(0.69287), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.72432)}\n",
            "Step 1100: {'train_ae_loss': np.float64(0.78665), 'train_ucc_loss': np.float64(0.69165), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.73915)}\n",
            "Step 1120: {'train_ae_loss': np.float64(0.80385), 'train_ucc_loss': np.float64(0.69486), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.74935)}\n",
            "Step 1140: {'train_ae_loss': np.float64(0.76778), 'train_ucc_loss': np.float64(0.69271), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.73024)}\n",
            "Step 1160: {'train_ae_loss': np.float64(0.76228), 'train_ucc_loss': np.float64(0.69142), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.72685)}\n",
            "Step 1180: {'train_ae_loss': np.float64(0.77386), 'train_ucc_loss': np.float64(0.69585), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.73486)}\n",
            "Step 1200: {'train_ae_loss': np.float64(0.77174), 'train_ucc_loss': np.float64(0.68926), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.7305)}\n",
            "Step 1220: {'train_ae_loss': np.float64(0.78101), 'train_ucc_loss': np.float64(0.68954), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.73528)}\n",
            "Step 1240: {'train_ae_loss': np.float64(0.77782), 'train_ucc_loss': np.float64(0.69407), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.73594)}\n",
            "Step 1260: {'train_ae_loss': np.float64(0.76425), 'train_ucc_loss': np.float64(0.69306), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.72866)}\n",
            "Step 1280: {'train_ae_loss': np.float64(0.76418), 'train_ucc_loss': np.float64(0.69168), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.72793)}\n",
            "Step 1300: {'train_ae_loss': np.float64(0.78822), 'train_ucc_loss': np.float64(0.69325), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.74073)}\n",
            "Step 1320: {'train_ae_loss': np.float64(0.76137), 'train_ucc_loss': np.float64(0.69254), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.72695)}\n",
            "Step 1340: {'train_ae_loss': np.float64(0.75773), 'train_ucc_loss': np.float64(0.69337), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.72555)}\n",
            "Step 1360: {'train_ae_loss': np.float64(0.78396), 'train_ucc_loss': np.float64(0.69414), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.73905)}\n",
            "Step 1380: {'train_ae_loss': np.float64(0.77499), 'train_ucc_loss': np.float64(0.69356), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.73428)}\n",
            "Step 1400: {'train_ae_loss': np.float64(0.77744), 'train_ucc_loss': np.float64(0.69334), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.73539)}\n",
            "Step 1420: {'train_ae_loss': np.float64(0.76295), 'train_ucc_loss': np.float64(0.69284), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.72789)}\n",
            "Step 1440: {'train_ae_loss': np.float64(0.77817), 'train_ucc_loss': np.float64(0.6929), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.73553)}\n",
            "Step 1460: {'train_ae_loss': np.float64(0.76445), 'train_ucc_loss': np.float64(0.69328), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.72887)}\n",
            "Step 1480: {'train_ae_loss': np.float64(0.74095), 'train_ucc_loss': np.float64(0.69489), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.71792)}\n",
            "Step 1500: {'train_ae_loss': np.float64(0.79251), 'train_ucc_loss': np.float64(0.69317), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.74284)}\n",
            "Step 1520: {'train_ae_loss': np.float64(0.77939), 'train_ucc_loss': np.float64(0.69407), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.73673)}\n",
            "Step 1540: {'train_ae_loss': np.float64(0.76556), 'train_ucc_loss': np.float64(0.69247), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.72902)}\n",
            "Step 1560: {'train_ae_loss': np.float64(0.76816), 'train_ucc_loss': np.float64(0.6941), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.73113)}\n",
            "Step 1580: {'train_ae_loss': np.float64(0.78707), 'train_ucc_loss': np.float64(0.69412), 'train_ucc_acc': np.float64(0.375), 'loss': np.float64(0.74059)}\n",
            "Step 1600: {'train_ae_loss': np.float64(0.78087), 'train_ucc_loss': np.float64(0.69291), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.73689)}\n",
            "Step 1620: {'train_ae_loss': np.float64(0.76354), 'train_ucc_loss': np.float64(0.69325), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.7284)}\n",
            "Step 1640: {'train_ae_loss': np.float64(0.77731), 'train_ucc_loss': np.float64(0.69113), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.73422)}\n",
            "Step 1660: {'train_ae_loss': np.float64(0.80637), 'train_ucc_loss': np.float64(0.69113), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.74875)}\n",
            "Step 1680: {'train_ae_loss': np.float64(0.76126), 'train_ucc_loss': np.float64(0.69213), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.7267)}\n",
            "Step 1700: {'train_ae_loss': np.float64(0.7539), 'train_ucc_loss': np.float64(0.69391), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.72391)}\n",
            "Step 1720: {'train_ae_loss': np.float64(0.78113), 'train_ucc_loss': np.float64(0.69308), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.73711)}\n",
            "Step 1740: {'train_ae_loss': np.float64(0.78026), 'train_ucc_loss': np.float64(0.69253), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.73639)}\n",
            "Step 1760: {'train_ae_loss': np.float64(0.7585), 'train_ucc_loss': np.float64(0.69262), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.72556)}\n",
            "Step 1780: {'train_ae_loss': np.float64(0.78467), 'train_ucc_loss': np.float64(0.69418), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.73942)}\n",
            "Step 1800: {'train_ae_loss': np.float64(0.75937), 'train_ucc_loss': np.float64(0.69216), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72576)}\n",
            "Step 1820: {'train_ae_loss': np.float64(0.78933), 'train_ucc_loss': np.float64(0.69241), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.74087)}\n",
            "Step 1840: {'train_ae_loss': np.float64(0.77779), 'train_ucc_loss': np.float64(0.69261), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.7352)}\n",
            "Step 1860: {'train_ae_loss': np.float64(0.76567), 'train_ucc_loss': np.float64(0.69205), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.72886)}\n",
            "Step 1880: {'train_ae_loss': np.float64(0.7535), 'train_ucc_loss': np.float64(0.69354), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.72352)}\n",
            "Step 1900: {'train_ae_loss': np.float64(0.76657), 'train_ucc_loss': np.float64(0.69311), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72984)}\n",
            "Step 1920: {'train_ae_loss': np.float64(0.77617), 'train_ucc_loss': np.float64(0.69306), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.73461)}\n",
            "Step 1940: {'train_ae_loss': np.float64(0.75404), 'train_ucc_loss': np.float64(0.69281), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72342)}\n",
            "Step 1960: {'train_ae_loss': np.float64(0.77928), 'train_ucc_loss': np.float64(0.6923), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.73579)}\n",
            "Step 1980: {'train_ae_loss': np.float64(0.75639), 'train_ucc_loss': np.float64(0.6942), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.72529)}\n",
            "Step 2000: {'train_ae_loss': np.float64(0.77526), 'train_ucc_loss': np.float64(0.69304), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.73415)}\n",
            "step: 2000,eval_ae_loss: 0.75135,eval_ucc_loss: 0.69322,eval_ucc_acc: 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/02 15:43:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 2020: {'train_ae_loss': np.float64(0.75705), 'train_ucc_loss': np.float64(0.69247), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72476)}\n",
            "Step 2040: {'train_ae_loss': np.float64(0.76287), 'train_ucc_loss': np.float64(0.69295), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.72791)}\n",
            "Step 2060: {'train_ae_loss': np.float64(0.75292), 'train_ucc_loss': np.float64(0.6936), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.72326)}\n",
            "Step 2080: {'train_ae_loss': np.float64(0.78882), 'train_ucc_loss': np.float64(0.69078), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.7398)}\n",
            "Step 2100: {'train_ae_loss': np.float64(0.79082), 'train_ucc_loss': np.float64(0.6989), 'train_ucc_acc': np.float64(0.28125), 'loss': np.float64(0.74486)}\n",
            "Step 2120: {'train_ae_loss': np.float64(0.73962), 'train_ucc_loss': np.float64(0.6909), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.71526)}\n",
            "Step 2140: {'train_ae_loss': np.float64(0.77086), 'train_ucc_loss': np.float64(0.69398), 'train_ucc_acc': np.float64(0.34375), 'loss': np.float64(0.73242)}\n",
            "Step 2160: {'train_ae_loss': np.float64(0.78629), 'train_ucc_loss': np.float64(0.69074), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.73852)}\n",
            "Step 2180: {'train_ae_loss': np.float64(0.77073), 'train_ucc_loss': np.float64(0.69598), 'train_ucc_acc': np.float64(0.375), 'loss': np.float64(0.73336)}\n",
            "Step 2200: {'train_ae_loss': np.float64(0.77094), 'train_ucc_loss': np.float64(0.69203), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.73149)}\n",
            "Step 2220: {'train_ae_loss': np.float64(0.75926), 'train_ucc_loss': np.float64(0.69406), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.72666)}\n",
            "Step 2240: {'train_ae_loss': np.float64(0.77183), 'train_ucc_loss': np.float64(0.69604), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.73394)}\n",
            "Step 2260: {'train_ae_loss': np.float64(0.77637), 'train_ucc_loss': np.float64(0.69244), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.7344)}\n",
            "Step 2280: {'train_ae_loss': np.float64(0.75847), 'train_ucc_loss': np.float64(0.6902), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.72433)}\n",
            "Step 2300: {'train_ae_loss': np.float64(0.76429), 'train_ucc_loss': np.float64(0.69304), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.72867)}\n",
            "Step 2320: {'train_ae_loss': np.float64(0.74203), 'train_ucc_loss': np.float64(0.69155), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.71679)}\n",
            "Step 2340: {'train_ae_loss': np.float64(0.76198), 'train_ucc_loss': np.float64(0.69304), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.72751)}\n",
            "Step 2360: {'train_ae_loss': np.float64(0.77948), 'train_ucc_loss': np.float64(0.69325), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.73637)}\n",
            "Step 2380: {'train_ae_loss': np.float64(0.78178), 'train_ucc_loss': np.float64(0.69323), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.73751)}\n",
            "Step 2400: {'train_ae_loss': np.float64(0.76895), 'train_ucc_loss': np.float64(0.68866), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.72881)}\n",
            "Step 2420: {'train_ae_loss': np.float64(0.76266), 'train_ucc_loss': np.float64(0.69069), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.72667)}\n",
            "Step 2440: {'train_ae_loss': np.float64(0.77797), 'train_ucc_loss': np.float64(0.69196), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.73496)}\n",
            "Step 2460: {'train_ae_loss': np.float64(0.79775), 'train_ucc_loss': np.float64(0.68848), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.74311)}\n",
            "Step 2480: {'train_ae_loss': np.float64(0.76325), 'train_ucc_loss': np.float64(0.69202), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72764)}\n",
            "Step 2500: {'train_ae_loss': np.float64(0.78437), 'train_ucc_loss': np.float64(0.69446), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.73941)}\n",
            "Step 2520: {'train_ae_loss': np.float64(0.77736), 'train_ucc_loss': np.float64(0.69376), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.73556)}\n",
            "Step 2540: {'train_ae_loss': np.float64(0.78187), 'train_ucc_loss': np.float64(0.69481), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.73834)}\n",
            "Step 2560: {'train_ae_loss': np.float64(0.78321), 'train_ucc_loss': np.float64(0.69232), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.73777)}\n",
            "Step 2580: {'train_ae_loss': np.float64(0.79157), 'train_ucc_loss': np.float64(0.69336), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.74246)}\n",
            "Step 2600: {'train_ae_loss': np.float64(0.77446), 'train_ucc_loss': np.float64(0.69073), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.7326)}\n",
            "Step 2620: {'train_ae_loss': np.float64(0.78411), 'train_ucc_loss': np.float64(0.69307), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.73859)}\n",
            "Step 2640: {'train_ae_loss': np.float64(0.76676), 'train_ucc_loss': np.float64(0.69272), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72974)}\n",
            "Step 2660: {'train_ae_loss': np.float64(0.7833), 'train_ucc_loss': np.float64(0.69372), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.73851)}\n",
            "Step 2680: {'train_ae_loss': np.float64(0.7729), 'train_ucc_loss': np.float64(0.69284), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.73287)}\n",
            "Step 2700: {'train_ae_loss': np.float64(0.76158), 'train_ucc_loss': np.float64(0.69449), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.72804)}\n",
            "Step 2720: {'train_ae_loss': np.float64(0.77837), 'train_ucc_loss': np.float64(0.69357), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.73597)}\n",
            "Step 2740: {'train_ae_loss': np.float64(0.77142), 'train_ucc_loss': np.float64(0.68832), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.72987)}\n",
            "Step 2760: {'train_ae_loss': np.float64(0.74998), 'train_ucc_loss': np.float64(0.69239), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72119)}\n",
            "Step 2780: {'train_ae_loss': np.float64(0.76614), 'train_ucc_loss': np.float64(0.69462), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.73038)}\n",
            "Step 2800: {'train_ae_loss': np.float64(0.77966), 'train_ucc_loss': np.float64(0.6933), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.73648)}\n",
            "Step 2820: {'train_ae_loss': np.float64(0.76739), 'train_ucc_loss': np.float64(0.69354), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.73046)}\n",
            "Step 2840: {'train_ae_loss': np.float64(0.78079), 'train_ucc_loss': np.float64(0.6924), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.73659)}\n",
            "Step 2860: {'train_ae_loss': np.float64(0.77899), 'train_ucc_loss': np.float64(0.68572), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.73236)}\n",
            "Step 2880: {'train_ae_loss': np.float64(0.77193), 'train_ucc_loss': np.float64(0.69233), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.73213)}\n",
            "Step 2900: {'train_ae_loss': np.float64(0.7655), 'train_ucc_loss': np.float64(0.68823), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.72686)}\n",
            "Step 2920: {'train_ae_loss': np.float64(0.77137), 'train_ucc_loss': np.float64(0.68942), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.7304)}\n",
            "Step 2940: {'train_ae_loss': np.float64(0.7838), 'train_ucc_loss': np.float64(0.68997), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.73689)}\n",
            "Step 2960: {'train_ae_loss': np.float64(0.77752), 'train_ucc_loss': np.float64(0.69587), 'train_ucc_acc': np.float64(0.375), 'loss': np.float64(0.73669)}\n",
            "Step 2980: {'train_ae_loss': np.float64(0.74772), 'train_ucc_loss': np.float64(0.68865), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.71818)}\n",
            "Step 3000: {'train_ae_loss': np.float64(0.75901), 'train_ucc_loss': np.float64(0.69643), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.72772)}\n",
            "step: 3000,eval_ae_loss: 0.74967,eval_ucc_loss: 0.69326,eval_ucc_acc: 0.5\n",
            "Step 3020: {'train_ae_loss': np.float64(0.76483), 'train_ucc_loss': np.float64(0.69308), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.72895)}\n",
            "Step 3040: {'train_ae_loss': np.float64(0.75724), 'train_ucc_loss': np.float64(0.69421), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.72573)}\n",
            "Step 3060: {'train_ae_loss': np.float64(0.76029), 'train_ucc_loss': np.float64(0.69348), 'train_ucc_acc': np.float64(0.375), 'loss': np.float64(0.72688)}\n",
            "Step 3080: {'train_ae_loss': np.float64(0.76225), 'train_ucc_loss': np.float64(0.69248), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72737)}\n",
            "Step 3100: {'train_ae_loss': np.float64(0.76763), 'train_ucc_loss': np.float64(0.69304), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.73034)}\n",
            "Step 3120: {'train_ae_loss': np.float64(0.75927), 'train_ucc_loss': np.float64(0.69353), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.7264)}\n",
            "Step 3140: {'train_ae_loss': np.float64(0.76759), 'train_ucc_loss': np.float64(0.6931), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.73035)}\n",
            "Step 3160: {'train_ae_loss': np.float64(0.76357), 'train_ucc_loss': np.float64(0.69431), 'train_ucc_acc': np.float64(0.34375), 'loss': np.float64(0.72894)}\n",
            "Step 3180: {'train_ae_loss': np.float64(0.77185), 'train_ucc_loss': np.float64(0.69192), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.73189)}\n",
            "Step 3200: {'train_ae_loss': np.float64(0.75864), 'train_ucc_loss': np.float64(0.69274), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72569)}\n",
            "Step 3220: {'train_ae_loss': np.float64(0.76012), 'train_ucc_loss': np.float64(0.69236), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.72624)}\n",
            "Step 3240: {'train_ae_loss': np.float64(0.75537), 'train_ucc_loss': np.float64(0.69322), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.7243)}\n",
            "Step 3260: {'train_ae_loss': np.float64(0.77124), 'train_ucc_loss': np.float64(0.6921), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.73167)}\n",
            "Step 3280: {'train_ae_loss': np.float64(0.76406), 'train_ucc_loss': np.float64(0.69433), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.72919)}\n",
            "Step 3300: {'train_ae_loss': np.float64(0.77038), 'train_ucc_loss': np.float64(0.69135), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.73086)}\n",
            "Step 3320: {'train_ae_loss': np.float64(0.74791), 'train_ucc_loss': np.float64(0.69395), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.72093)}\n",
            "Step 3340: {'train_ae_loss': np.float64(0.77418), 'train_ucc_loss': np.float64(0.69537), 'train_ucc_acc': np.float64(0.3125), 'loss': np.float64(0.73478)}\n",
            "Step 3360: {'train_ae_loss': np.float64(0.76488), 'train_ucc_loss': np.float64(0.69325), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.72907)}\n",
            "Step 3380: {'train_ae_loss': np.float64(0.76896), 'train_ucc_loss': np.float64(0.69265), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.73081)}\n",
            "Step 3400: {'train_ae_loss': np.float64(0.75571), 'train_ucc_loss': np.float64(0.69379), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.72475)}\n",
            "Step 3420: {'train_ae_loss': np.float64(0.76914), 'train_ucc_loss': np.float64(0.69329), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.73122)}\n",
            "Step 3440: {'train_ae_loss': np.float64(0.76846), 'train_ucc_loss': np.float64(0.69264), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.73055)}\n",
            "Step 3460: {'train_ae_loss': np.float64(0.7581), 'train_ucc_loss': np.float64(0.69247), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.72528)}\n",
            "Step 3480: {'train_ae_loss': np.float64(0.7535), 'train_ucc_loss': np.float64(0.69298), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.72324)}\n",
            "Step 3500: {'train_ae_loss': np.float64(0.77067), 'train_ucc_loss': np.float64(0.69296), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.73181)}\n",
            "Step 3520: {'train_ae_loss': np.float64(0.7596), 'train_ucc_loss': np.float64(0.6926), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.7261)}\n",
            "Step 3540: {'train_ae_loss': np.float64(0.77563), 'train_ucc_loss': np.float64(0.69155), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.73359)}\n",
            "Step 3560: {'train_ae_loss': np.float64(0.75103), 'train_ucc_loss': np.float64(0.69141), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.72122)}\n",
            "Step 3580: {'train_ae_loss': np.float64(0.76365), 'train_ucc_loss': np.float64(0.69269), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72817)}\n",
            "Step 3600: {'train_ae_loss': np.float64(0.77821), 'train_ucc_loss': np.float64(0.69471), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.73646)}\n",
            "Step 3620: {'train_ae_loss': np.float64(0.75934), 'train_ucc_loss': np.float64(0.69404), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.72669)}\n",
            "Step 3640: {'train_ae_loss': np.float64(0.73555), 'train_ucc_loss': np.float64(0.69813), 'train_ucc_acc': np.float64(0.3125), 'loss': np.float64(0.71684)}\n",
            "Step 3660: {'train_ae_loss': np.float64(0.77381), 'train_ucc_loss': np.float64(0.69278), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.73329)}\n",
            "Step 3680: {'train_ae_loss': np.float64(0.78643), 'train_ucc_loss': np.float64(0.69316), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.73979)}\n",
            "Step 3700: {'train_ae_loss': np.float64(0.75361), 'train_ucc_loss': np.float64(0.69263), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72312)}\n",
            "Step 3720: {'train_ae_loss': np.float64(0.75593), 'train_ucc_loss': np.float64(0.69292), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72442)}\n",
            "Step 3740: {'train_ae_loss': np.float64(0.74571), 'train_ucc_loss': np.float64(0.69346), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.71958)}\n",
            "Step 3760: {'train_ae_loss': np.float64(0.75203), 'train_ucc_loss': np.float64(0.69326), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.72264)}\n",
            "Step 3780: {'train_ae_loss': np.float64(0.76792), 'train_ucc_loss': np.float64(0.69448), 'train_ucc_acc': np.float64(0.34375), 'loss': np.float64(0.7312)}\n",
            "Step 3800: {'train_ae_loss': np.float64(0.75728), 'train_ucc_loss': np.float64(0.69351), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.7254)}\n",
            "Step 3820: {'train_ae_loss': np.float64(0.76123), 'train_ucc_loss': np.float64(0.69132), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.72627)}\n",
            "Step 3840: {'train_ae_loss': np.float64(0.75462), 'train_ucc_loss': np.float64(0.69392), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.72427)}\n",
            "Step 3860: {'train_ae_loss': np.float64(0.74349), 'train_ucc_loss': np.float64(0.69192), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.7177)}\n",
            "Step 3880: {'train_ae_loss': np.float64(0.72462), 'train_ucc_loss': np.float64(0.69667), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.71065)}\n",
            "Step 3900: {'train_ae_loss': np.float64(0.7679), 'train_ucc_loss': np.float64(0.69335), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.73063)}\n",
            "Step 3920: {'train_ae_loss': np.float64(0.73973), 'train_ucc_loss': np.float64(0.69545), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.71759)}\n",
            "Step 3940: {'train_ae_loss': np.float64(0.74966), 'train_ucc_loss': np.float64(0.69055), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.7201)}\n",
            "Step 3960: {'train_ae_loss': np.float64(0.77142), 'train_ucc_loss': np.float64(0.69251), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.73197)}\n",
            "Step 3980: {'train_ae_loss': np.float64(0.7515), 'train_ucc_loss': np.float64(0.69566), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.72358)}\n",
            "Step 4000: {'train_ae_loss': np.float64(0.75384), 'train_ucc_loss': np.float64(0.69091), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.72237)}\n",
            "step: 4000,eval_ae_loss: 0.74119,eval_ucc_loss: 0.69321,eval_ucc_acc: 0.5\n",
            "Step 4020: {'train_ae_loss': np.float64(0.76213), 'train_ucc_loss': np.float64(0.69194), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.72704)}\n",
            "Step 4040: {'train_ae_loss': np.float64(0.76627), 'train_ucc_loss': np.float64(0.69324), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.72976)}\n",
            "Step 4060: {'train_ae_loss': np.float64(0.75252), 'train_ucc_loss': np.float64(0.69143), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.72197)}\n",
            "Step 4080: {'train_ae_loss': np.float64(0.7533), 'train_ucc_loss': np.float64(0.69341), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.72336)}\n",
            "Step 4100: {'train_ae_loss': np.float64(0.75069), 'train_ucc_loss': np.float64(0.69564), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.72317)}\n",
            "Step 4120: {'train_ae_loss': np.float64(0.74085), 'train_ucc_loss': np.float64(0.6931), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71698)}\n",
            "Step 4140: {'train_ae_loss': np.float64(0.7587), 'train_ucc_loss': np.float64(0.69312), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.72591)}\n",
            "Step 4160: {'train_ae_loss': np.float64(0.74062), 'train_ucc_loss': np.float64(0.69628), 'train_ucc_acc': np.float64(0.34375), 'loss': np.float64(0.71845)}\n",
            "Step 4180: {'train_ae_loss': np.float64(0.76594), 'train_ucc_loss': np.float64(0.69194), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.72894)}\n",
            "Step 4200: {'train_ae_loss': np.float64(0.75658), 'train_ucc_loss': np.float64(0.69305), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72481)}\n",
            "Step 4220: {'train_ae_loss': np.float64(0.76446), 'train_ucc_loss': np.float64(0.6929), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.72868)}\n",
            "Step 4240: {'train_ae_loss': np.float64(0.75188), 'train_ucc_loss': np.float64(0.69347), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.72268)}\n",
            "Step 4260: {'train_ae_loss': np.float64(0.7731), 'train_ucc_loss': np.float64(0.69246), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.73278)}\n",
            "Step 4280: {'train_ae_loss': np.float64(0.73127), 'train_ucc_loss': np.float64(0.69308), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71217)}\n",
            "Step 4300: {'train_ae_loss': np.float64(0.76449), 'train_ucc_loss': np.float64(0.69216), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.72832)}\n",
            "Step 4320: {'train_ae_loss': np.float64(0.76026), 'train_ucc_loss': np.float64(0.69302), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.72664)}\n",
            "Step 4340: {'train_ae_loss': np.float64(0.74974), 'train_ucc_loss': np.float64(0.69272), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.72123)}\n",
            "Step 4360: {'train_ae_loss': np.float64(0.74136), 'train_ucc_loss': np.float64(0.69282), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.71709)}\n",
            "Step 4380: {'train_ae_loss': np.float64(0.75322), 'train_ucc_loss': np.float64(0.69254), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.72288)}\n",
            "Step 4400: {'train_ae_loss': np.float64(0.73702), 'train_ucc_loss': np.float64(0.69238), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.7147)}\n",
            "Step 4420: {'train_ae_loss': np.float64(0.73291), 'train_ucc_loss': np.float64(0.69281), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.71286)}\n",
            "Step 4440: {'train_ae_loss': np.float64(0.75694), 'train_ucc_loss': np.float64(0.69266), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.7248)}\n",
            "Step 4460: {'train_ae_loss': np.float64(0.74956), 'train_ucc_loss': np.float64(0.69393), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.72175)}\n",
            "Step 4480: {'train_ae_loss': np.float64(0.74572), 'train_ucc_loss': np.float64(0.69284), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71928)}\n",
            "Step 4500: {'train_ae_loss': np.float64(0.75439), 'train_ucc_loss': np.float64(0.69227), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72333)}\n",
            "Step 4520: {'train_ae_loss': np.float64(0.73246), 'train_ucc_loss': np.float64(0.69235), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.7124)}\n",
            "Step 4540: {'train_ae_loss': np.float64(0.74705), 'train_ucc_loss': np.float64(0.69251), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.71978)}\n",
            "Step 4560: {'train_ae_loss': np.float64(0.77511), 'train_ucc_loss': np.float64(0.69287), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.73399)}\n",
            "Step 4580: {'train_ae_loss': np.float64(0.73399), 'train_ucc_loss': np.float64(0.69236), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71318)}\n",
            "Step 4600: {'train_ae_loss': np.float64(0.75267), 'train_ucc_loss': np.float64(0.69253), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.7226)}\n",
            "Step 4620: {'train_ae_loss': np.float64(0.73061), 'train_ucc_loss': np.float64(0.69297), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.71179)}\n",
            "Step 4640: {'train_ae_loss': np.float64(0.75215), 'train_ucc_loss': np.float64(0.69342), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.72278)}\n",
            "Step 4660: {'train_ae_loss': np.float64(0.74091), 'train_ucc_loss': np.float64(0.69305), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.71698)}\n",
            "Step 4680: {'train_ae_loss': np.float64(0.76883), 'train_ucc_loss': np.float64(0.69299), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.73091)}\n",
            "Step 4700: {'train_ae_loss': np.float64(0.73708), 'train_ucc_loss': np.float64(0.69438), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.71573)}\n",
            "Step 4720: {'train_ae_loss': np.float64(0.76737), 'train_ucc_loss': np.float64(0.69099), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.72918)}\n",
            "Step 4740: {'train_ae_loss': np.float64(0.7443), 'train_ucc_loss': np.float64(0.69484), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.71957)}\n",
            "Step 4760: {'train_ae_loss': np.float64(0.75212), 'train_ucc_loss': np.float64(0.69143), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72177)}\n",
            "Step 4780: {'train_ae_loss': np.float64(0.73211), 'train_ucc_loss': np.float64(0.69871), 'train_ucc_acc': np.float64(0.3125), 'loss': np.float64(0.71541)}\n",
            "Step 4800: {'train_ae_loss': np.float64(0.76079), 'train_ucc_loss': np.float64(0.68786), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.72433)}\n",
            "Step 4820: {'train_ae_loss': np.float64(0.74864), 'train_ucc_loss': np.float64(0.69295), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.72079)}\n",
            "Step 4840: {'train_ae_loss': np.float64(0.72885), 'train_ucc_loss': np.float64(0.69295), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.7109)}\n",
            "Step 4860: {'train_ae_loss': np.float64(0.75228), 'train_ucc_loss': np.float64(0.69222), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72225)}\n",
            "Step 4880: {'train_ae_loss': np.float64(0.75514), 'train_ucc_loss': np.float64(0.6964), 'train_ucc_acc': np.float64(0.375), 'loss': np.float64(0.72577)}\n",
            "Step 4900: {'train_ae_loss': np.float64(0.72834), 'train_ucc_loss': np.float64(0.69679), 'train_ucc_acc': np.float64(0.34375), 'loss': np.float64(0.71257)}\n",
            "Step 4920: {'train_ae_loss': np.float64(0.76309), 'train_ucc_loss': np.float64(0.693), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72805)}\n",
            "Step 4940: {'train_ae_loss': np.float64(0.74952), 'train_ucc_loss': np.float64(0.69628), 'train_ucc_acc': np.float64(0.28125), 'loss': np.float64(0.7229)}\n",
            "Step 4960: {'train_ae_loss': np.float64(0.74394), 'train_ucc_loss': np.float64(0.69255), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71824)}\n",
            "Step 4980: {'train_ae_loss': np.float64(0.75635), 'train_ucc_loss': np.float64(0.69267), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.72451)}\n",
            "Step 5000: {'train_ae_loss': np.float64(0.74525), 'train_ucc_loss': np.float64(0.69272), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.71898)}\n",
            "step: 5000,eval_ae_loss: 0.73861,eval_ucc_loss: 0.69324,eval_ucc_acc: 0.5\n",
            "Step 5020: {'train_ae_loss': np.float64(0.77011), 'train_ucc_loss': np.float64(0.69353), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.73182)}\n",
            "Step 5040: {'train_ae_loss': np.float64(0.74694), 'train_ucc_loss': np.float64(0.69308), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72001)}\n",
            "Step 5060: {'train_ae_loss': np.float64(0.73244), 'train_ucc_loss': np.float64(0.69351), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.71297)}\n",
            "Step 5080: {'train_ae_loss': np.float64(0.74004), 'train_ucc_loss': np.float64(0.69363), 'train_ucc_acc': np.float64(0.375), 'loss': np.float64(0.71684)}\n",
            "Step 5100: {'train_ae_loss': np.float64(0.74436), 'train_ucc_loss': np.float64(0.69358), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.71897)}\n",
            "Step 5120: {'train_ae_loss': np.float64(0.7432), 'train_ucc_loss': np.float64(0.69081), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.717)}\n",
            "Step 5140: {'train_ae_loss': np.float64(0.73424), 'train_ucc_loss': np.float64(0.69566), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.71495)}\n",
            "Step 5160: {'train_ae_loss': np.float64(0.7673), 'train_ucc_loss': np.float64(0.69231), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.7298)}\n",
            "Step 5180: {'train_ae_loss': np.float64(0.73606), 'train_ucc_loss': np.float64(0.69414), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.7151)}\n",
            "Step 5200: {'train_ae_loss': np.float64(0.73289), 'train_ucc_loss': np.float64(0.69255), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.71272)}\n",
            "Step 5220: {'train_ae_loss': np.float64(0.75059), 'train_ucc_loss': np.float64(0.69407), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.72233)}\n",
            "Step 5240: {'train_ae_loss': np.float64(0.74214), 'train_ucc_loss': np.float64(0.69313), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.71763)}\n",
            "Step 5260: {'train_ae_loss': np.float64(0.75548), 'train_ucc_loss': np.float64(0.69318), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.72433)}\n",
            "Step 5280: {'train_ae_loss': np.float64(0.75962), 'train_ucc_loss': np.float64(0.69248), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.72605)}\n",
            "Step 5300: {'train_ae_loss': np.float64(0.7508), 'train_ucc_loss': np.float64(0.69317), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.72199)}\n",
            "Step 5320: {'train_ae_loss': np.float64(0.76934), 'train_ucc_loss': np.float64(0.69165), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.73049)}\n",
            "Step 5340: {'train_ae_loss': np.float64(0.74381), 'train_ucc_loss': np.float64(0.69384), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.71882)}\n",
            "Step 5360: {'train_ae_loss': np.float64(0.75804), 'train_ucc_loss': np.float64(0.69109), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.72456)}\n",
            "Step 5380: {'train_ae_loss': np.float64(0.75467), 'train_ucc_loss': np.float64(0.69154), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.7231)}\n",
            "Step 5400: {'train_ae_loss': np.float64(0.74891), 'train_ucc_loss': np.float64(0.69245), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.72068)}\n",
            "Step 5420: {'train_ae_loss': np.float64(0.755), 'train_ucc_loss': np.float64(0.69205), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.72353)}\n",
            "Step 5440: {'train_ae_loss': np.float64(0.75755), 'train_ucc_loss': np.float64(0.69307), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.72531)}\n",
            "Step 5460: {'train_ae_loss': np.float64(0.75257), 'train_ucc_loss': np.float64(0.69193), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.72225)}\n",
            "Step 5480: {'train_ae_loss': np.float64(0.74026), 'train_ucc_loss': np.float64(0.69345), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71685)}\n",
            "Step 5500: {'train_ae_loss': np.float64(0.76173), 'train_ucc_loss': np.float64(0.69394), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.72783)}\n",
            "Step 5520: {'train_ae_loss': np.float64(0.7461), 'train_ucc_loss': np.float64(0.69253), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71932)}\n",
            "Step 5540: {'train_ae_loss': np.float64(0.72879), 'train_ucc_loss': np.float64(0.68739), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.70809)}\n",
            "Step 5560: {'train_ae_loss': np.float64(0.75694), 'train_ucc_loss': np.float64(0.69136), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72415)}\n",
            "Step 5580: {'train_ae_loss': np.float64(0.73827), 'train_ucc_loss': np.float64(0.69484), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.71656)}\n",
            "Step 5600: {'train_ae_loss': np.float64(0.73504), 'train_ucc_loss': np.float64(0.68863), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.71184)}\n",
            "Step 5620: {'train_ae_loss': np.float64(0.74848), 'train_ucc_loss': np.float64(0.69819), 'train_ucc_acc': np.float64(0.34375), 'loss': np.float64(0.72333)}\n",
            "Step 5640: {'train_ae_loss': np.float64(0.72618), 'train_ucc_loss': np.float64(0.69271), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.70944)}\n",
            "Step 5660: {'train_ae_loss': np.float64(0.74821), 'train_ucc_loss': np.float64(0.69022), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.71921)}\n",
            "Step 5680: {'train_ae_loss': np.float64(0.7393), 'train_ucc_loss': np.float64(0.69435), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.71682)}\n",
            "Step 5700: {'train_ae_loss': np.float64(0.7599), 'train_ucc_loss': np.float64(0.69828), 'train_ucc_acc': np.float64(0.375), 'loss': np.float64(0.72909)}\n",
            "Step 5720: {'train_ae_loss': np.float64(0.74677), 'train_ucc_loss': np.float64(0.68992), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.71834)}\n",
            "Step 5740: {'train_ae_loss': np.float64(0.7434), 'train_ucc_loss': np.float64(0.69334), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71837)}\n",
            "Step 5760: {'train_ae_loss': np.float64(0.74627), 'train_ucc_loss': np.float64(0.69292), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.71959)}\n",
            "Step 5780: {'train_ae_loss': np.float64(0.7501), 'train_ucc_loss': np.float64(0.69459), 'train_ucc_acc': np.float64(0.34375), 'loss': np.float64(0.72235)}\n",
            "Step 5800: {'train_ae_loss': np.float64(0.72772), 'train_ucc_loss': np.float64(0.69401), 'train_ucc_acc': np.float64(0.34375), 'loss': np.float64(0.71086)}\n",
            "Step 5820: {'train_ae_loss': np.float64(0.77049), 'train_ucc_loss': np.float64(0.69315), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.73182)}\n",
            "Step 5840: {'train_ae_loss': np.float64(0.74812), 'train_ucc_loss': np.float64(0.69392), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.72102)}\n",
            "Step 5860: {'train_ae_loss': np.float64(0.74452), 'train_ucc_loss': np.float64(0.69293), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.71873)}\n",
            "Step 5880: {'train_ae_loss': np.float64(0.74629), 'train_ucc_loss': np.float64(0.69257), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.71943)}\n",
            "Step 5900: {'train_ae_loss': np.float64(0.73043), 'train_ucc_loss': np.float64(0.6906), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.71051)}\n",
            "Step 5920: {'train_ae_loss': np.float64(0.73898), 'train_ucc_loss': np.float64(0.6922), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.71559)}\n",
            "Step 5940: {'train_ae_loss': np.float64(0.74647), 'train_ucc_loss': np.float64(0.69312), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.71979)}\n",
            "Step 5960: {'train_ae_loss': np.float64(0.76129), 'train_ucc_loss': np.float64(0.69044), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.72586)}\n",
            "Step 5980: {'train_ae_loss': np.float64(0.72766), 'train_ucc_loss': np.float64(0.69275), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.7102)}\n",
            "Step 6000: {'train_ae_loss': np.float64(0.74328), 'train_ucc_loss': np.float64(0.69176), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.71752)}\n",
            "step: 6000,eval_ae_loss: 0.72371,eval_ucc_loss: 0.69366,eval_ucc_acc: 0.44141\n",
            "Step 6020: {'train_ae_loss': np.float64(0.74082), 'train_ucc_loss': np.float64(0.69211), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71646)}\n",
            "Step 6040: {'train_ae_loss': np.float64(0.71542), 'train_ucc_loss': np.float64(0.69452), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.70497)}\n",
            "Step 6060: {'train_ae_loss': np.float64(0.76133), 'train_ucc_loss': np.float64(0.69394), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.72763)}\n",
            "Step 6080: {'train_ae_loss': np.float64(0.73497), 'train_ucc_loss': np.float64(0.6923), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.71364)}\n",
            "Step 6100: {'train_ae_loss': np.float64(0.72597), 'train_ucc_loss': np.float64(0.69282), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.7094)}\n",
            "Step 6120: {'train_ae_loss': np.float64(0.73791), 'train_ucc_loss': np.float64(0.69269), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.7153)}\n",
            "Step 6140: {'train_ae_loss': np.float64(0.74868), 'train_ucc_loss': np.float64(0.68857), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.71862)}\n",
            "Step 6160: {'train_ae_loss': np.float64(0.72952), 'train_ucc_loss': np.float64(0.69441), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.71197)}\n",
            "Step 6180: {'train_ae_loss': np.float64(0.76358), 'train_ucc_loss': np.float64(0.70238), 'train_ucc_acc': np.float64(0.3125), 'loss': np.float64(0.73298)}\n",
            "Step 6200: {'train_ae_loss': np.float64(0.74082), 'train_ucc_loss': np.float64(0.69118), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.716)}\n",
            "Step 6220: {'train_ae_loss': np.float64(0.753), 'train_ucc_loss': np.float64(0.69045), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.72172)}\n",
            "Step 6240: {'train_ae_loss': np.float64(0.73085), 'train_ucc_loss': np.float64(0.69318), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.71202)}\n",
            "Step 6260: {'train_ae_loss': np.float64(0.71916), 'train_ucc_loss': np.float64(0.69363), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.7064)}\n",
            "Step 6280: {'train_ae_loss': np.float64(0.74782), 'train_ucc_loss': np.float64(0.69443), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.72112)}\n",
            "Step 6300: {'train_ae_loss': np.float64(0.73509), 'train_ucc_loss': np.float64(0.69352), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.71431)}\n",
            "Step 6320: {'train_ae_loss': np.float64(0.74361), 'train_ucc_loss': np.float64(0.69268), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.71815)}\n",
            "Step 6340: {'train_ae_loss': np.float64(0.72525), 'train_ucc_loss': np.float64(0.6917), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.70847)}\n",
            "Step 6360: {'train_ae_loss': np.float64(0.73066), 'train_ucc_loss': np.float64(0.69518), 'train_ucc_acc': np.float64(0.375), 'loss': np.float64(0.71292)}\n",
            "Step 6380: {'train_ae_loss': np.float64(0.72377), 'train_ucc_loss': np.float64(0.69113), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.70745)}\n",
            "Step 6400: {'train_ae_loss': np.float64(0.73354), 'train_ucc_loss': np.float64(0.69199), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.71277)}\n",
            "Step 6420: {'train_ae_loss': np.float64(0.74515), 'train_ucc_loss': np.float64(0.69078), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.71797)}\n",
            "Step 6440: {'train_ae_loss': np.float64(0.73345), 'train_ucc_loss': np.float64(0.69303), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71324)}\n",
            "Step 6460: {'train_ae_loss': np.float64(0.75167), 'train_ucc_loss': np.float64(0.69422), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.72294)}\n",
            "Step 6480: {'train_ae_loss': np.float64(0.73522), 'train_ucc_loss': np.float64(0.69315), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.71418)}\n",
            "Step 6500: {'train_ae_loss': np.float64(0.732), 'train_ucc_loss': np.float64(0.68745), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.70972)}\n",
            "Step 6520: {'train_ae_loss': np.float64(0.73541), 'train_ucc_loss': np.float64(0.69133), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.71337)}\n",
            "Step 6540: {'train_ae_loss': np.float64(0.7669), 'train_ucc_loss': np.float64(0.68686), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.72688)}\n",
            "Step 6560: {'train_ae_loss': np.float64(0.74686), 'train_ucc_loss': np.float64(0.6926), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71973)}\n",
            "Step 6580: {'train_ae_loss': np.float64(0.73827), 'train_ucc_loss': np.float64(0.69318), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71573)}\n",
            "Step 6600: {'train_ae_loss': np.float64(0.75423), 'train_ucc_loss': np.float64(0.69431), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.72427)}\n",
            "Step 6620: {'train_ae_loss': np.float64(0.75084), 'train_ucc_loss': np.float64(0.68747), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.71915)}\n",
            "Step 6640: {'train_ae_loss': np.float64(0.73687), 'train_ucc_loss': np.float64(0.69472), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.71579)}\n",
            "Step 6660: {'train_ae_loss': np.float64(0.74805), 'train_ucc_loss': np.float64(0.68924), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.71865)}\n",
            "Step 6680: {'train_ae_loss': np.float64(0.7357), 'train_ucc_loss': np.float64(0.6928), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.71425)}\n",
            "Step 6700: {'train_ae_loss': np.float64(0.74478), 'train_ucc_loss': np.float64(0.69005), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.71741)}\n",
            "Step 6720: {'train_ae_loss': np.float64(0.71885), 'train_ucc_loss': np.float64(0.68203), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.70044)}\n",
            "Step 6740: {'train_ae_loss': np.float64(0.78137), 'train_ucc_loss': np.float64(0.69566), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.73852)}\n",
            "Step 6760: {'train_ae_loss': np.float64(0.73204), 'train_ucc_loss': np.float64(0.69495), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71349)}\n",
            "Step 6780: {'train_ae_loss': np.float64(0.73456), 'train_ucc_loss': np.float64(0.6926), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.71358)}\n",
            "Step 6800: {'train_ae_loss': np.float64(0.75495), 'train_ucc_loss': np.float64(0.69232), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.72363)}\n",
            "Step 6820: {'train_ae_loss': np.float64(0.72754), 'train_ucc_loss': np.float64(0.69038), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.70896)}\n",
            "Step 6840: {'train_ae_loss': np.float64(0.73876), 'train_ucc_loss': np.float64(0.69086), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.71481)}\n",
            "Step 6860: {'train_ae_loss': np.float64(0.73812), 'train_ucc_loss': np.float64(0.68985), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.71398)}\n",
            "Step 6880: {'train_ae_loss': np.float64(0.73827), 'train_ucc_loss': np.float64(0.69025), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.71426)}\n",
            "Step 6900: {'train_ae_loss': np.float64(0.72843), 'train_ucc_loss': np.float64(0.69295), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71069)}\n",
            "Step 6920: {'train_ae_loss': np.float64(0.71584), 'train_ucc_loss': np.float64(0.69623), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.70603)}\n",
            "Step 6940: {'train_ae_loss': np.float64(0.73274), 'train_ucc_loss': np.float64(0.69378), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.71326)}\n",
            "Step 6960: {'train_ae_loss': np.float64(0.74464), 'train_ucc_loss': np.float64(0.69146), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71805)}\n",
            "Step 6980: {'train_ae_loss': np.float64(0.71897), 'train_ucc_loss': np.float64(0.69382), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.70639)}\n",
            "Step 7000: {'train_ae_loss': np.float64(0.72521), 'train_ucc_loss': np.float64(0.6904), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.7078)}\n",
            "step: 7000,eval_ae_loss: 0.72066,eval_ucc_loss: 0.69438,eval_ucc_acc: 0.44336\n",
            "Step 7020: {'train_ae_loss': np.float64(0.72858), 'train_ucc_loss': np.float64(0.69029), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.70944)}\n",
            "Step 7040: {'train_ae_loss': np.float64(0.72773), 'train_ucc_loss': np.float64(0.6854), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.70656)}\n",
            "Step 7060: {'train_ae_loss': np.float64(0.71426), 'train_ucc_loss': np.float64(0.69504), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.70465)}\n",
            "Step 7080: {'train_ae_loss': np.float64(0.7171), 'train_ucc_loss': np.float64(0.70353), 'train_ucc_acc': np.float64(0.3125), 'loss': np.float64(0.71031)}\n",
            "Step 7100: {'train_ae_loss': np.float64(0.73431), 'train_ucc_loss': np.float64(0.69388), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.7141)}\n",
            "Step 7120: {'train_ae_loss': np.float64(0.72721), 'train_ucc_loss': np.float64(0.69089), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.70905)}\n",
            "Step 7140: {'train_ae_loss': np.float64(0.72171), 'train_ucc_loss': np.float64(0.69413), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.70792)}\n",
            "Step 7160: {'train_ae_loss': np.float64(0.73359), 'train_ucc_loss': np.float64(0.69723), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.71541)}\n",
            "Step 7180: {'train_ae_loss': np.float64(0.7205), 'train_ucc_loss': np.float64(0.68999), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.70524)}\n",
            "Step 7200: {'train_ae_loss': np.float64(0.71736), 'train_ucc_loss': np.float64(0.68753), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.70244)}\n",
            "Step 7220: {'train_ae_loss': np.float64(0.73743), 'train_ucc_loss': np.float64(0.69949), 'train_ucc_acc': np.float64(0.34375), 'loss': np.float64(0.71846)}\n",
            "Step 7240: {'train_ae_loss': np.float64(0.72483), 'train_ucc_loss': np.float64(0.6928), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.70881)}\n",
            "Step 7260: {'train_ae_loss': np.float64(0.71998), 'train_ucc_loss': np.float64(0.6916), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.70579)}\n",
            "Step 7280: {'train_ae_loss': np.float64(0.70444), 'train_ucc_loss': np.float64(0.69298), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.69871)}\n",
            "Step 7300: {'train_ae_loss': np.float64(0.72706), 'train_ucc_loss': np.float64(0.68651), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.70679)}\n",
            "Step 7320: {'train_ae_loss': np.float64(0.72322), 'train_ucc_loss': np.float64(0.68722), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.70522)}\n",
            "Step 7340: {'train_ae_loss': np.float64(0.70774), 'train_ucc_loss': np.float64(0.69171), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.69972)}\n",
            "Step 7360: {'train_ae_loss': np.float64(0.71121), 'train_ucc_loss': np.float64(0.69531), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.70326)}\n",
            "Step 7380: {'train_ae_loss': np.float64(0.71487), 'train_ucc_loss': np.float64(0.6848), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.69984)}\n",
            "Step 7400: {'train_ae_loss': np.float64(0.7216), 'train_ucc_loss': np.float64(0.69129), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.70644)}\n",
            "Step 7420: {'train_ae_loss': np.float64(0.71199), 'train_ucc_loss': np.float64(0.69133), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.70166)}\n",
            "Step 7440: {'train_ae_loss': np.float64(0.744), 'train_ucc_loss': np.float64(0.68794), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.71597)}\n",
            "Step 7460: {'train_ae_loss': np.float64(0.72708), 'train_ucc_loss': np.float64(0.69127), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.70917)}\n",
            "Step 7480: {'train_ae_loss': np.float64(0.72689), 'train_ucc_loss': np.float64(0.68563), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.70626)}\n",
            "Step 7500: {'train_ae_loss': np.float64(0.70296), 'train_ucc_loss': np.float64(0.69616), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.69956)}\n",
            "Step 7520: {'train_ae_loss': np.float64(0.69074), 'train_ucc_loss': np.float64(0.68916), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.68995)}\n",
            "Step 7540: {'train_ae_loss': np.float64(0.70883), 'train_ucc_loss': np.float64(0.69302), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.70093)}\n",
            "Step 7560: {'train_ae_loss': np.float64(0.71654), 'train_ucc_loss': np.float64(0.67489), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.69571)}\n",
            "Step 7580: {'train_ae_loss': np.float64(0.70768), 'train_ucc_loss': np.float64(0.68425), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.69596)}\n",
            "Step 7600: {'train_ae_loss': np.float64(0.69128), 'train_ucc_loss': np.float64(0.71983), 'train_ucc_acc': np.float64(0.34375), 'loss': np.float64(0.70555)}\n",
            "Step 7620: {'train_ae_loss': np.float64(0.70918), 'train_ucc_loss': np.float64(0.68205), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.69561)}\n",
            "Step 7640: {'train_ae_loss': np.float64(0.73606), 'train_ucc_loss': np.float64(0.68651), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.71128)}\n",
            "Step 7660: {'train_ae_loss': np.float64(0.69455), 'train_ucc_loss': np.float64(0.69515), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.69485)}\n",
            "Step 7680: {'train_ae_loss': np.float64(0.71962), 'train_ucc_loss': np.float64(0.69074), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.70518)}\n",
            "Step 7700: {'train_ae_loss': np.float64(0.74375), 'train_ucc_loss': np.float64(0.66646), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.7051)}\n",
            "Step 7720: {'train_ae_loss': np.float64(0.70496), 'train_ucc_loss': np.float64(0.7024), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.70368)}\n",
            "Step 7740: {'train_ae_loss': np.float64(0.69797), 'train_ucc_loss': np.float64(0.68692), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.69244)}\n",
            "Step 7760: {'train_ae_loss': np.float64(0.71186), 'train_ucc_loss': np.float64(0.67883), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.69534)}\n",
            "Step 7780: {'train_ae_loss': np.float64(0.70997), 'train_ucc_loss': np.float64(0.69552), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.70274)}\n",
            "Step 7800: {'train_ae_loss': np.float64(0.71859), 'train_ucc_loss': np.float64(0.68406), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.70132)}\n",
            "Step 7820: {'train_ae_loss': np.float64(0.72321), 'train_ucc_loss': np.float64(0.69467), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.70894)}\n",
            "Step 7840: {'train_ae_loss': np.float64(0.70193), 'train_ucc_loss': np.float64(0.69377), 'train_ucc_acc': np.float64(0.34375), 'loss': np.float64(0.69785)}\n",
            "Step 7860: {'train_ae_loss': np.float64(0.70503), 'train_ucc_loss': np.float64(0.68112), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.69307)}\n",
            "Step 7880: {'train_ae_loss': np.float64(0.69548), 'train_ucc_loss': np.float64(0.68422), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.68985)}\n",
            "Step 7900: {'train_ae_loss': np.float64(0.71226), 'train_ucc_loss': np.float64(0.69626), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.70426)}\n",
            "Step 7920: {'train_ae_loss': np.float64(0.73777), 'train_ucc_loss': np.float64(0.68322), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.7105)}\n",
            "Step 7940: {'train_ae_loss': np.float64(0.73151), 'train_ucc_loss': np.float64(0.68918), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.71034)}\n",
            "Step 7960: {'train_ae_loss': np.float64(0.71508), 'train_ucc_loss': np.float64(0.69971), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.70739)}\n",
            "Step 7980: {'train_ae_loss': np.float64(0.72198), 'train_ucc_loss': np.float64(0.69083), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.7064)}\n",
            "Step 8000: {'train_ae_loss': np.float64(0.70673), 'train_ucc_loss': np.float64(0.69622), 'train_ucc_acc': np.float64(0.34375), 'loss': np.float64(0.70147)}\n",
            "step: 8000,eval_ae_loss: 0.69377,eval_ucc_loss: 0.69608,eval_ucc_acc: 0.4541\n",
            "Step 8020: {'train_ae_loss': np.float64(0.70694), 'train_ucc_loss': np.float64(0.67663), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.69179)}\n",
            "Step 8040: {'train_ae_loss': np.float64(0.70439), 'train_ucc_loss': np.float64(0.67958), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.69198)}\n",
            "Step 8060: {'train_ae_loss': np.float64(0.71363), 'train_ucc_loss': np.float64(0.67323), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.69343)}\n",
            "Step 8080: {'train_ae_loss': np.float64(0.71419), 'train_ucc_loss': np.float64(0.67338), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.69378)}\n",
            "Step 8100: {'train_ae_loss': np.float64(0.7009), 'train_ucc_loss': np.float64(0.70672), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.70381)}\n",
            "Step 8120: {'train_ae_loss': np.float64(0.71623), 'train_ucc_loss': np.float64(0.69563), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.70593)}\n",
            "Step 8140: {'train_ae_loss': np.float64(0.71744), 'train_ucc_loss': np.float64(0.71106), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.71425)}\n",
            "Step 8160: {'train_ae_loss': np.float64(0.70476), 'train_ucc_loss': np.float64(0.69854), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.70165)}\n",
            "Step 8180: {'train_ae_loss': np.float64(0.70814), 'train_ucc_loss': np.float64(0.70402), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.70608)}\n",
            "Step 8200: {'train_ae_loss': np.float64(0.71315), 'train_ucc_loss': np.float64(0.67343), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.69329)}\n",
            "Step 8220: {'train_ae_loss': np.float64(0.7127), 'train_ucc_loss': np.float64(0.66178), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.68724)}\n",
            "Step 8240: {'train_ae_loss': np.float64(0.70134), 'train_ucc_loss': np.float64(0.6848), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.69307)}\n",
            "Step 8260: {'train_ae_loss': np.float64(0.71593), 'train_ucc_loss': np.float64(0.70008), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.70801)}\n",
            "Step 8280: {'train_ae_loss': np.float64(0.67755), 'train_ucc_loss': np.float64(0.67559), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.67657)}\n",
            "Step 8300: {'train_ae_loss': np.float64(0.70803), 'train_ucc_loss': np.float64(0.68228), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.69516)}\n",
            "Step 8320: {'train_ae_loss': np.float64(0.69938), 'train_ucc_loss': np.float64(0.6815), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.69044)}\n",
            "Step 8340: {'train_ae_loss': np.float64(0.70457), 'train_ucc_loss': np.float64(0.69376), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.69916)}\n",
            "Step 8360: {'train_ae_loss': np.float64(0.70732), 'train_ucc_loss': np.float64(0.68485), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.69609)}\n",
            "Step 8380: {'train_ae_loss': np.float64(0.72188), 'train_ucc_loss': np.float64(0.72707), 'train_ucc_acc': np.float64(0.25), 'loss': np.float64(0.72447)}\n",
            "Step 8400: {'train_ae_loss': np.float64(0.70238), 'train_ucc_loss': np.float64(0.6682), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.68529)}\n",
            "Step 8420: {'train_ae_loss': np.float64(0.70538), 'train_ucc_loss': np.float64(0.71614), 'train_ucc_acc': np.float64(0.3125), 'loss': np.float64(0.71076)}\n",
            "Step 8440: {'train_ae_loss': np.float64(0.68579), 'train_ucc_loss': np.float64(0.68655), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.68617)}\n",
            "Step 8460: {'train_ae_loss': np.float64(0.71134), 'train_ucc_loss': np.float64(0.69544), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.70339)}\n",
            "Step 8480: {'train_ae_loss': np.float64(0.72152), 'train_ucc_loss': np.float64(0.65841), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.68997)}\n",
            "Step 8500: {'train_ae_loss': np.float64(0.70551), 'train_ucc_loss': np.float64(0.69077), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.69814)}\n",
            "Step 8520: {'train_ae_loss': np.float64(0.7158), 'train_ucc_loss': np.float64(0.68757), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.70169)}\n",
            "Step 8540: {'train_ae_loss': np.float64(0.69237), 'train_ucc_loss': np.float64(0.6939), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.69313)}\n",
            "Step 8560: {'train_ae_loss': np.float64(0.6914), 'train_ucc_loss': np.float64(0.66919), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.68029)}\n",
            "Step 8580: {'train_ae_loss': np.float64(0.70008), 'train_ucc_loss': np.float64(0.67873), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68941)}\n",
            "Step 8600: {'train_ae_loss': np.float64(0.71435), 'train_ucc_loss': np.float64(0.6631), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.68873)}\n",
            "Step 8620: {'train_ae_loss': np.float64(0.68708), 'train_ucc_loss': np.float64(0.69177), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.68943)}\n",
            "Step 8640: {'train_ae_loss': np.float64(0.71718), 'train_ucc_loss': np.float64(0.72296), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.72007)}\n",
            "Step 8660: {'train_ae_loss': np.float64(0.70576), 'train_ucc_loss': np.float64(0.66936), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68756)}\n",
            "Step 8680: {'train_ae_loss': np.float64(0.69265), 'train_ucc_loss': np.float64(0.67047), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68156)}\n",
            "Step 8700: {'train_ae_loss': np.float64(0.70925), 'train_ucc_loss': np.float64(0.67383), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.69154)}\n",
            "Step 8720: {'train_ae_loss': np.float64(0.69383), 'train_ucc_loss': np.float64(0.68697), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.6904)}\n",
            "Step 8740: {'train_ae_loss': np.float64(0.69872), 'train_ucc_loss': np.float64(0.6511), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.67491)}\n",
            "Step 8760: {'train_ae_loss': np.float64(0.68576), 'train_ucc_loss': np.float64(0.67276), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67926)}\n",
            "Step 8780: {'train_ae_loss': np.float64(0.71663), 'train_ucc_loss': np.float64(0.69225), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.70444)}\n",
            "Step 8800: {'train_ae_loss': np.float64(0.70729), 'train_ucc_loss': np.float64(0.70607), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.70668)}\n",
            "Step 8820: {'train_ae_loss': np.float64(0.70409), 'train_ucc_loss': np.float64(0.64933), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.67671)}\n",
            "Step 8840: {'train_ae_loss': np.float64(0.7045), 'train_ucc_loss': np.float64(0.68905), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.69677)}\n",
            "Step 8860: {'train_ae_loss': np.float64(0.7123), 'train_ucc_loss': np.float64(0.66985), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.69108)}\n",
            "Step 8880: {'train_ae_loss': np.float64(0.69392), 'train_ucc_loss': np.float64(0.65576), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67484)}\n",
            "Step 8900: {'train_ae_loss': np.float64(0.72195), 'train_ucc_loss': np.float64(0.66536), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.69366)}\n",
            "Step 8920: {'train_ae_loss': np.float64(0.6982), 'train_ucc_loss': np.float64(0.63827), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.66824)}\n",
            "Step 8940: {'train_ae_loss': np.float64(0.69393), 'train_ucc_loss': np.float64(0.67385), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.68389)}\n",
            "Step 8960: {'train_ae_loss': np.float64(0.69337), 'train_ucc_loss': np.float64(0.68341), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.68839)}\n",
            "Step 8980: {'train_ae_loss': np.float64(0.70857), 'train_ucc_loss': np.float64(0.6646), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68658)}\n",
            "Step 9000: {'train_ae_loss': np.float64(0.69044), 'train_ucc_loss': np.float64(0.61709), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.65377)}\n",
            "step: 9000,eval_ae_loss: 0.68847,eval_ucc_loss: 0.68576,eval_ucc_acc: 0.54492\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/02 21:55:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 9020: {'train_ae_loss': np.float64(0.68925), 'train_ucc_loss': np.float64(0.6801), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.68468)}\n",
            "Step 9040: {'train_ae_loss': np.float64(0.70447), 'train_ucc_loss': np.float64(0.6476), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67603)}\n",
            "Step 9060: {'train_ae_loss': np.float64(0.70601), 'train_ucc_loss': np.float64(0.64189), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67395)}\n",
            "Step 9080: {'train_ae_loss': np.float64(0.69714), 'train_ucc_loss': np.float64(0.74425), 'train_ucc_acc': np.float64(0.375), 'loss': np.float64(0.7207)}\n",
            "Step 9100: {'train_ae_loss': np.float64(0.71511), 'train_ucc_loss': np.float64(0.63144), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.67328)}\n",
            "Step 9120: {'train_ae_loss': np.float64(0.70272), 'train_ucc_loss': np.float64(0.70008), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.7014)}\n",
            "Step 9140: {'train_ae_loss': np.float64(0.70338), 'train_ucc_loss': np.float64(0.66658), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.68498)}\n",
            "Step 9160: {'train_ae_loss': np.float64(0.69379), 'train_ucc_loss': np.float64(0.69839), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.69609)}\n",
            "Step 9180: {'train_ae_loss': np.float64(0.70005), 'train_ucc_loss': np.float64(0.63784), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66895)}\n",
            "Step 9200: {'train_ae_loss': np.float64(0.7056), 'train_ucc_loss': np.float64(0.63936), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.67248)}\n",
            "Step 9220: {'train_ae_loss': np.float64(0.71423), 'train_ucc_loss': np.float64(0.65804), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.68613)}\n",
            "Step 9240: {'train_ae_loss': np.float64(0.70374), 'train_ucc_loss': np.float64(0.61908), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.66141)}\n",
            "Step 9260: {'train_ae_loss': np.float64(0.69858), 'train_ucc_loss': np.float64(0.63249), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.66553)}\n",
            "Step 9280: {'train_ae_loss': np.float64(0.70648), 'train_ucc_loss': np.float64(0.72309), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.71478)}\n",
            "Step 9300: {'train_ae_loss': np.float64(0.6867), 'train_ucc_loss': np.float64(0.67122), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.67896)}\n",
            "Step 9320: {'train_ae_loss': np.float64(0.68493), 'train_ucc_loss': np.float64(0.67224), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67858)}\n",
            "Step 9340: {'train_ae_loss': np.float64(0.71994), 'train_ucc_loss': np.float64(0.65779), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.68886)}\n",
            "Step 9360: {'train_ae_loss': np.float64(0.69631), 'train_ucc_loss': np.float64(0.66171), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67901)}\n",
            "Step 9380: {'train_ae_loss': np.float64(0.70629), 'train_ucc_loss': np.float64(0.65714), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68172)}\n",
            "Step 9400: {'train_ae_loss': np.float64(0.72069), 'train_ucc_loss': np.float64(0.68428), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.70248)}\n",
            "Step 9420: {'train_ae_loss': np.float64(0.69806), 'train_ucc_loss': np.float64(0.652), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.67503)}\n",
            "Step 9440: {'train_ae_loss': np.float64(0.70267), 'train_ucc_loss': np.float64(0.66744), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.68505)}\n",
            "Step 9460: {'train_ae_loss': np.float64(0.6906), 'train_ucc_loss': np.float64(0.61223), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65141)}\n",
            "Step 9480: {'train_ae_loss': np.float64(0.69737), 'train_ucc_loss': np.float64(0.73366), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71551)}\n",
            "Step 9500: {'train_ae_loss': np.float64(0.70605), 'train_ucc_loss': np.float64(0.65734), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.6817)}\n",
            "Step 9520: {'train_ae_loss': np.float64(0.70203), 'train_ucc_loss': np.float64(0.64759), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67481)}\n",
            "Step 9540: {'train_ae_loss': np.float64(0.69278), 'train_ucc_loss': np.float64(0.67354), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.68316)}\n",
            "Step 9560: {'train_ae_loss': np.float64(0.70307), 'train_ucc_loss': np.float64(0.66858), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.68583)}\n",
            "Step 9580: {'train_ae_loss': np.float64(0.70936), 'train_ucc_loss': np.float64(0.63006), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.66971)}\n",
            "Step 9600: {'train_ae_loss': np.float64(0.7309), 'train_ucc_loss': np.float64(0.60871), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.6698)}\n",
            "Step 9620: {'train_ae_loss': np.float64(0.72299), 'train_ucc_loss': np.float64(0.69223), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.70761)}\n",
            "Step 9640: {'train_ae_loss': np.float64(0.71327), 'train_ucc_loss': np.float64(0.62151), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.66739)}\n",
            "Step 9660: {'train_ae_loss': np.float64(0.69155), 'train_ucc_loss': np.float64(0.7127), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.70212)}\n",
            "Step 9680: {'train_ae_loss': np.float64(0.6896), 'train_ucc_loss': np.float64(0.67746), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.68353)}\n",
            "Step 9700: {'train_ae_loss': np.float64(0.69817), 'train_ucc_loss': np.float64(0.69068), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.69442)}\n",
            "Step 9720: {'train_ae_loss': np.float64(0.70889), 'train_ucc_loss': np.float64(0.61451), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.6617)}\n",
            "Step 9740: {'train_ae_loss': np.float64(0.69979), 'train_ucc_loss': np.float64(0.68623), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.69301)}\n",
            "Step 9760: {'train_ae_loss': np.float64(0.68132), 'train_ucc_loss': np.float64(0.63788), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.6596)}\n",
            "Step 9780: {'train_ae_loss': np.float64(0.71948), 'train_ucc_loss': np.float64(0.63226), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67587)}\n",
            "Step 9800: {'train_ae_loss': np.float64(0.69321), 'train_ucc_loss': np.float64(0.65762), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.67542)}\n",
            "Step 9820: {'train_ae_loss': np.float64(0.70931), 'train_ucc_loss': np.float64(0.67623), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.69277)}\n",
            "Step 9840: {'train_ae_loss': np.float64(0.7037), 'train_ucc_loss': np.float64(0.6328), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.66825)}\n",
            "Step 9860: {'train_ae_loss': np.float64(0.68387), 'train_ucc_loss': np.float64(0.60882), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.64635)}\n",
            "Step 9880: {'train_ae_loss': np.float64(0.7002), 'train_ucc_loss': np.float64(0.65928), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.67974)}\n",
            "Step 9900: {'train_ae_loss': np.float64(0.69332), 'train_ucc_loss': np.float64(0.71518), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.70425)}\n",
            "Step 9920: {'train_ae_loss': np.float64(0.71638), 'train_ucc_loss': np.float64(0.58286), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.64962)}\n",
            "Step 9940: {'train_ae_loss': np.float64(0.69539), 'train_ucc_loss': np.float64(0.71637), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.70588)}\n",
            "Step 9960: {'train_ae_loss': np.float64(0.68574), 'train_ucc_loss': np.float64(0.6403), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66302)}\n",
            "Step 9980: {'train_ae_loss': np.float64(0.69871), 'train_ucc_loss': np.float64(0.7004), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.69956)}\n",
            "Step 10000: {'train_ae_loss': np.float64(0.69451), 'train_ucc_loss': np.float64(0.64627), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67039)}\n",
            "step: 10000,eval_ae_loss: 0.69454,eval_ucc_loss: 0.6799,eval_ucc_acc: 0.61328\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/02 22:14:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 10020: {'train_ae_loss': np.float64(0.69853), 'train_ucc_loss': np.float64(0.61388), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.6562)}\n",
            "Step 10040: {'train_ae_loss': np.float64(0.67951), 'train_ucc_loss': np.float64(0.76755), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.72353)}\n",
            "Step 10060: {'train_ae_loss': np.float64(0.68975), 'train_ucc_loss': np.float64(0.71429), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.70202)}\n",
            "Step 10080: {'train_ae_loss': np.float64(0.68334), 'train_ucc_loss': np.float64(0.69724), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.69029)}\n",
            "Step 10100: {'train_ae_loss': np.float64(0.70287), 'train_ucc_loss': np.float64(0.64477), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.67382)}\n",
            "Step 10120: {'train_ae_loss': np.float64(0.69969), 'train_ucc_loss': np.float64(0.68153), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.69061)}\n",
            "Step 10140: {'train_ae_loss': np.float64(0.69604), 'train_ucc_loss': np.float64(0.69695), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.69649)}\n",
            "Step 10160: {'train_ae_loss': np.float64(0.68969), 'train_ucc_loss': np.float64(0.64126), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66547)}\n",
            "Step 10180: {'train_ae_loss': np.float64(0.69931), 'train_ucc_loss': np.float64(0.62783), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.66357)}\n",
            "Step 10200: {'train_ae_loss': np.float64(0.68976), 'train_ucc_loss': np.float64(0.66427), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.67702)}\n",
            "Step 10220: {'train_ae_loss': np.float64(0.68664), 'train_ucc_loss': np.float64(0.58872), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.63768)}\n",
            "Step 10240: {'train_ae_loss': np.float64(0.68681), 'train_ucc_loss': np.float64(0.63816), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.66248)}\n",
            "Step 10260: {'train_ae_loss': np.float64(0.68285), 'train_ucc_loss': np.float64(0.63654), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.6597)}\n",
            "Step 10280: {'train_ae_loss': np.float64(0.6808), 'train_ucc_loss': np.float64(0.58552), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.63316)}\n",
            "Step 10300: {'train_ae_loss': np.float64(0.69906), 'train_ucc_loss': np.float64(0.63905), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.66906)}\n",
            "Step 10320: {'train_ae_loss': np.float64(0.71616), 'train_ucc_loss': np.float64(0.69448), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.70532)}\n",
            "Step 10340: {'train_ae_loss': np.float64(0.71931), 'train_ucc_loss': np.float64(0.61057), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.66494)}\n",
            "Step 10360: {'train_ae_loss': np.float64(0.68566), 'train_ucc_loss': np.float64(0.58399), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.63482)}\n",
            "Step 10380: {'train_ae_loss': np.float64(0.71373), 'train_ucc_loss': np.float64(0.65426), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.684)}\n",
            "Step 10400: {'train_ae_loss': np.float64(0.7045), 'train_ucc_loss': np.float64(0.65407), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67928)}\n",
            "Step 10420: {'train_ae_loss': np.float64(0.6791), 'train_ucc_loss': np.float64(0.64688), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66299)}\n",
            "Step 10440: {'train_ae_loss': np.float64(0.68903), 'train_ucc_loss': np.float64(0.67469), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68186)}\n",
            "Step 10460: {'train_ae_loss': np.float64(0.68247), 'train_ucc_loss': np.float64(0.6049), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.64369)}\n",
            "Step 10480: {'train_ae_loss': np.float64(0.69119), 'train_ucc_loss': np.float64(0.70787), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.69953)}\n",
            "Step 10500: {'train_ae_loss': np.float64(0.69655), 'train_ucc_loss': np.float64(0.71771), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.70713)}\n",
            "Step 10520: {'train_ae_loss': np.float64(0.70883), 'train_ucc_loss': np.float64(0.70017), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.7045)}\n",
            "Step 10540: {'train_ae_loss': np.float64(0.6828), 'train_ucc_loss': np.float64(0.60633), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.64457)}\n",
            "Step 10560: {'train_ae_loss': np.float64(0.68785), 'train_ucc_loss': np.float64(0.76763), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.72774)}\n",
            "Step 10580: {'train_ae_loss': np.float64(0.69086), 'train_ucc_loss': np.float64(0.69604), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.69345)}\n",
            "Step 10600: {'train_ae_loss': np.float64(0.70603), 'train_ucc_loss': np.float64(0.59382), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.64993)}\n",
            "Step 10620: {'train_ae_loss': np.float64(0.69012), 'train_ucc_loss': np.float64(0.65278), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.67145)}\n",
            "Step 10640: {'train_ae_loss': np.float64(0.68904), 'train_ucc_loss': np.float64(0.65173), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67039)}\n",
            "Step 10660: {'train_ae_loss': np.float64(0.71211), 'train_ucc_loss': np.float64(0.65178), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.68194)}\n",
            "Step 10680: {'train_ae_loss': np.float64(0.69722), 'train_ucc_loss': np.float64(0.65362), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67542)}\n",
            "Step 10700: {'train_ae_loss': np.float64(0.69504), 'train_ucc_loss': np.float64(0.58932), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.64218)}\n",
            "Step 10720: {'train_ae_loss': np.float64(0.69574), 'train_ucc_loss': np.float64(0.67969), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.68771)}\n",
            "Step 10740: {'train_ae_loss': np.float64(0.68858), 'train_ucc_loss': np.float64(0.65659), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67259)}\n",
            "Step 10760: {'train_ae_loss': np.float64(0.69463), 'train_ucc_loss': np.float64(0.64904), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67184)}\n",
            "Step 10780: {'train_ae_loss': np.float64(0.68205), 'train_ucc_loss': np.float64(0.64781), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.66493)}\n",
            "Step 10800: {'train_ae_loss': np.float64(0.70047), 'train_ucc_loss': np.float64(0.69152), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.69599)}\n",
            "Step 10820: {'train_ae_loss': np.float64(0.6869), 'train_ucc_loss': np.float64(0.68462), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.68576)}\n",
            "Step 10840: {'train_ae_loss': np.float64(0.6885), 'train_ucc_loss': np.float64(0.64152), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.66501)}\n",
            "Step 10860: {'train_ae_loss': np.float64(0.70544), 'train_ucc_loss': np.float64(0.7053), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.70537)}\n",
            "Step 10880: {'train_ae_loss': np.float64(0.70323), 'train_ucc_loss': np.float64(0.65556), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.6794)}\n",
            "Step 10900: {'train_ae_loss': np.float64(0.69401), 'train_ucc_loss': np.float64(0.59296), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.64348)}\n",
            "Step 10920: {'train_ae_loss': np.float64(0.69296), 'train_ucc_loss': np.float64(0.62578), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65937)}\n",
            "Step 10940: {'train_ae_loss': np.float64(0.71287), 'train_ucc_loss': np.float64(0.61593), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.6644)}\n",
            "Step 10960: {'train_ae_loss': np.float64(0.71097), 'train_ucc_loss': np.float64(0.62393), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.66745)}\n",
            "Step 10980: {'train_ae_loss': np.float64(0.71124), 'train_ucc_loss': np.float64(0.58978), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.65051)}\n",
            "Step 11000: {'train_ae_loss': np.float64(0.69143), 'train_ucc_loss': np.float64(0.59855), 'train_ucc_acc': np.float64(0.8125), 'loss': np.float64(0.64499)}\n",
            "step: 11000,eval_ae_loss: 0.68789,eval_ucc_loss: 0.67446,eval_ucc_acc: 0.58105\n",
            "Step 11020: {'train_ae_loss': np.float64(0.70101), 'train_ucc_loss': np.float64(0.65978), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.6804)}\n",
            "Step 11040: {'train_ae_loss': np.float64(0.67704), 'train_ucc_loss': np.float64(0.65099), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.66402)}\n",
            "Step 11060: {'train_ae_loss': np.float64(0.69729), 'train_ucc_loss': np.float64(0.67031), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.6838)}\n",
            "Step 11080: {'train_ae_loss': np.float64(0.70012), 'train_ucc_loss': np.float64(0.66122), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68067)}\n",
            "Step 11100: {'train_ae_loss': np.float64(0.69272), 'train_ucc_loss': np.float64(0.63188), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.6623)}\n",
            "Step 11120: {'train_ae_loss': np.float64(0.70388), 'train_ucc_loss': np.float64(0.66391), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.68389)}\n",
            "Step 11140: {'train_ae_loss': np.float64(0.6956), 'train_ucc_loss': np.float64(0.56387), 'train_ucc_acc': np.float64(0.84375), 'loss': np.float64(0.62973)}\n",
            "Step 11160: {'train_ae_loss': np.float64(0.6826), 'train_ucc_loss': np.float64(0.69813), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.69036)}\n",
            "Step 11180: {'train_ae_loss': np.float64(0.68237), 'train_ucc_loss': np.float64(0.64005), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.66121)}\n",
            "Step 11200: {'train_ae_loss': np.float64(0.69192), 'train_ucc_loss': np.float64(0.71342), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.70267)}\n",
            "Step 11220: {'train_ae_loss': np.float64(0.68483), 'train_ucc_loss': np.float64(0.65535), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67009)}\n",
            "Step 11240: {'train_ae_loss': np.float64(0.70626), 'train_ucc_loss': np.float64(0.75194), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.7291)}\n",
            "Step 11260: {'train_ae_loss': np.float64(0.69654), 'train_ucc_loss': np.float64(0.5959), 'train_ucc_acc': np.float64(0.8125), 'loss': np.float64(0.64622)}\n",
            "Step 11280: {'train_ae_loss': np.float64(0.7114), 'train_ucc_loss': np.float64(0.59882), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65511)}\n",
            "Step 11300: {'train_ae_loss': np.float64(0.68563), 'train_ucc_loss': np.float64(0.65913), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.67238)}\n",
            "Step 11320: {'train_ae_loss': np.float64(0.67961), 'train_ucc_loss': np.float64(0.62515), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.65238)}\n",
            "Step 11340: {'train_ae_loss': np.float64(0.70461), 'train_ucc_loss': np.float64(0.64579), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.6752)}\n",
            "Step 11360: {'train_ae_loss': np.float64(0.68444), 'train_ucc_loss': np.float64(0.59918), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.64181)}\n",
            "Step 11380: {'train_ae_loss': np.float64(0.69356), 'train_ucc_loss': np.float64(0.58042), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.63699)}\n",
            "Step 11400: {'train_ae_loss': np.float64(0.68771), 'train_ucc_loss': np.float64(0.6974), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.69256)}\n",
            "Step 11420: {'train_ae_loss': np.float64(0.68555), 'train_ucc_loss': np.float64(0.68314), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68434)}\n",
            "Step 11440: {'train_ae_loss': np.float64(0.69091), 'train_ucc_loss': np.float64(0.65241), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67166)}\n",
            "Step 11460: {'train_ae_loss': np.float64(0.70101), 'train_ucc_loss': np.float64(0.69335), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.69718)}\n",
            "Step 11480: {'train_ae_loss': np.float64(0.68303), 'train_ucc_loss': np.float64(0.57275), 'train_ucc_acc': np.float64(0.84375), 'loss': np.float64(0.62789)}\n",
            "Step 11500: {'train_ae_loss': np.float64(0.68178), 'train_ucc_loss': np.float64(0.65303), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66741)}\n",
            "Step 11520: {'train_ae_loss': np.float64(0.70476), 'train_ucc_loss': np.float64(0.57735), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.64106)}\n",
            "Step 11540: {'train_ae_loss': np.float64(0.68549), 'train_ucc_loss': np.float64(0.64423), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.66486)}\n",
            "Step 11560: {'train_ae_loss': np.float64(0.70314), 'train_ucc_loss': np.float64(0.66352), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68333)}\n",
            "Step 11580: {'train_ae_loss': np.float64(0.69536), 'train_ucc_loss': np.float64(0.6697), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.68253)}\n",
            "Step 11600: {'train_ae_loss': np.float64(0.69349), 'train_ucc_loss': np.float64(0.65487), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67418)}\n",
            "Step 11620: {'train_ae_loss': np.float64(0.69564), 'train_ucc_loss': np.float64(0.68174), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68869)}\n",
            "Step 11640: {'train_ae_loss': np.float64(0.70235), 'train_ucc_loss': np.float64(0.6023), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65233)}\n",
            "Step 11660: {'train_ae_loss': np.float64(0.7139), 'train_ucc_loss': np.float64(0.66304), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68847)}\n",
            "Step 11680: {'train_ae_loss': np.float64(0.69971), 'train_ucc_loss': np.float64(0.62472), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.66221)}\n",
            "Step 11700: {'train_ae_loss': np.float64(0.70019), 'train_ucc_loss': np.float64(0.65589), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67804)}\n",
            "Step 11720: {'train_ae_loss': np.float64(0.69627), 'train_ucc_loss': np.float64(0.65167), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67397)}\n",
            "Step 11740: {'train_ae_loss': np.float64(0.71578), 'train_ucc_loss': np.float64(0.67032), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.69305)}\n",
            "Step 11760: {'train_ae_loss': np.float64(0.70199), 'train_ucc_loss': np.float64(0.60338), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65269)}\n",
            "Step 11780: {'train_ae_loss': np.float64(0.70908), 'train_ucc_loss': np.float64(0.6565), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.68279)}\n",
            "Step 11800: {'train_ae_loss': np.float64(0.70331), 'train_ucc_loss': np.float64(0.6745), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.6889)}\n",
            "Step 11820: {'train_ae_loss': np.float64(0.70249), 'train_ucc_loss': np.float64(0.60577), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65413)}\n",
            "Step 11840: {'train_ae_loss': np.float64(0.70845), 'train_ucc_loss': np.float64(0.63216), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.67031)}\n",
            "Step 11860: {'train_ae_loss': np.float64(0.6936), 'train_ucc_loss': np.float64(0.66278), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67819)}\n",
            "Step 11880: {'train_ae_loss': np.float64(0.69321), 'train_ucc_loss': np.float64(0.79065), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.74193)}\n",
            "Step 11900: {'train_ae_loss': np.float64(0.70029), 'train_ucc_loss': np.float64(0.57864), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.63946)}\n",
            "Step 11920: {'train_ae_loss': np.float64(0.69523), 'train_ucc_loss': np.float64(0.67826), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.68675)}\n",
            "Step 11940: {'train_ae_loss': np.float64(0.68175), 'train_ucc_loss': np.float64(0.6357), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.65873)}\n",
            "Step 11960: {'train_ae_loss': np.float64(0.6737), 'train_ucc_loss': np.float64(0.72713), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.70042)}\n",
            "Step 11980: {'train_ae_loss': np.float64(0.69775), 'train_ucc_loss': np.float64(0.61817), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.65796)}\n",
            "Step 12000: {'train_ae_loss': np.float64(0.67931), 'train_ucc_loss': np.float64(0.59497), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.63714)}\n",
            "step: 12000,eval_ae_loss: 0.6877,eval_ucc_loss: 0.67442,eval_ucc_acc: 0.5625\n",
            "Step 12020: {'train_ae_loss': np.float64(0.6789), 'train_ucc_loss': np.float64(0.59111), 'train_ucc_acc': np.float64(0.84375), 'loss': np.float64(0.63501)}\n",
            "Step 12040: {'train_ae_loss': np.float64(0.69021), 'train_ucc_loss': np.float64(0.67337), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68179)}\n",
            "Step 12060: {'train_ae_loss': np.float64(0.7137), 'train_ucc_loss': np.float64(0.62372), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.66871)}\n",
            "Step 12080: {'train_ae_loss': np.float64(0.69237), 'train_ucc_loss': np.float64(0.72776), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71007)}\n",
            "Step 12100: {'train_ae_loss': np.float64(0.7106), 'train_ucc_loss': np.float64(0.71184), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.71122)}\n",
            "Step 12120: {'train_ae_loss': np.float64(0.69349), 'train_ucc_loss': np.float64(0.70559), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.69954)}\n",
            "Step 12140: {'train_ae_loss': np.float64(0.68605), 'train_ucc_loss': np.float64(0.65497), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.67051)}\n",
            "Step 12160: {'train_ae_loss': np.float64(0.67635), 'train_ucc_loss': np.float64(0.78403), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.73019)}\n",
            "Step 12180: {'train_ae_loss': np.float64(0.69468), 'train_ucc_loss': np.float64(0.57882), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.63675)}\n",
            "Step 12200: {'train_ae_loss': np.float64(0.6951), 'train_ucc_loss': np.float64(0.6433), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.6692)}\n",
            "Step 12220: {'train_ae_loss': np.float64(0.694), 'train_ucc_loss': np.float64(0.68832), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.69116)}\n",
            "Step 12240: {'train_ae_loss': np.float64(0.66966), 'train_ucc_loss': np.float64(0.66075), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.6652)}\n",
            "Step 12260: {'train_ae_loss': np.float64(0.70667), 'train_ucc_loss': np.float64(0.66211), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.68439)}\n",
            "Step 12280: {'train_ae_loss': np.float64(0.67461), 'train_ucc_loss': np.float64(0.727), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.7008)}\n",
            "Step 12300: {'train_ae_loss': np.float64(0.70236), 'train_ucc_loss': np.float64(0.64088), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.67162)}\n",
            "Step 12320: {'train_ae_loss': np.float64(0.6916), 'train_ucc_loss': np.float64(0.58066), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.63613)}\n",
            "Step 12340: {'train_ae_loss': np.float64(0.69461), 'train_ucc_loss': np.float64(0.66002), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67732)}\n",
            "Step 12360: {'train_ae_loss': np.float64(0.70978), 'train_ucc_loss': np.float64(0.6079), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65884)}\n",
            "Step 12380: {'train_ae_loss': np.float64(0.69327), 'train_ucc_loss': np.float64(0.65815), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.67571)}\n",
            "Step 12400: {'train_ae_loss': np.float64(0.69039), 'train_ucc_loss': np.float64(0.67249), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.68144)}\n",
            "Step 12420: {'train_ae_loss': np.float64(0.68655), 'train_ucc_loss': np.float64(0.61967), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.65311)}\n",
            "Step 12440: {'train_ae_loss': np.float64(0.68753), 'train_ucc_loss': np.float64(0.72465), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.70609)}\n",
            "Step 12460: {'train_ae_loss': np.float64(0.70078), 'train_ucc_loss': np.float64(0.64854), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.67466)}\n",
            "Step 12480: {'train_ae_loss': np.float64(0.69078), 'train_ucc_loss': np.float64(0.64723), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.669)}\n",
            "Step 12500: {'train_ae_loss': np.float64(0.70948), 'train_ucc_loss': np.float64(0.5724), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.64094)}\n",
            "Step 12520: {'train_ae_loss': np.float64(0.69409), 'train_ucc_loss': np.float64(0.68043), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.68726)}\n",
            "Step 12540: {'train_ae_loss': np.float64(0.68672), 'train_ucc_loss': np.float64(0.63257), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.65964)}\n",
            "Step 12560: {'train_ae_loss': np.float64(0.70854), 'train_ucc_loss': np.float64(0.5882), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.64837)}\n",
            "Step 12580: {'train_ae_loss': np.float64(0.68087), 'train_ucc_loss': np.float64(0.71681), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.69884)}\n",
            "Step 12600: {'train_ae_loss': np.float64(0.7051), 'train_ucc_loss': np.float64(0.7105), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.7078)}\n",
            "Step 12620: {'train_ae_loss': np.float64(0.69417), 'train_ucc_loss': np.float64(0.65026), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.67221)}\n",
            "Step 12640: {'train_ae_loss': np.float64(0.68507), 'train_ucc_loss': np.float64(0.72332), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.7042)}\n",
            "Step 12660: {'train_ae_loss': np.float64(0.67538), 'train_ucc_loss': np.float64(0.64653), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.66096)}\n",
            "Step 12680: {'train_ae_loss': np.float64(0.6996), 'train_ucc_loss': np.float64(0.54639), 'train_ucc_acc': np.float64(0.84375), 'loss': np.float64(0.623)}\n",
            "Step 12700: {'train_ae_loss': np.float64(0.67773), 'train_ucc_loss': np.float64(0.58802), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.63287)}\n",
            "Step 12720: {'train_ae_loss': np.float64(0.67739), 'train_ucc_loss': np.float64(0.63479), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.65609)}\n",
            "Step 12740: {'train_ae_loss': np.float64(0.70264), 'train_ucc_loss': np.float64(0.7883), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.74547)}\n",
            "Step 12760: {'train_ae_loss': np.float64(0.69428), 'train_ucc_loss': np.float64(0.68562), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.68995)}\n",
            "Step 12780: {'train_ae_loss': np.float64(0.69305), 'train_ucc_loss': np.float64(0.65319), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.67312)}\n",
            "Step 12800: {'train_ae_loss': np.float64(0.70083), 'train_ucc_loss': np.float64(0.67504), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68794)}\n",
            "Step 12820: {'train_ae_loss': np.float64(0.69659), 'train_ucc_loss': np.float64(0.58804), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.64231)}\n",
            "Step 12840: {'train_ae_loss': np.float64(0.68855), 'train_ucc_loss': np.float64(0.58712), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.63784)}\n",
            "Step 12860: {'train_ae_loss': np.float64(0.69442), 'train_ucc_loss': np.float64(0.67211), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.68327)}\n",
            "Step 12880: {'train_ae_loss': np.float64(0.68718), 'train_ucc_loss': np.float64(0.67618), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68168)}\n",
            "Step 12900: {'train_ae_loss': np.float64(0.69319), 'train_ucc_loss': np.float64(0.61099), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65209)}\n",
            "Step 12920: {'train_ae_loss': np.float64(0.69041), 'train_ucc_loss': np.float64(0.5846), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.6375)}\n",
            "Step 12940: {'train_ae_loss': np.float64(0.68595), 'train_ucc_loss': np.float64(0.58341), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.63468)}\n",
            "Step 12960: {'train_ae_loss': np.float64(0.67575), 'train_ucc_loss': np.float64(0.66282), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66928)}\n",
            "Step 12980: {'train_ae_loss': np.float64(0.69012), 'train_ucc_loss': np.float64(0.61837), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.65424)}\n",
            "Step 13000: {'train_ae_loss': np.float64(0.72639), 'train_ucc_loss': np.float64(0.66088), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.69363)}\n",
            "step: 13000,eval_ae_loss: 0.68478,eval_ucc_loss: 0.6708,eval_ucc_acc: 0.57227\n",
            "Step 13020: {'train_ae_loss': np.float64(0.68072), 'train_ucc_loss': np.float64(0.62321), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65197)}\n",
            "Step 13040: {'train_ae_loss': np.float64(0.67669), 'train_ucc_loss': np.float64(0.61994), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.64831)}\n",
            "Step 13060: {'train_ae_loss': np.float64(0.68309), 'train_ucc_loss': np.float64(0.74741), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.71525)}\n",
            "Step 13080: {'train_ae_loss': np.float64(0.69797), 'train_ucc_loss': np.float64(0.64825), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.67311)}\n",
            "Step 13100: {'train_ae_loss': np.float64(0.69235), 'train_ucc_loss': np.float64(0.6523), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.67233)}\n",
            "Step 13120: {'train_ae_loss': np.float64(0.68758), 'train_ucc_loss': np.float64(0.67633), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.68195)}\n",
            "Step 13140: {'train_ae_loss': np.float64(0.69901), 'train_ucc_loss': np.float64(0.79152), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.74527)}\n",
            "Step 13160: {'train_ae_loss': np.float64(0.7037), 'train_ucc_loss': np.float64(0.60093), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.65232)}\n",
            "Step 13180: {'train_ae_loss': np.float64(0.68071), 'train_ucc_loss': np.float64(0.64319), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.66195)}\n",
            "Step 13200: {'train_ae_loss': np.float64(0.69136), 'train_ucc_loss': np.float64(0.6289), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66013)}\n",
            "Step 13220: {'train_ae_loss': np.float64(0.68652), 'train_ucc_loss': np.float64(0.6116), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.64906)}\n",
            "Step 13240: {'train_ae_loss': np.float64(0.69755), 'train_ucc_loss': np.float64(0.68699), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.69227)}\n",
            "Step 13260: {'train_ae_loss': np.float64(0.68683), 'train_ucc_loss': np.float64(0.66248), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67465)}\n",
            "Step 13280: {'train_ae_loss': np.float64(0.69742), 'train_ucc_loss': np.float64(0.59864), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.64803)}\n",
            "Step 13300: {'train_ae_loss': np.float64(0.69121), 'train_ucc_loss': np.float64(0.58739), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.6393)}\n",
            "Step 13320: {'train_ae_loss': np.float64(0.69469), 'train_ucc_loss': np.float64(0.5984), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.64654)}\n",
            "Step 13340: {'train_ae_loss': np.float64(0.69553), 'train_ucc_loss': np.float64(0.7118), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.70366)}\n",
            "Step 13360: {'train_ae_loss': np.float64(0.67678), 'train_ucc_loss': np.float64(0.58151), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.62915)}\n",
            "Step 13380: {'train_ae_loss': np.float64(0.68787), 'train_ucc_loss': np.float64(0.70513), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.6965)}\n",
            "Step 13400: {'train_ae_loss': np.float64(0.70513), 'train_ucc_loss': np.float64(0.67245), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.68879)}\n",
            "Step 13420: {'train_ae_loss': np.float64(0.67531), 'train_ucc_loss': np.float64(0.65224), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66377)}\n",
            "Step 13440: {'train_ae_loss': np.float64(0.68678), 'train_ucc_loss': np.float64(0.64044), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66361)}\n",
            "Step 13460: {'train_ae_loss': np.float64(0.68567), 'train_ucc_loss': np.float64(0.66052), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.67309)}\n",
            "Step 13480: {'train_ae_loss': np.float64(0.69625), 'train_ucc_loss': np.float64(0.58572), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.64098)}\n",
            "Step 13500: {'train_ae_loss': np.float64(0.69074), 'train_ucc_loss': np.float64(0.72143), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.70609)}\n",
            "Step 13520: {'train_ae_loss': np.float64(0.6906), 'train_ucc_loss': np.float64(0.65551), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67305)}\n",
            "Step 13540: {'train_ae_loss': np.float64(0.68926), 'train_ucc_loss': np.float64(0.63731), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66329)}\n",
            "Step 13560: {'train_ae_loss': np.float64(0.68968), 'train_ucc_loss': np.float64(0.76638), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.72803)}\n",
            "Step 13580: {'train_ae_loss': np.float64(0.67519), 'train_ucc_loss': np.float64(0.70641), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.6908)}\n",
            "Step 13600: {'train_ae_loss': np.float64(0.67366), 'train_ucc_loss': np.float64(0.63477), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.65421)}\n",
            "Step 13620: {'train_ae_loss': np.float64(0.67793), 'train_ucc_loss': np.float64(0.67048), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67421)}\n",
            "Step 13640: {'train_ae_loss': np.float64(0.68374), 'train_ucc_loss': np.float64(0.58982), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.63678)}\n",
            "Step 13660: {'train_ae_loss': np.float64(0.70834), 'train_ucc_loss': np.float64(0.666), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.68717)}\n",
            "Step 13680: {'train_ae_loss': np.float64(0.67792), 'train_ucc_loss': np.float64(0.73959), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.70876)}\n",
            "Step 13700: {'train_ae_loss': np.float64(0.67906), 'train_ucc_loss': np.float64(0.6248), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65193)}\n",
            "Step 13720: {'train_ae_loss': np.float64(0.6881), 'train_ucc_loss': np.float64(0.67215), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.68012)}\n",
            "Step 13740: {'train_ae_loss': np.float64(0.67924), 'train_ucc_loss': np.float64(0.61221), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.64572)}\n",
            "Step 13760: {'train_ae_loss': np.float64(0.68189), 'train_ucc_loss': np.float64(0.62068), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65128)}\n",
            "Step 13780: {'train_ae_loss': np.float64(0.68662), 'train_ucc_loss': np.float64(0.64849), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.66756)}\n",
            "Step 13800: {'train_ae_loss': np.float64(0.69463), 'train_ucc_loss': np.float64(0.63168), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.66316)}\n",
            "Step 13820: {'train_ae_loss': np.float64(0.68871), 'train_ucc_loss': np.float64(0.65425), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67148)}\n",
            "Step 13840: {'train_ae_loss': np.float64(0.6865), 'train_ucc_loss': np.float64(0.60957), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.64803)}\n",
            "Step 13860: {'train_ae_loss': np.float64(0.69712), 'train_ucc_loss': np.float64(0.54984), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.62348)}\n",
            "Step 13880: {'train_ae_loss': np.float64(0.69341), 'train_ucc_loss': np.float64(0.63144), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.66243)}\n",
            "Step 13900: {'train_ae_loss': np.float64(0.70084), 'train_ucc_loss': np.float64(0.72825), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71454)}\n",
            "Step 13920: {'train_ae_loss': np.float64(0.6812), 'train_ucc_loss': np.float64(0.68124), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68122)}\n",
            "Step 13940: {'train_ae_loss': np.float64(0.67529), 'train_ucc_loss': np.float64(0.62779), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.65154)}\n",
            "Step 13960: {'train_ae_loss': np.float64(0.68692), 'train_ucc_loss': np.float64(0.6117), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.64931)}\n",
            "Step 13980: {'train_ae_loss': np.float64(0.6927), 'train_ucc_loss': np.float64(0.61117), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.65194)}\n",
            "Step 14000: {'train_ae_loss': np.float64(0.70031), 'train_ucc_loss': np.float64(0.70033), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.70032)}\n",
            "step: 14000,eval_ae_loss: 0.68567,eval_ucc_loss: 0.68594,eval_ucc_acc: 0.55078\n",
            "Step 14020: {'train_ae_loss': np.float64(0.67914), 'train_ucc_loss': np.float64(0.69806), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.6886)}\n",
            "Step 14040: {'train_ae_loss': np.float64(0.69369), 'train_ucc_loss': np.float64(0.60608), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.64989)}\n",
            "Step 14060: {'train_ae_loss': np.float64(0.70711), 'train_ucc_loss': np.float64(0.6291), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66811)}\n",
            "Step 14080: {'train_ae_loss': np.float64(0.69292), 'train_ucc_loss': np.float64(0.58391), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.63842)}\n",
            "Step 14100: {'train_ae_loss': np.float64(0.69648), 'train_ucc_loss': np.float64(0.57169), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.63408)}\n",
            "Step 14120: {'train_ae_loss': np.float64(0.68873), 'train_ucc_loss': np.float64(0.61927), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.654)}\n",
            "Step 14140: {'train_ae_loss': np.float64(0.70699), 'train_ucc_loss': np.float64(0.57146), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.63923)}\n",
            "Step 14160: {'train_ae_loss': np.float64(0.68313), 'train_ucc_loss': np.float64(0.67115), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.67714)}\n",
            "Step 14180: {'train_ae_loss': np.float64(0.69996), 'train_ucc_loss': np.float64(0.56902), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.63449)}\n",
            "Step 14200: {'train_ae_loss': np.float64(0.67743), 'train_ucc_loss': np.float64(0.62824), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.65284)}\n",
            "Step 14220: {'train_ae_loss': np.float64(0.69649), 'train_ucc_loss': np.float64(0.58533), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.64091)}\n",
            "Step 14240: {'train_ae_loss': np.float64(0.68839), 'train_ucc_loss': np.float64(0.65821), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.6733)}\n",
            "Step 14260: {'train_ae_loss': np.float64(0.68869), 'train_ucc_loss': np.float64(0.66037), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.67453)}\n",
            "Step 14280: {'train_ae_loss': np.float64(0.66848), 'train_ucc_loss': np.float64(0.61195), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.64022)}\n",
            "Step 14300: {'train_ae_loss': np.float64(0.68069), 'train_ucc_loss': np.float64(0.58869), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.63469)}\n",
            "Step 14320: {'train_ae_loss': np.float64(0.68314), 'train_ucc_loss': np.float64(0.64244), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.66279)}\n",
            "Step 14340: {'train_ae_loss': np.float64(0.69246), 'train_ucc_loss': np.float64(0.60052), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.64649)}\n",
            "Step 14360: {'train_ae_loss': np.float64(0.68378), 'train_ucc_loss': np.float64(0.54786), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.61582)}\n",
            "Step 14380: {'train_ae_loss': np.float64(0.6945), 'train_ucc_loss': np.float64(0.70116), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.69783)}\n",
            "Step 14400: {'train_ae_loss': np.float64(0.67929), 'train_ucc_loss': np.float64(0.61755), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.64842)}\n",
            "Step 14420: {'train_ae_loss': np.float64(0.70242), 'train_ucc_loss': np.float64(0.61808), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.66025)}\n",
            "Step 14440: {'train_ae_loss': np.float64(0.66616), 'train_ucc_loss': np.float64(0.72473), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.69545)}\n",
            "Step 14460: {'train_ae_loss': np.float64(0.67882), 'train_ucc_loss': np.float64(0.65375), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66629)}\n",
            "Step 14480: {'train_ae_loss': np.float64(0.68303), 'train_ucc_loss': np.float64(0.64056), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.6618)}\n",
            "Step 14500: {'train_ae_loss': np.float64(0.68666), 'train_ucc_loss': np.float64(0.60168), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.64417)}\n",
            "Step 14520: {'train_ae_loss': np.float64(0.68224), 'train_ucc_loss': np.float64(0.65077), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66651)}\n",
            "Step 14540: {'train_ae_loss': np.float64(0.68928), 'train_ucc_loss': np.float64(0.61648), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.65288)}\n",
            "Step 14560: {'train_ae_loss': np.float64(0.68859), 'train_ucc_loss': np.float64(0.63524), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.66192)}\n",
            "Step 14580: {'train_ae_loss': np.float64(0.69563), 'train_ucc_loss': np.float64(0.63509), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66536)}\n",
            "Step 14600: {'train_ae_loss': np.float64(0.70084), 'train_ucc_loss': np.float64(0.62058), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66071)}\n",
            "Step 14620: {'train_ae_loss': np.float64(0.67938), 'train_ucc_loss': np.float64(0.61666), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.64802)}\n",
            "Step 14640: {'train_ae_loss': np.float64(0.68694), 'train_ucc_loss': np.float64(0.69019), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68856)}\n",
            "Step 14660: {'train_ae_loss': np.float64(0.68846), 'train_ucc_loss': np.float64(0.74326), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71586)}\n",
            "Step 14680: {'train_ae_loss': np.float64(0.69318), 'train_ucc_loss': np.float64(0.64368), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.66843)}\n",
            "Step 14700: {'train_ae_loss': np.float64(0.68686), 'train_ucc_loss': np.float64(0.61976), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.65331)}\n",
            "Step 14720: {'train_ae_loss': np.float64(0.67205), 'train_ucc_loss': np.float64(0.72518), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.69862)}\n",
            "Step 14740: {'train_ae_loss': np.float64(0.69796), 'train_ucc_loss': np.float64(0.6036), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.65078)}\n",
            "Step 14760: {'train_ae_loss': np.float64(0.6878), 'train_ucc_loss': np.float64(0.624), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.6559)}\n",
            "Step 14780: {'train_ae_loss': np.float64(0.71614), 'train_ucc_loss': np.float64(0.62851), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67233)}\n",
            "Step 14800: {'train_ae_loss': np.float64(0.70391), 'train_ucc_loss': np.float64(0.58017), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.64204)}\n",
            "Step 14820: {'train_ae_loss': np.float64(0.67933), 'train_ucc_loss': np.float64(0.66276), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67104)}\n",
            "Step 14840: {'train_ae_loss': np.float64(0.67078), 'train_ucc_loss': np.float64(0.60133), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.63606)}\n",
            "Step 14860: {'train_ae_loss': np.float64(0.68103), 'train_ucc_loss': np.float64(0.65827), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.66965)}\n",
            "Step 14880: {'train_ae_loss': np.float64(0.69349), 'train_ucc_loss': np.float64(0.69951), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.6965)}\n",
            "Step 14900: {'train_ae_loss': np.float64(0.68078), 'train_ucc_loss': np.float64(0.62408), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65243)}\n",
            "Step 14920: {'train_ae_loss': np.float64(0.68045), 'train_ucc_loss': np.float64(0.65531), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66788)}\n",
            "Step 14940: {'train_ae_loss': np.float64(0.6863), 'train_ucc_loss': np.float64(0.65209), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.6692)}\n",
            "Step 14960: {'train_ae_loss': np.float64(0.68013), 'train_ucc_loss': np.float64(0.47712), 'train_ucc_acc': np.float64(0.875), 'loss': np.float64(0.57862)}\n",
            "Step 14980: {'train_ae_loss': np.float64(0.67283), 'train_ucc_loss': np.float64(0.65139), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.66211)}\n",
            "Step 15000: {'train_ae_loss': np.float64(0.67803), 'train_ucc_loss': np.float64(0.75124), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.71464)}\n",
            "step: 15000,eval_ae_loss: 0.67753,eval_ucc_loss: 0.67185,eval_ucc_acc: 0.63867\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/09/02 23:59:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step 15020: {'train_ae_loss': np.float64(0.70253), 'train_ucc_loss': np.float64(0.62914), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.66584)}\n",
            "Step 15040: {'train_ae_loss': np.float64(0.68516), 'train_ucc_loss': np.float64(0.69021), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.68768)}\n",
            "Step 15060: {'train_ae_loss': np.float64(0.69925), 'train_ucc_loss': np.float64(0.63993), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.66959)}\n",
            "Step 15080: {'train_ae_loss': np.float64(0.70433), 'train_ucc_loss': np.float64(0.65919), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.68176)}\n",
            "Step 15100: {'train_ae_loss': np.float64(0.71064), 'train_ucc_loss': np.float64(0.6459), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67827)}\n",
            "Step 15120: {'train_ae_loss': np.float64(0.69243), 'train_ucc_loss': np.float64(0.61828), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.65535)}\n",
            "Step 15140: {'train_ae_loss': np.float64(0.67891), 'train_ucc_loss': np.float64(0.60615), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.64253)}\n",
            "Step 15160: {'train_ae_loss': np.float64(0.68298), 'train_ucc_loss': np.float64(0.65564), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.66931)}\n",
            "Step 15180: {'train_ae_loss': np.float64(0.66879), 'train_ucc_loss': np.float64(0.62246), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.64562)}\n",
            "Step 15200: {'train_ae_loss': np.float64(0.68905), 'train_ucc_loss': np.float64(0.64353), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.66629)}\n",
            "Step 15220: {'train_ae_loss': np.float64(0.68404), 'train_ucc_loss': np.float64(0.64123), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.66263)}\n",
            "Step 15240: {'train_ae_loss': np.float64(0.69942), 'train_ucc_loss': np.float64(0.60085), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.65014)}\n",
            "Step 15260: {'train_ae_loss': np.float64(0.69064), 'train_ucc_loss': np.float64(0.59642), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.64353)}\n",
            "Step 15280: {'train_ae_loss': np.float64(0.70786), 'train_ucc_loss': np.float64(0.63572), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67179)}\n",
            "Step 15300: {'train_ae_loss': np.float64(0.69104), 'train_ucc_loss': np.float64(0.6266), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65882)}\n",
            "Step 15320: {'train_ae_loss': np.float64(0.6974), 'train_ucc_loss': np.float64(0.7027), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.70005)}\n",
            "Step 15340: {'train_ae_loss': np.float64(0.71359), 'train_ucc_loss': np.float64(0.64795), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.68077)}\n",
            "Step 15360: {'train_ae_loss': np.float64(0.68911), 'train_ucc_loss': np.float64(0.51253), 'train_ucc_acc': np.float64(0.8125), 'loss': np.float64(0.60082)}\n",
            "Step 15380: {'train_ae_loss': np.float64(0.69013), 'train_ucc_loss': np.float64(0.64201), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66607)}\n",
            "Step 15400: {'train_ae_loss': np.float64(0.67979), 'train_ucc_loss': np.float64(0.72962), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.70471)}\n",
            "Step 15420: {'train_ae_loss': np.float64(0.68361), 'train_ucc_loss': np.float64(0.5994), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.6415)}\n",
            "Step 15440: {'train_ae_loss': np.float64(0.69155), 'train_ucc_loss': np.float64(0.59113), 'train_ucc_acc': np.float64(0.8125), 'loss': np.float64(0.64134)}\n",
            "Step 15460: {'train_ae_loss': np.float64(0.69623), 'train_ucc_loss': np.float64(0.64169), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.66896)}\n",
            "Step 15480: {'train_ae_loss': np.float64(0.69222), 'train_ucc_loss': np.float64(0.60488), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.64855)}\n",
            "Step 15500: {'train_ae_loss': np.float64(0.68486), 'train_ucc_loss': np.float64(0.66258), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.67372)}\n",
            "Step 15520: {'train_ae_loss': np.float64(0.69027), 'train_ucc_loss': np.float64(0.68683), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.68855)}\n",
            "Step 15540: {'train_ae_loss': np.float64(0.69213), 'train_ucc_loss': np.float64(0.67077), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.68145)}\n",
            "Step 15560: {'train_ae_loss': np.float64(0.69004), 'train_ucc_loss': np.float64(0.65572), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67288)}\n",
            "Step 15580: {'train_ae_loss': np.float64(0.6943), 'train_ucc_loss': np.float64(0.62454), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65942)}\n",
            "Step 15600: {'train_ae_loss': np.float64(0.6986), 'train_ucc_loss': np.float64(0.59043), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.64451)}\n",
            "Step 15620: {'train_ae_loss': np.float64(0.7049), 'train_ucc_loss': np.float64(0.59039), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.64764)}\n",
            "Step 15640: {'train_ae_loss': np.float64(0.68095), 'train_ucc_loss': np.float64(0.71386), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.69741)}\n",
            "Step 15660: {'train_ae_loss': np.float64(0.69074), 'train_ucc_loss': np.float64(0.58811), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.63943)}\n",
            "Step 15680: {'train_ae_loss': np.float64(0.67227), 'train_ucc_loss': np.float64(0.63551), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.65389)}\n",
            "Step 15700: {'train_ae_loss': np.float64(0.69197), 'train_ucc_loss': np.float64(0.54164), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.6168)}\n",
            "Step 15720: {'train_ae_loss': np.float64(0.69861), 'train_ucc_loss': np.float64(0.68639), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.6925)}\n",
            "Step 15740: {'train_ae_loss': np.float64(0.6855), 'train_ucc_loss': np.float64(0.59319), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.63935)}\n",
            "Step 15760: {'train_ae_loss': np.float64(0.71088), 'train_ucc_loss': np.float64(0.66973), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.6903)}\n",
            "Step 15780: {'train_ae_loss': np.float64(0.69881), 'train_ucc_loss': np.float64(0.62354), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.66118)}\n",
            "Step 15800: {'train_ae_loss': np.float64(0.67528), 'train_ucc_loss': np.float64(0.64419), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.65973)}\n",
            "Step 15820: {'train_ae_loss': np.float64(0.69954), 'train_ucc_loss': np.float64(0.61654), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65804)}\n",
            "Step 15840: {'train_ae_loss': np.float64(0.69276), 'train_ucc_loss': np.float64(0.56941), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.63108)}\n",
            "Step 15860: {'train_ae_loss': np.float64(0.6768), 'train_ucc_loss': np.float64(0.65656), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.66668)}\n",
            "Step 15880: {'train_ae_loss': np.float64(0.69099), 'train_ucc_loss': np.float64(0.58999), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.64049)}\n",
            "Step 15900: {'train_ae_loss': np.float64(0.68943), 'train_ucc_loss': np.float64(0.61478), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.65211)}\n",
            "Step 15920: {'train_ae_loss': np.float64(0.69833), 'train_ucc_loss': np.float64(0.58404), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.64119)}\n",
            "Step 15940: {'train_ae_loss': np.float64(0.68787), 'train_ucc_loss': np.float64(0.59463), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.64125)}\n",
            "Step 15960: {'train_ae_loss': np.float64(0.7154), 'train_ucc_loss': np.float64(0.70185), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.70862)}\n",
            "Step 15980: {'train_ae_loss': np.float64(0.67265), 'train_ucc_loss': np.float64(0.60092), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.63678)}\n",
            "Step 16000: {'train_ae_loss': np.float64(0.68289), 'train_ucc_loss': np.float64(0.69378), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.68834)}\n",
            "step: 16000,eval_ae_loss: 0.67707,eval_ucc_loss: 0.68173,eval_ucc_acc: 0.57422\n",
            "Step 16020: {'train_ae_loss': np.float64(0.695), 'train_ucc_loss': np.float64(0.57036), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.63268)}\n",
            "Step 16040: {'train_ae_loss': np.float64(0.70435), 'train_ucc_loss': np.float64(0.6006), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.65247)}\n",
            "Step 16060: {'train_ae_loss': np.float64(0.71089), 'train_ucc_loss': np.float64(0.56107), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.63598)}\n",
            "Step 16080: {'train_ae_loss': np.float64(0.69705), 'train_ucc_loss': np.float64(0.64832), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.67269)}\n",
            "Step 16100: {'train_ae_loss': np.float64(0.68866), 'train_ucc_loss': np.float64(0.64495), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.66681)}\n",
            "Step 16120: {'train_ae_loss': np.float64(0.68687), 'train_ucc_loss': np.float64(0.65071), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.66879)}\n",
            "Step 16140: {'train_ae_loss': np.float64(0.71089), 'train_ucc_loss': np.float64(0.52902), 'train_ucc_acc': np.float64(0.8125), 'loss': np.float64(0.61995)}\n",
            "Step 16160: {'train_ae_loss': np.float64(0.67744), 'train_ucc_loss': np.float64(0.59963), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.63853)}\n",
            "Step 16180: {'train_ae_loss': np.float64(0.69392), 'train_ucc_loss': np.float64(0.58375), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.63883)}\n",
            "Step 16200: {'train_ae_loss': np.float64(0.68524), 'train_ucc_loss': np.float64(0.57775), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.6315)}\n",
            "Step 16220: {'train_ae_loss': np.float64(0.69317), 'train_ucc_loss': np.float64(0.59572), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.64445)}\n",
            "Step 16240: {'train_ae_loss': np.float64(0.68236), 'train_ucc_loss': np.float64(0.63402), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.65819)}\n",
            "Step 16260: {'train_ae_loss': np.float64(0.68931), 'train_ucc_loss': np.float64(0.71245), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.70088)}\n",
            "Step 16280: {'train_ae_loss': np.float64(0.67962), 'train_ucc_loss': np.float64(0.56624), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.62293)}\n",
            "Step 16300: {'train_ae_loss': np.float64(0.69709), 'train_ucc_loss': np.float64(0.62533), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.66121)}\n",
            "Step 16320: {'train_ae_loss': np.float64(0.67817), 'train_ucc_loss': np.float64(0.63188), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.65503)}\n",
            "Step 16340: {'train_ae_loss': np.float64(0.68246), 'train_ucc_loss': np.float64(0.54853), 'train_ucc_acc': np.float64(0.8125), 'loss': np.float64(0.6155)}\n",
            "Step 16360: {'train_ae_loss': np.float64(0.6937), 'train_ucc_loss': np.float64(0.69476), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.69423)}\n",
            "Step 16380: {'train_ae_loss': np.float64(0.68702), 'train_ucc_loss': np.float64(0.65784), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.67243)}\n",
            "Step 16400: {'train_ae_loss': np.float64(0.68901), 'train_ucc_loss': np.float64(0.63558), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.66229)}\n",
            "Step 16420: {'train_ae_loss': np.float64(0.67528), 'train_ucc_loss': np.float64(0.60047), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.63787)}\n",
            "Step 16440: {'train_ae_loss': np.float64(0.68616), 'train_ucc_loss': np.float64(0.63887), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66251)}\n",
            "Step 16460: {'train_ae_loss': np.float64(0.66301), 'train_ucc_loss': np.float64(0.62482), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.64392)}\n",
            "Step 16480: {'train_ae_loss': np.float64(0.68243), 'train_ucc_loss': np.float64(0.59684), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.63963)}\n",
            "Step 16500: {'train_ae_loss': np.float64(0.67872), 'train_ucc_loss': np.float64(0.64765), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66318)}\n",
            "Step 16520: {'train_ae_loss': np.float64(0.6826), 'train_ucc_loss': np.float64(0.66637), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67449)}\n",
            "Step 16540: {'train_ae_loss': np.float64(0.68614), 'train_ucc_loss': np.float64(0.68089), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68351)}\n",
            "Step 16560: {'train_ae_loss': np.float64(0.69652), 'train_ucc_loss': np.float64(0.64209), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.6693)}\n",
            "Step 16580: {'train_ae_loss': np.float64(0.6893), 'train_ucc_loss': np.float64(0.55006), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.61968)}\n",
            "Step 16600: {'train_ae_loss': np.float64(0.68104), 'train_ucc_loss': np.float64(0.68147), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68126)}\n",
            "Step 16620: {'train_ae_loss': np.float64(0.69042), 'train_ucc_loss': np.float64(0.65909), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67476)}\n",
            "Step 16640: {'train_ae_loss': np.float64(0.6762), 'train_ucc_loss': np.float64(0.63186), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.65403)}\n",
            "Step 16660: {'train_ae_loss': np.float64(0.68616), 'train_ucc_loss': np.float64(0.58995), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.63805)}\n",
            "Step 16680: {'train_ae_loss': np.float64(0.69195), 'train_ucc_loss': np.float64(0.62348), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.65772)}\n",
            "Step 16700: {'train_ae_loss': np.float64(0.71727), 'train_ucc_loss': np.float64(0.63538), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67632)}\n",
            "Step 16720: {'train_ae_loss': np.float64(0.68494), 'train_ucc_loss': np.float64(0.60068), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.64281)}\n",
            "Step 16740: {'train_ae_loss': np.float64(0.66897), 'train_ucc_loss': np.float64(0.67011), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.66954)}\n",
            "Step 16760: {'train_ae_loss': np.float64(0.6974), 'train_ucc_loss': np.float64(0.60366), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.65053)}\n",
            "Step 16780: {'train_ae_loss': np.float64(0.68476), 'train_ucc_loss': np.float64(0.65257), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.66867)}\n",
            "Step 16800: {'train_ae_loss': np.float64(0.67271), 'train_ucc_loss': np.float64(0.6356), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65415)}\n",
            "Step 16820: {'train_ae_loss': np.float64(0.68059), 'train_ucc_loss': np.float64(0.57246), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.62653)}\n",
            "Step 16840: {'train_ae_loss': np.float64(0.68639), 'train_ucc_loss': np.float64(0.69563), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.69101)}\n",
            "Step 16860: {'train_ae_loss': np.float64(0.72025), 'train_ucc_loss': np.float64(0.64658), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.68342)}\n",
            "Step 16880: {'train_ae_loss': np.float64(0.69712), 'train_ucc_loss': np.float64(0.61944), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.65828)}\n",
            "Step 16900: {'train_ae_loss': np.float64(0.69109), 'train_ucc_loss': np.float64(0.60589), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.64849)}\n",
            "Step 16920: {'train_ae_loss': np.float64(0.69253), 'train_ucc_loss': np.float64(0.51766), 'train_ucc_acc': np.float64(0.8125), 'loss': np.float64(0.6051)}\n",
            "Step 16940: {'train_ae_loss': np.float64(0.70831), 'train_ucc_loss': np.float64(0.63524), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67177)}\n",
            "Step 16960: {'train_ae_loss': np.float64(0.67555), 'train_ucc_loss': np.float64(0.69648), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.68601)}\n",
            "Step 16980: {'train_ae_loss': np.float64(0.69336), 'train_ucc_loss': np.float64(0.67486), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68411)}\n",
            "Step 17000: {'train_ae_loss': np.float64(0.69217), 'train_ucc_loss': np.float64(0.58761), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.63989)}\n",
            "step: 17000,eval_ae_loss: 0.68301,eval_ucc_loss: 0.66345,eval_ucc_acc: 0.61328\n",
            "Step 17020: {'train_ae_loss': np.float64(0.67949), 'train_ucc_loss': np.float64(0.63912), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.6593)}\n",
            "Step 17040: {'train_ae_loss': np.float64(0.68611), 'train_ucc_loss': np.float64(0.70017), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.69314)}\n",
            "Step 17060: {'train_ae_loss': np.float64(0.70803), 'train_ucc_loss': np.float64(0.58501), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.64652)}\n",
            "Step 17080: {'train_ae_loss': np.float64(0.69039), 'train_ucc_loss': np.float64(0.65447), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.67243)}\n",
            "Step 17100: {'train_ae_loss': np.float64(0.68593), 'train_ucc_loss': np.float64(0.48651), 'train_ucc_acc': np.float64(0.875), 'loss': np.float64(0.58622)}\n",
            "Step 17120: {'train_ae_loss': np.float64(0.70632), 'train_ucc_loss': np.float64(0.55838), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.63235)}\n",
            "Step 17140: {'train_ae_loss': np.float64(0.69051), 'train_ucc_loss': np.float64(0.64151), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.66601)}\n",
            "Step 17160: {'train_ae_loss': np.float64(0.69689), 'train_ucc_loss': np.float64(0.59821), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.64755)}\n",
            "Step 17180: {'train_ae_loss': np.float64(0.67988), 'train_ucc_loss': np.float64(0.58063), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.63026)}\n",
            "Step 17200: {'train_ae_loss': np.float64(0.69046), 'train_ucc_loss': np.float64(0.58613), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.63829)}\n",
            "Step 17220: {'train_ae_loss': np.float64(0.67712), 'train_ucc_loss': np.float64(0.62353), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.65032)}\n",
            "Step 17240: {'train_ae_loss': np.float64(0.69014), 'train_ucc_loss': np.float64(0.65638), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67326)}\n",
            "Step 17260: {'train_ae_loss': np.float64(0.67924), 'train_ucc_loss': np.float64(0.59636), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.6378)}\n",
            "Step 17280: {'train_ae_loss': np.float64(0.6932), 'train_ucc_loss': np.float64(0.65949), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67634)}\n",
            "Step 17300: {'train_ae_loss': np.float64(0.68433), 'train_ucc_loss': np.float64(0.82813), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.75623)}\n",
            "Step 17320: {'train_ae_loss': np.float64(0.68991), 'train_ucc_loss': np.float64(0.68861), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.68926)}\n",
            "Step 17340: {'train_ae_loss': np.float64(0.68774), 'train_ucc_loss': np.float64(0.57584), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.63179)}\n",
            "Step 17360: {'train_ae_loss': np.float64(0.67694), 'train_ucc_loss': np.float64(0.56674), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.62184)}\n",
            "Step 17380: {'train_ae_loss': np.float64(0.70461), 'train_ucc_loss': np.float64(0.66319), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.6839)}\n",
            "Step 17400: {'train_ae_loss': np.float64(0.69657), 'train_ucc_loss': np.float64(0.6273), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.66194)}\n",
            "Step 17420: {'train_ae_loss': np.float64(0.69296), 'train_ucc_loss': np.float64(0.64323), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.66809)}\n",
            "Step 17440: {'train_ae_loss': np.float64(0.69927), 'train_ucc_loss': np.float64(0.55413), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.6267)}\n",
            "Step 17460: {'train_ae_loss': np.float64(0.68354), 'train_ucc_loss': np.float64(0.71253), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.69804)}\n",
            "Step 17480: {'train_ae_loss': np.float64(0.67254), 'train_ucc_loss': np.float64(0.69199), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.68227)}\n",
            "Step 17500: {'train_ae_loss': np.float64(0.68729), 'train_ucc_loss': np.float64(0.72177), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.70453)}\n",
            "Step 17520: {'train_ae_loss': np.float64(0.68607), 'train_ucc_loss': np.float64(0.74994), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.718)}\n",
            "Step 17540: {'train_ae_loss': np.float64(0.69653), 'train_ucc_loss': np.float64(0.68797), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.69225)}\n",
            "Step 17560: {'train_ae_loss': np.float64(0.71327), 'train_ucc_loss': np.float64(0.61772), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.6655)}\n",
            "Step 17580: {'train_ae_loss': np.float64(0.68565), 'train_ucc_loss': np.float64(0.61822), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65193)}\n",
            "Step 17600: {'train_ae_loss': np.float64(0.69586), 'train_ucc_loss': np.float64(0.57317), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.63452)}\n",
            "Step 17620: {'train_ae_loss': np.float64(0.71853), 'train_ucc_loss': np.float64(0.7549), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.73672)}\n",
            "Step 17640: {'train_ae_loss': np.float64(0.68317), 'train_ucc_loss': np.float64(0.57716), 'train_ucc_acc': np.float64(0.8125), 'loss': np.float64(0.63016)}\n",
            "Step 17660: {'train_ae_loss': np.float64(0.66799), 'train_ucc_loss': np.float64(0.61908), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.64354)}\n",
            "Step 17680: {'train_ae_loss': np.float64(0.70733), 'train_ucc_loss': np.float64(0.60702), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.65718)}\n",
            "Step 17700: {'train_ae_loss': np.float64(0.69758), 'train_ucc_loss': np.float64(0.52497), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.61128)}\n",
            "Step 17720: {'train_ae_loss': np.float64(0.69882), 'train_ucc_loss': np.float64(0.64638), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.6726)}\n",
            "Step 17740: {'train_ae_loss': np.float64(0.70893), 'train_ucc_loss': np.float64(0.5676), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.63826)}\n",
            "Step 17760: {'train_ae_loss': np.float64(0.70042), 'train_ucc_loss': np.float64(0.59674), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.64858)}\n",
            "Step 17780: {'train_ae_loss': np.float64(0.70224), 'train_ucc_loss': np.float64(0.68511), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.69367)}\n",
            "Step 17800: {'train_ae_loss': np.float64(0.67429), 'train_ucc_loss': np.float64(0.64255), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.65842)}\n",
            "Step 17820: {'train_ae_loss': np.float64(0.69671), 'train_ucc_loss': np.float64(0.52382), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.61026)}\n",
            "Step 17840: {'train_ae_loss': np.float64(0.6851), 'train_ucc_loss': np.float64(0.65586), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.67048)}\n",
            "Step 17860: {'train_ae_loss': np.float64(0.68099), 'train_ucc_loss': np.float64(0.66055), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.67077)}\n",
            "Step 17880: {'train_ae_loss': np.float64(0.6785), 'train_ucc_loss': np.float64(0.64076), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.65963)}\n",
            "Step 17900: {'train_ae_loss': np.float64(0.70148), 'train_ucc_loss': np.float64(0.65625), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67887)}\n",
            "Step 17920: {'train_ae_loss': np.float64(0.71355), 'train_ucc_loss': np.float64(0.60014), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.65685)}\n",
            "Step 17940: {'train_ae_loss': np.float64(0.69585), 'train_ucc_loss': np.float64(0.6873), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.69158)}\n",
            "Step 17960: {'train_ae_loss': np.float64(0.6834), 'train_ucc_loss': np.float64(0.52921), 'train_ucc_acc': np.float64(0.84375), 'loss': np.float64(0.6063)}\n",
            "Step 17980: {'train_ae_loss': np.float64(0.68447), 'train_ucc_loss': np.float64(0.62432), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65439)}\n",
            "Step 18000: {'train_ae_loss': np.float64(0.69629), 'train_ucc_loss': np.float64(0.59984), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.64807)}\n",
            "step: 18000,eval_ae_loss: 0.68321,eval_ucc_loss: 0.65901,eval_ucc_acc: 0.60254\n",
            "Step 18020: {'train_ae_loss': np.float64(0.70138), 'train_ucc_loss': np.float64(0.55261), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.627)}\n",
            "Step 18040: {'train_ae_loss': np.float64(0.71125), 'train_ucc_loss': np.float64(0.60778), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.65952)}\n",
            "Step 18060: {'train_ae_loss': np.float64(0.69332), 'train_ucc_loss': np.float64(0.62376), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65854)}\n",
            "Step 18080: {'train_ae_loss': np.float64(0.70871), 'train_ucc_loss': np.float64(0.63115), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.66993)}\n",
            "Step 18100: {'train_ae_loss': np.float64(0.69975), 'train_ucc_loss': np.float64(0.70463), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.70219)}\n",
            "Step 18120: {'train_ae_loss': np.float64(0.69468), 'train_ucc_loss': np.float64(0.6794), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68704)}\n",
            "Step 18140: {'train_ae_loss': np.float64(0.68426), 'train_ucc_loss': np.float64(0.61478), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.64952)}\n",
            "Step 18160: {'train_ae_loss': np.float64(0.68384), 'train_ucc_loss': np.float64(0.60615), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.645)}\n",
            "Step 18180: {'train_ae_loss': np.float64(0.68689), 'train_ucc_loss': np.float64(0.60026), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.64358)}\n",
            "Step 18200: {'train_ae_loss': np.float64(0.68711), 'train_ucc_loss': np.float64(0.72337), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.70524)}\n",
            "Step 18220: {'train_ae_loss': np.float64(0.69238), 'train_ucc_loss': np.float64(0.61931), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.65584)}\n",
            "Step 18240: {'train_ae_loss': np.float64(0.7016), 'train_ucc_loss': np.float64(0.61883), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.66022)}\n",
            "Step 18260: {'train_ae_loss': np.float64(0.68165), 'train_ucc_loss': np.float64(0.60521), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.64343)}\n",
            "Step 18280: {'train_ae_loss': np.float64(0.69717), 'train_ucc_loss': np.float64(0.63333), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.66525)}\n",
            "Step 18300: {'train_ae_loss': np.float64(0.69039), 'train_ucc_loss': np.float64(0.61661), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.6535)}\n",
            "Step 18320: {'train_ae_loss': np.float64(0.71299), 'train_ucc_loss': np.float64(0.56112), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.63705)}\n",
            "Step 18340: {'train_ae_loss': np.float64(0.68869), 'train_ucc_loss': np.float64(0.6138), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.65124)}\n",
            "Step 18360: {'train_ae_loss': np.float64(0.69862), 'train_ucc_loss': np.float64(0.66711), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.68287)}\n",
            "Step 18380: {'train_ae_loss': np.float64(0.69667), 'train_ucc_loss': np.float64(0.60304), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.64985)}\n",
            "Step 18400: {'train_ae_loss': np.float64(0.69196), 'train_ucc_loss': np.float64(0.68694), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.68945)}\n",
            "Step 18420: {'train_ae_loss': np.float64(0.69387), 'train_ucc_loss': np.float64(0.64306), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66847)}\n",
            "Step 18440: {'train_ae_loss': np.float64(0.67909), 'train_ucc_loss': np.float64(0.65641), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.66775)}\n",
            "Step 18460: {'train_ae_loss': np.float64(0.7), 'train_ucc_loss': np.float64(0.62824), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66412)}\n",
            "Step 18480: {'train_ae_loss': np.float64(0.67809), 'train_ucc_loss': np.float64(0.63179), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65494)}\n",
            "Step 18500: {'train_ae_loss': np.float64(0.67713), 'train_ucc_loss': np.float64(0.61407), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.6456)}\n",
            "Step 18520: {'train_ae_loss': np.float64(0.68027), 'train_ucc_loss': np.float64(0.55907), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.61967)}\n",
            "Step 18540: {'train_ae_loss': np.float64(0.69016), 'train_ucc_loss': np.float64(0.58267), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.63641)}\n",
            "Step 18560: {'train_ae_loss': np.float64(0.7017), 'train_ucc_loss': np.float64(0.64817), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.67493)}\n",
            "Step 18580: {'train_ae_loss': np.float64(0.67934), 'train_ucc_loss': np.float64(0.56598), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.62266)}\n",
            "Step 18600: {'train_ae_loss': np.float64(0.69773), 'train_ucc_loss': np.float64(0.52111), 'train_ucc_acc': np.float64(0.8125), 'loss': np.float64(0.60942)}\n",
            "Step 18620: {'train_ae_loss': np.float64(0.68943), 'train_ucc_loss': np.float64(0.66322), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.67632)}\n",
            "Step 18640: {'train_ae_loss': np.float64(0.67619), 'train_ucc_loss': np.float64(0.63674), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.65646)}\n",
            "Step 18660: {'train_ae_loss': np.float64(0.70926), 'train_ucc_loss': np.float64(0.54992), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.62959)}\n",
            "Step 18680: {'train_ae_loss': np.float64(0.70659), 'train_ucc_loss': np.float64(0.611), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.6588)}\n",
            "Step 18700: {'train_ae_loss': np.float64(0.68167), 'train_ucc_loss': np.float64(0.58213), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.6319)}\n",
            "Step 18720: {'train_ae_loss': np.float64(0.68397), 'train_ucc_loss': np.float64(0.73499), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.70948)}\n",
            "Step 18740: {'train_ae_loss': np.float64(0.71384), 'train_ucc_loss': np.float64(0.57322), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.64353)}\n",
            "Step 18760: {'train_ae_loss': np.float64(0.69627), 'train_ucc_loss': np.float64(0.58635), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.64131)}\n",
            "Step 18780: {'train_ae_loss': np.float64(0.68796), 'train_ucc_loss': np.float64(0.6504), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66918)}\n",
            "Step 18800: {'train_ae_loss': np.float64(0.6829), 'train_ucc_loss': np.float64(0.61639), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.64965)}\n",
            "Step 18820: {'train_ae_loss': np.float64(0.69256), 'train_ucc_loss': np.float64(0.5918), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.64218)}\n",
            "Step 18840: {'train_ae_loss': np.float64(0.69451), 'train_ucc_loss': np.float64(0.65709), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.6758)}\n",
            "Step 18860: {'train_ae_loss': np.float64(0.70262), 'train_ucc_loss': np.float64(0.89393), 'train_ucc_acc': np.float64(0.375), 'loss': np.float64(0.79828)}\n",
            "Step 18880: {'train_ae_loss': np.float64(0.6855), 'train_ucc_loss': np.float64(0.55728), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.62139)}\n",
            "Step 18900: {'train_ae_loss': np.float64(0.71111), 'train_ucc_loss': np.float64(0.54996), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.63054)}\n",
            "Step 18920: {'train_ae_loss': np.float64(0.68763), 'train_ucc_loss': np.float64(0.59909), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.64336)}\n",
            "Step 18940: {'train_ae_loss': np.float64(0.67086), 'train_ucc_loss': np.float64(0.58944), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.63015)}\n",
            "Step 18960: {'train_ae_loss': np.float64(0.6948), 'train_ucc_loss': np.float64(0.55608), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.62544)}\n",
            "Step 18980: {'train_ae_loss': np.float64(0.69164), 'train_ucc_loss': np.float64(0.55703), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.62433)}\n",
            "Step 19000: {'train_ae_loss': np.float64(0.69583), 'train_ucc_loss': np.float64(0.51757), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.6067)}\n",
            "step: 19000,eval_ae_loss: 0.68738,eval_ucc_loss: 0.68724,eval_ucc_acc: 0.58496\n",
            "Step 19020: {'train_ae_loss': np.float64(0.69541), 'train_ucc_loss': np.float64(0.71031), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.70286)}\n",
            "Step 19040: {'train_ae_loss': np.float64(0.69479), 'train_ucc_loss': np.float64(0.59281), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.6438)}\n",
            "Step 19060: {'train_ae_loss': np.float64(0.71154), 'train_ucc_loss': np.float64(0.61373), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.66264)}\n",
            "Step 19080: {'train_ae_loss': np.float64(0.69559), 'train_ucc_loss': np.float64(0.4797), 'train_ucc_acc': np.float64(0.84375), 'loss': np.float64(0.58765)}\n",
            "Step 19100: {'train_ae_loss': np.float64(0.68945), 'train_ucc_loss': np.float64(0.52029), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.60487)}\n",
            "Step 19120: {'train_ae_loss': np.float64(0.68745), 'train_ucc_loss': np.float64(0.69821), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.69283)}\n",
            "Step 19140: {'train_ae_loss': np.float64(0.68453), 'train_ucc_loss': np.float64(0.57734), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.63093)}\n",
            "Step 19160: {'train_ae_loss': np.float64(0.69279), 'train_ucc_loss': np.float64(0.6992), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.696)}\n",
            "Step 19180: {'train_ae_loss': np.float64(0.71354), 'train_ucc_loss': np.float64(0.56007), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.63681)}\n",
            "Step 19200: {'train_ae_loss': np.float64(0.70876), 'train_ucc_loss': np.float64(0.67686), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.69281)}\n",
            "Step 19220: {'train_ae_loss': np.float64(0.69798), 'train_ucc_loss': np.float64(0.5694), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.63369)}\n",
            "Step 19240: {'train_ae_loss': np.float64(0.67974), 'train_ucc_loss': np.float64(0.5771), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.62842)}\n",
            "Step 19260: {'train_ae_loss': np.float64(0.72257), 'train_ucc_loss': np.float64(0.61518), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.66887)}\n",
            "Step 19280: {'train_ae_loss': np.float64(0.70111), 'train_ucc_loss': np.float64(0.63216), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.66664)}\n",
            "Step 19300: {'train_ae_loss': np.float64(0.68874), 'train_ucc_loss': np.float64(0.69994), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.69434)}\n",
            "Step 19320: {'train_ae_loss': np.float64(0.6792), 'train_ucc_loss': np.float64(0.67485), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.67702)}\n",
            "Step 19340: {'train_ae_loss': np.float64(0.69014), 'train_ucc_loss': np.float64(0.61582), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.65298)}\n",
            "Step 19360: {'train_ae_loss': np.float64(0.70156), 'train_ucc_loss': np.float64(0.63197), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.66677)}\n",
            "Step 19380: {'train_ae_loss': np.float64(0.71172), 'train_ucc_loss': np.float64(0.71111), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.71141)}\n",
            "Step 19400: {'train_ae_loss': np.float64(0.69534), 'train_ucc_loss': np.float64(0.60269), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.64902)}\n",
            "Step 19420: {'train_ae_loss': np.float64(0.68948), 'train_ucc_loss': np.float64(0.73874), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.71411)}\n",
            "Step 19440: {'train_ae_loss': np.float64(0.7109), 'train_ucc_loss': np.float64(0.62578), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.66834)}\n",
            "Step 19460: {'train_ae_loss': np.float64(0.70257), 'train_ucc_loss': np.float64(0.70653), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.70455)}\n",
            "Step 19480: {'train_ae_loss': np.float64(0.69792), 'train_ucc_loss': np.float64(0.55864), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.62828)}\n",
            "Step 19500: {'train_ae_loss': np.float64(0.68928), 'train_ucc_loss': np.float64(0.6935), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.69139)}\n",
            "Step 19520: {'train_ae_loss': np.float64(0.69566), 'train_ucc_loss': np.float64(0.81244), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.75405)}\n",
            "Step 19540: {'train_ae_loss': np.float64(0.69407), 'train_ucc_loss': np.float64(0.64336), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.66871)}\n",
            "Step 19560: {'train_ae_loss': np.float64(0.68158), 'train_ucc_loss': np.float64(0.69533), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.68846)}\n",
            "Step 19580: {'train_ae_loss': np.float64(0.69502), 'train_ucc_loss': np.float64(0.65968), 'train_ucc_acc': np.float64(0.65625), 'loss': np.float64(0.67735)}\n",
            "Step 19600: {'train_ae_loss': np.float64(0.68792), 'train_ucc_loss': np.float64(0.54416), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.61604)}\n",
            "Step 19620: {'train_ae_loss': np.float64(0.67961), 'train_ucc_loss': np.float64(0.68854), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.68408)}\n",
            "Step 19640: {'train_ae_loss': np.float64(0.67232), 'train_ucc_loss': np.float64(0.67713), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.67472)}\n",
            "Step 19660: {'train_ae_loss': np.float64(0.696), 'train_ucc_loss': np.float64(0.59551), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.64576)}\n",
            "Step 19680: {'train_ae_loss': np.float64(0.67279), 'train_ucc_loss': np.float64(0.60185), 'train_ucc_acc': np.float64(0.75), 'loss': np.float64(0.63732)}\n",
            "Step 19700: {'train_ae_loss': np.float64(0.67736), 'train_ucc_loss': np.float64(0.68564), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.6815)}\n",
            "Step 19720: {'train_ae_loss': np.float64(0.69556), 'train_ucc_loss': np.float64(0.53984), 'train_ucc_acc': np.float64(0.78125), 'loss': np.float64(0.6177)}\n",
            "Step 19740: {'train_ae_loss': np.float64(0.69588), 'train_ucc_loss': np.float64(0.60749), 'train_ucc_acc': np.float64(0.625), 'loss': np.float64(0.65168)}\n",
            "Step 19760: {'train_ae_loss': np.float64(0.68807), 'train_ucc_loss': np.float64(0.67463), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.68135)}\n"
          ]
        }
      ],
      "source": [
        "mlflow.set_tracking_uri(\"file:///Users/tanguanyu/UCC-DRN-Pytorch/camelyon/mlruns\")\n",
        "\n",
        "run_name = \"camelyon-ucc-drn-search-init\"\n",
        "experiment_id = get_or_create_experiment(experiment_name=run_name)\n",
        "mlflow.set_experiment(experiment_id=experiment_id)\n",
        "for lower_bound in x:\n",
        "    for upper_bound in x:\n",
        "        if lower_bound >= upper_bound:\n",
        "            continue\n",
        "        with mlflow.start_run(nested=True) as run:\n",
        "            cfg.model.drn.init_lower_bound = float(lower_bound)\n",
        "            cfg.model.drn.init_upper_bound = float(upper_bound)\n",
        "            mlflow.log_params({\n",
        "                \"init_W_lower_bound\": float(lower_bound),\n",
        "                \"init_W_upper_bound\": float(upper_bound)\n",
        "            })\n",
        "            print(cfg.model.drn)\n",
        "            cfg.args.learning_rate = 0.001\n",
        "            mlflow.log_dict(dict(OmegaConf.to_object(cfg)), \"config.yaml\")\n",
        "            args = cfg.args\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
        "            model, optimizer = init_model_and_optimizer(args, cfg, device)\n",
        "            train_loader, val_loader = init_dataloader(args)\n",
        "            artifact_path = run.info.artifact_uri\n",
        "            mlflow.pytorch.log_model(\n",
        "                    model,\n",
        "                    artifact_path = \"init_model\")\n",
        "            best_acc = train(args, model, optimizer, None,\n",
        "                            train_loader, val_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP-uF0b8vyWn"
      },
      "source": [
        "{'args': {'dataset': 'camelyon', 'model_dir': 'saved_models/', 'model_name': 'camelyon_ucc_drn', 'num_instances': 32, 'ucc_start': 1, 'ucc_end': 4, 'batch_size': 5, 'num_samples_per_class': 5, 'num_workers': 4, 'learning_rate': 0.0001, 'num_bins': 11, 'num_features': 10, 'train_num_steps': 100000, 'val_num_steps': 200, 'save_interval': 1000, 'patch_size': 32, 'seed': 22}, 'model': {'kde_model': {'num_bins': 11, 'sigma': 0.1}, 'num_channels': 3, 'encoder': {'conv_input_channel': 3, 'conv_output_channel': 16, 'block1_output_channel': 32, 'block1_num_layer': 1, 'block2_output_channel': 64, 'block2_num_layer': 1, 'block3_output_channel': 128, 'block3_num_layer': 1, 'flatten_size': 8192, 'num_features': 16}, 'decoder': {'linear_size': 8192, 'reshape_size': [128, 8, 8], 'block1_output_channel': 128, 'block1_num_layer': 1, 'block2_output_channel': 64, 'block2_num_layer': 1, 'block3_output_channel': 32, 'block3_num_layer': 1, 'output_channel': 3}, 'drn': {'num_bins': 11, 'hidden_q': 100, 'num_layers': 2, 'num_nodes': 9, 'init_method': 'uniform', 'init_upper_bound': 0.5, 'init_lower_bound': -0.5, 'output_bins': 4}, 'ucc_classifier': 'None', 'loss': {'alpha': 0.5}}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UExxHuIISwlh",
        "outputId": "670bda90-2541-459e-a298-3989979f04e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.0012\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "201000\n",
            "training\n",
            "{'train_ae_loss': np.float64(1.00001), 'train_ucc_loss': np.float64(0.68627), 'train_ucc_acc': np.float64(0.71875), 'loss': np.float64(0.84314)}\n",
            "{'train_ae_loss': np.float64(1.0), 'train_ucc_loss': np.float64(0.69135), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.84568)}\n",
            "{'train_ae_loss': np.float64(1.00002), 'train_ucc_loss': np.float64(0.69038), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.8452)}\n",
            "{'train_ae_loss': np.float64(0.99998), 'train_ucc_loss': np.float64(0.69322), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.8466)}\n",
            "{'train_ae_loss': np.float64(1.0), 'train_ucc_loss': np.float64(0.69326), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.84663)}\n",
            "{'train_ae_loss': np.float64(0.99999), 'train_ucc_loss': np.float64(0.69482), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.8474)}\n",
            "{'train_ae_loss': np.float64(0.99999), 'train_ucc_loss': np.float64(0.69406), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.84703)}\n",
            "{'train_ae_loss': np.float64(0.99997), 'train_ucc_loss': np.float64(0.69471), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.84734)}\n",
            "{'train_ae_loss': np.float64(0.99999), 'train_ucc_loss': np.float64(0.69187), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.84593)}\n",
            "{'train_ae_loss': np.float64(0.99999), 'train_ucc_loss': np.float64(0.69315), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.84657)}\n",
            "{'train_ae_loss': np.float64(1.00001), 'train_ucc_loss': np.float64(0.69316), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.84659)}\n",
            "{'train_ae_loss': np.float64(1.00001), 'train_ucc_loss': np.float64(0.69431), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.84716)}\n",
            "{'train_ae_loss': np.float64(1.0), 'train_ucc_loss': np.float64(0.69341), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.84671)}\n",
            "{'train_ae_loss': np.float64(1.00001), 'train_ucc_loss': np.float64(0.69313), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.84657)}\n",
            "{'train_ae_loss': np.float64(1.0), 'train_ucc_loss': np.float64(0.69327), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.84664)}\n",
            "{'train_ae_loss': np.float64(0.99998), 'train_ucc_loss': np.float64(0.69345), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.84671)}\n",
            "{'train_ae_loss': np.float64(1.0), 'train_ucc_loss': np.float64(0.69344), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.84672)}\n",
            "{'train_ae_loss': np.float64(0.99999), 'train_ucc_loss': np.float64(0.69274), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.84637)}\n",
            "{'train_ae_loss': np.float64(0.99999), 'train_ucc_loss': np.float64(0.69289), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.84644)}\n",
            "{'train_ae_loss': np.float64(0.99999), 'train_ucc_loss': np.float64(0.69263), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.84631)}\n",
            "{'train_ae_loss': np.float64(0.99998), 'train_ucc_loss': np.float64(0.69433), 'train_ucc_acc': np.float64(0.3125), 'loss': np.float64(0.84716)}\n",
            "{'train_ae_loss': np.float64(1.00001), 'train_ucc_loss': np.float64(0.69302), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.84651)}\n",
            "{'train_ae_loss': np.float64(0.99999), 'train_ucc_loss': np.float64(0.69102), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.8455)}\n",
            "{'train_ae_loss': np.float64(1.0), 'train_ucc_loss': np.float64(0.69158), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.84579)}\n",
            "{'train_ae_loss': np.float64(1.0), 'train_ucc_loss': np.float64(0.68845), 'train_ucc_acc': np.float64(0.6875), 'loss': np.float64(0.84423)}\n",
            "{'train_ae_loss': np.float64(1.0), 'train_ucc_loss': np.float64(0.69537), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.84769)}\n",
            "{'train_ae_loss': np.float64(1.0), 'train_ucc_loss': np.float64(0.69331), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.84665)}\n",
            "{'train_ae_loss': np.float64(0.99999), 'train_ucc_loss': np.float64(0.69411), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.84705)}\n",
            "{'train_ae_loss': np.float64(0.99999), 'train_ucc_loss': np.float64(0.69491), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.84745)}\n",
            "{'train_ae_loss': np.float64(1.0), 'train_ucc_loss': np.float64(0.69259), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.84629)}\n",
            "{'train_ae_loss': np.float64(1.0), 'train_ucc_loss': np.float64(0.69262), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.84631)}\n",
            "{'train_ae_loss': np.float64(0.99999), 'train_ucc_loss': np.float64(0.69487), 'train_ucc_acc': np.float64(0.40625), 'loss': np.float64(0.84743)}\n",
            "{'train_ae_loss': np.float64(1.00001), 'train_ucc_loss': np.float64(0.69349), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.84675)}\n",
            "{'train_ae_loss': np.float64(1.00001), 'train_ucc_loss': np.float64(0.69243), 'train_ucc_acc': np.float64(0.59375), 'loss': np.float64(0.84622)}\n",
            "{'train_ae_loss': np.float64(1.00001), 'train_ucc_loss': np.float64(0.69335), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.84668)}\n",
            "{'train_ae_loss': np.float64(0.99999), 'train_ucc_loss': np.float64(0.69315), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.84657)}\n",
            "{'train_ae_loss': np.float64(1.0), 'train_ucc_loss': np.float64(0.69332), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.84666)}\n",
            "{'train_ae_loss': np.float64(1.00005), 'train_ucc_loss': np.float64(0.69384), 'train_ucc_acc': np.float64(0.375), 'loss': np.float64(0.84695)}\n",
            "{'train_ae_loss': np.float64(1.0), 'train_ucc_loss': np.float64(0.69336), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.84668)}\n",
            "{'train_ae_loss': np.float64(0.99997), 'train_ucc_loss': np.float64(0.69317), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.84657)}\n",
            "{'train_ae_loss': np.float64(1.00004), 'train_ucc_loss': np.float64(0.6944), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.84722)}\n",
            "{'train_ae_loss': np.float64(1.0), 'train_ucc_loss': np.float64(0.69348), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.84674)}\n",
            "{'train_ae_loss': np.float64(1.00001), 'train_ucc_loss': np.float64(0.69424), 'train_ucc_acc': np.float64(0.375), 'loss': np.float64(0.84712)}\n",
            "{'train_ae_loss': np.float64(1.0), 'train_ucc_loss': np.float64(0.69328), 'train_ucc_acc': np.float64(0.46875), 'loss': np.float64(0.84664)}\n",
            "{'train_ae_loss': np.float64(1.0), 'train_ucc_loss': np.float64(0.6936), 'train_ucc_acc': np.float64(0.4375), 'loss': np.float64(0.8468)}\n",
            "{'train_ae_loss': np.float64(1.0), 'train_ucc_loss': np.float64(0.69315), 'train_ucc_acc': np.float64(0.5), 'loss': np.float64(0.84657)}\n",
            "{'train_ae_loss': np.float64(0.99999), 'train_ucc_loss': np.float64(0.6929), 'train_ucc_acc': np.float64(0.5625), 'loss': np.float64(0.84644)}\n",
            "{'train_ae_loss': np.float64(0.99998), 'train_ucc_loss': np.float64(0.69419), 'train_ucc_acc': np.float64(0.3125), 'loss': np.float64(0.84708)}\n",
            "{'train_ae_loss': np.float64(0.99998), 'train_ucc_loss': np.float64(0.694), 'train_ucc_acc': np.float64(0.34375), 'loss': np.float64(0.84699)}\n",
            "{'train_ae_loss': np.float64(1.0), 'train_ucc_loss': np.float64(0.69285), 'train_ucc_acc': np.float64(0.53125), 'loss': np.float64(0.84643)}\n",
            "step: 202000,eval_ae_loss: 1.0,eval_ucc_loss: 0.69316,eval_ucc_acc: 0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[31m2025/08/05 01:34:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "[Errno 30] Read-only file system: '/content'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m         mlflow\u001b[38;5;241m.\u001b[39mset_experiment(experiment_id\u001b[38;5;241m=\u001b[39mexperiment_id)\n\u001b[1;32m     28\u001b[0m         best_acc \u001b[38;5;241m=\u001b[39m train(args, model, optimizer, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     29\u001b[0m                     train_loader, val_loader, device, step\u001b[38;5;241m=\u001b[39mstep)\n\u001b[0;32m---> 31\u001b[0m \u001b[43mresume_training\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m67affc095c864c1ba34f32214201b08c\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[5], line 28\u001b[0m, in \u001b[0;36mresume_training\u001b[0;34m(run_id)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mstart_run(run_id\u001b[38;5;241m=\u001b[39mrun_id, nested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m     27\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mset_experiment(experiment_id\u001b[38;5;241m=\u001b[39mexperiment_id)\n\u001b[0;32m---> 28\u001b[0m     best_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[2], line 129\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(args, model, optimizer, lr_scheduler, train_loader, val_loader, device, step)\u001b[0m\n\u001b[1;32m    127\u001b[0m best_eval_acc \u001b[38;5;241m=\u001b[39m eval_acc\n\u001b[1;32m    128\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_metric(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_eval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_eval_acc)\n\u001b[0;32m--> 129\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpytorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbest_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(optimizer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_artifact(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/UCC-DRN-Pytorch/.venv/lib/python3.12/site-packages/mlflow/pytorch/__init__.py:296\u001b[0m, in \u001b[0;36mlog_model\u001b[0;34m(pytorch_model, artifact_path, conda_env, code_paths, pickle_module, registered_model_name, signature, input_example, await_registration_for, requirements_file, extra_files, pip_requirements, extra_pip_requirements, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03mLog a PyTorch model as an MLflow artifact for the current run.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    PyTorch logged models\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    295\u001b[0m pickle_module \u001b[38;5;241m=\u001b[39m pickle_module \u001b[38;5;129;01mor\u001b[39;00m mlflow_pytorch_pickle_module\n\u001b[0;32m--> 296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpytorch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpytorch_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpytorch_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m    \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_example\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequirements_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequirements_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/UCC-DRN-Pytorch/.venv/lib/python3.12/site-packages/mlflow/models/model.py:846\u001b[0m, in \u001b[0;36mModel.log\u001b[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m     _logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound the following environment variables used during model inference: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_var_info\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please check if you need to set them when deploying the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel. To disable this message, set environment variable \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` to `false`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n\u001b[1;32m    845\u001b[0m mlflow_model\u001b[38;5;241m.\u001b[39menv_vars \u001b[38;5;241m=\u001b[39m env_vars\n\u001b[0;32m--> 846\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtracking\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfluent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;66;03m# if the model_config kwarg is passed in, then log the model config as an params\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_config \u001b[38;5;241m:=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_config\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[0;32m~/UCC-DRN-Pytorch/.venv/lib/python3.12/site-packages/mlflow/tracking/fluent.py:1219\u001b[0m, in \u001b[0;36mlog_artifacts\u001b[0;34m(local_dir, artifact_path, run_id)\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;124;03mLog all the contents of a local directory as artifacts of the run. If no run is active,\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;124;03mthis method will create a new active run.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;124;03m            mlflow.log_artifacts(tmp_dir, artifact_path=\"states\")\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1218\u001b[0m run_id \u001b[38;5;241m=\u001b[39m run_id \u001b[38;5;129;01mor\u001b[39;00m _get_or_start_run()\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id\n\u001b[0;32m-> 1219\u001b[0m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/UCC-DRN-Pytorch/.venv/lib/python3.12/site-packages/mlflow/tracking/client.py:1982\u001b[0m, in \u001b[0;36mMlflowClient.log_artifacts\u001b[0;34m(self, run_id, local_dir, artifact_path)\u001b[0m\n\u001b[1;32m   1935\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_artifacts\u001b[39m(\n\u001b[1;32m   1936\u001b[0m     \u001b[38;5;28mself\u001b[39m, run_id: \u001b[38;5;28mstr\u001b[39m, local_dir: \u001b[38;5;28mstr\u001b[39m, artifact_path: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1937\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1938\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[1;32m   1939\u001b[0m \n\u001b[1;32m   1940\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1980\u001b[0m \n\u001b[1;32m   1981\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1982\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/UCC-DRN-Pytorch/.venv/lib/python3.12/site-packages/mlflow/tracking/_tracking_service/client.py:875\u001b[0m, in \u001b[0;36mTrackingServiceClient.log_artifacts\u001b[0;34m(self, run_id, local_dir, artifact_path)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_artifacts\u001b[39m(\u001b[38;5;28mself\u001b[39m, run_id, local_dir, artifact_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    867\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Write a directory of files to the remote ``artifact_uri``.\u001b[39;00m\n\u001b[1;32m    868\u001b[0m \n\u001b[1;32m    869\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    873\u001b[0m \n\u001b[1;32m    874\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 875\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_artifact_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_artifacts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/UCC-DRN-Pytorch/.venv/lib/python3.12/site-packages/mlflow/store/artifact/local_artifact_repo.py:66\u001b[0m, in \u001b[0;36mLocalArtifactRepository.log_artifacts\u001b[0;34m(self, local_dir, artifact_path)\u001b[0m\n\u001b[1;32m     62\u001b[0m artifact_dir \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     63\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifact_dir, artifact_path) \u001b[38;5;28;01mif\u001b[39;00m artifact_path \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifact_dir\n\u001b[1;32m     64\u001b[0m )\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(artifact_dir):\n\u001b[0;32m---> 66\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m shutil\u001b[38;5;241m.\u001b[39mcopytree(src\u001b[38;5;241m=\u001b[39mlocal_dir, dst\u001b[38;5;241m=\u001b[39martifact_dir, dirs_exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m~/UCC-DRN-Pytorch/.venv/lib/python3.12/site-packages/mlflow/utils/file_utils.py:211\u001b[0m, in \u001b[0;36mmkdir\u001b[0;34m(root, name)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m!=\u001b[39m errno\u001b[38;5;241m.\u001b[39mEEXIST \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(target):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target\n",
            "File \u001b[0;32m~/UCC-DRN-Pytorch/.venv/lib/python3.12/site-packages/mlflow/utils/file_utils.py:208\u001b[0m, in \u001b[0;36mmkdir\u001b[0;34m(root, name)\u001b[0m\n\u001b[1;32m    206\u001b[0m target \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root, name) \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m root\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m!=\u001b[39m errno\u001b[38;5;241m.\u001b[39mEEXIST \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(target):\n",
            "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
            "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
            "    \u001b[0;31m[... skipping similar frames: makedirs at line 215 (6 times)]\u001b[0m\n",
            "File \u001b[0;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
            "File \u001b[0;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 30] Read-only file system: '/content'"
          ]
        }
      ],
      "source": [
        "def load_model_and_optimizer(experiment_id, run_id):\n",
        "    model = torch.load(f\"mlruns/{experiment_id}/{run_id}/artifacts/best_model/data/model.pth\", weights_only=False, map_location=\"mps\")\n",
        "    optimizer = torch.optim.Adam(lr=0.0012, params=model.parameters())\n",
        "    # optimizer.load_state_dict(torch.load(f\"mlruns/{experiment_id}/{run_id}/artifacts/optimizer.pt\", weights_only=False, map_location=\"mps\").state_dict())\n",
        "\n",
        "    with open(f\"mlruns/{experiment_id}/{run_id}/metrics/eval_ucc_acc\") as file:\n",
        "        lines = file.readlines()\n",
        "        step = int(lines[-1].split(\" \")[-1])\n",
        "    return model, optimizer, step\n",
        "\n",
        "def resume_training(run_id):\n",
        "    mlflow.set_tracking_uri(\"mlruns\")\n",
        "    run_name = \"camelyon-ucc-drn\"\n",
        "    experiment = mlflow.set_experiment(run_name)\n",
        "    experiment_id = experiment.experiment_id\n",
        "    cfg_name = \"train_camelyon_ucc_drn\"\n",
        "    with initialize(version_base=None, config_path=\"../configs\"):\n",
        "        cfg = compose(config_name=cfg_name)\n",
        "\n",
        "    args = cfg.args\n",
        "    model, optimizer, step = load_model_and_optimizer(experiment_id, run_id)\n",
        "    train_loader, val_loader = init_dataloader(args)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
        "    print(optimizer)\n",
        "    print(step)\n",
        "    with mlflow.start_run(run_id=run_id, nested=True):\n",
        "        mlflow.set_experiment(experiment_id=experiment_id)\n",
        "        best_acc = train(args, model, optimizer, None,\n",
        "                    train_loader, val_loader, device, step=step)\n",
        "\n",
        "resume_training(\"67affc095c864c1ba34f32214201b08c\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFMWHXRKbXWt"
      },
      "outputs": [],
      "source": [
        "mlflow.set_tracking_uri(\"mlruns\")\n",
        "run_name = \"camelyon-ucc-drn\"\n",
        "experiment = mlflow.set_experiment(run_name)\n",
        "experiment_id = experiment.experiment_id\n",
        "cfg_name = \"train_camelyon_ucc_drn\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdc_8-oRbYQG"
      },
      "outputs": [],
      "source": [
        "experiment_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i3olSfWXbaAN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "prefix_to_replace = \"/content/gdrive/MyDrive/UCCDRNPytorch/\"\n",
        "prefix_replacement = \"/Users/tanguanyu/UCC-DRN-Pytorch/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "for root, dirs, files in  os.walk(\"mlruns/152105657986962541\"):\n",
        "    for d in dirs:\n",
        "        if d==\"models\":\n",
        "            for rt, ds, _ in os.walk(f\"{root}/models\"):\n",
        "                for d_ in ds:\n",
        "                    with open(f\"{rt}/{d_}/meta.yaml\", \"r\") as file:\n",
        "                        string = file.read()\n",
        "                        string = string.replace(prefix_to_replace, prefix_replacement)\n",
        "                    with open(f\"{rt}/{d_}/meta.yaml\", \"w\") as file:\n",
        "                        file.write(string)\n",
        "                break\n",
        "        else:\n",
        "            with open(f\"{root}/{d}/meta.yaml\", \"r\") as file:\n",
        "                string = file.read()\n",
        "                string = string.replace(prefix_to_replace, prefix_replacement)\n",
        "            with open(f\"{root}/{d}/meta.yaml\", \"w\") as file:\n",
        "                file.write(string)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"artifact_uri: /Users/tanguanyu/UCC-DRN-Pytorch/camelyon/mlruns/152105657986962541/2601d759316f40c78dc0aa8a8f21b5ad/artifacts\\nend_time: 1749875771310\\nentry_point_name: ''\\nexperiment_id: '152105657986962541'\\nlifecycle_stage: active\\nrun_id: 2601d759316f40c78dc0aa8a8f21b5ad\\nrun_name: funny-stork-278\\nsource_name: ''\\nsource_type: 4\\nsource_version: ''\\nstart_time: 1749875771065\\nstatus: 4\\ntags: []\\nuser_id: root\\n\""
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "string.replace(prefix_to_replace, prefix_replacement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"test.yaml\", \"w\") as file:\n",
        "    file.write(string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/tanguanyu/UCC-DRN-Pytorch/camelyon\n"
          ]
        }
      ],
      "source": [
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "import yaml\n",
        "for root, dirs, files in  os.walk(\"mlruns/152105657986962541\"):\n",
        "    for d in dirs:\n",
        "        if d==\"models\":\n",
        "            pass\n",
        "        else:\n",
        "            with open(f\"{root}/{d}/meta.yaml\", \"r\") as file:\n",
        "                obj = yaml.safe_load(file)\n",
        "            if \"run_uuid\" not in obj:\n",
        "                obj[\"run_uuid\"] = obj[\"run_id\"]\n",
        "                with open(f\"{root}/{d}/meta.yaml\", \"w\") as file:\n",
        "                    file.write(yaml.safe_dump(obj))\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"artifact_uri: /Users/tanguanyu/UCC-DRN-Pytorch/camelyon/mlruns/152105657986962541/2601d759316f40c78dc0aa8a8f21b5ad/artifacts\\nend_time: 1749875771310\\nentry_point_name: ''\\nexperiment_id: '152105657986962541'\\nlifecycle_stage: active\\nrun_id: 2601d759316f40c78dc0aa8a8f21b5ad\\nrun_name: funny-stork-278\\nsource_name: ''\\nsource_type: 4\\nsource_version: ''\\nstart_time: 1749875771065\\nstatus: 4\\ntags: []\\nuser_id: root\\n\""
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yaml.safe_dump(obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "filess = []\n",
        "for root, dirs, files in  os.walk(\"mlruns/152105657986962541\"):\n",
        "    for d in dirs:\n",
        "        if d==\"models\":\n",
        "            pass\n",
        "        else:\n",
        "            loss_file_path = f\"{root}/{d}/metrics/loss\"\n",
        "            if os.path.exists(loss_file_path):\n",
        "                with open(loss_file_path, \"r\") as file:\n",
        "                    string = file.read()\n",
        "                if len(string)==0:\n",
        "                    filess.append(f\"{root}/{d}\")\n",
        "            else:\n",
        "                filess.append(f\"{root}/{d}\")\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "for f in filess:\n",
        "    shutil.rmtree(f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.12.2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
