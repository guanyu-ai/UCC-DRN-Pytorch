{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f350f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models are from ucc-drn-multi-step\n",
    "# experiment 1: check if the initialized model would still converge under the same circustances\n",
    "# experiment 2: check if the initialized model would also converge under alpha=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92322418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\UCC-DRN-Pytorch\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x268c2db5fd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hydra import compose, initialize\n",
    "import omegaconf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import mlflow\n",
    "import optuna\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "from omegaconf.omegaconf import OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, OneCycleLR\n",
    "\n",
    "from model import UCCDRNModel\n",
    "from dataset import MnistDataset\n",
    "from utils import get_or_create_experiment, parse_experiment_runs_to_optuna_study\n",
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c51b34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7302e4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment 1\n",
    "run_name = \"ucc-drn-multi-step\"\n",
    "experiment_id = get_or_create_experiment(experiment_name=run_name)\n",
    "runs = mlflow.search_runs(experiment_ids=[experiment_id], output_format=\"list\")\n",
    "sucessful_runs = [run for run in runs if float(run.data.metrics[\"eval_ucc_acc\"])>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c8a23a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_1 = sucessful_runs[1]\n",
    "run_id = run_1.info.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f477cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f\"mlruns/{experiment_id}/{run_id}/artifacts/best_model.pth/data/model.pth\", weights_only=False)\n",
    "initial_model = torch.load(f\"mlruns/{experiment_id}/{run_id}/artifacts/init_model/data/model.pth\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e0e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def init_dataloader(args):\n",
    "    # assert args.dataset in [\n",
    "    #     \"mnist\",\n",
    "    #     \"camelyon\",\n",
    "    # ], \"Mode should be either mnist or camelyon\"\n",
    "    # if args.dataset == \"mnist\":\n",
    "    train_dataset_len = args.train_num_steps * args.batch_size\n",
    "    train_dataset = MnistDataset(\n",
    "        mode=\"train\",\n",
    "        num_instances=args.num_instances,\n",
    "        num_samples_per_class=args.num_samples_per_class,\n",
    "        digit_arr=list(range(args.ucc_end-args.ucc_start+1)),\n",
    "        ucc_start=args.ucc_start,\n",
    "        ucc_end=args.ucc_end,\n",
    "        length=train_dataset_len,\n",
    "    )\n",
    "    val_dataset_len = args.val_num_steps * args.batch_size\n",
    "    val_dataset = MnistDataset(\n",
    "        mode=\"val\",\n",
    "        num_instances=args.num_instances,\n",
    "        num_samples_per_class=args.num_samples_per_class,\n",
    "        digit_arr=list(range(args.ucc_end-args.ucc_start+1)),\n",
    "        ucc_start=args.ucc_start,\n",
    "        ucc_end=args.ucc_end,\n",
    "        length=val_dataset_len,\n",
    "    )\n",
    "    # create dataloader\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def evaluate(model, val_loader, device, ae_mode, clf_mode) -> dict:\n",
    "    model.eval()\n",
    "    val_ae_loss_list = []\n",
    "    val_ucc_loss_list = []\n",
    "    val_acc_list = []\n",
    "    rec_criterion = nn.MSELoss()\n",
    "    with torch.no_grad():\n",
    "        for batch_samples, batch_labels in val_loader:\n",
    "            batch_samples = batch_samples.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            if ae_mode:\n",
    "                batch_size, num_instances, num_channel, patch_size, _ = batch_samples.shape\n",
    "                x = batch_samples.view(-1, num_channel,\n",
    "                                       batch_samples.shape[-2], batch_samples.shape[-1])\n",
    "                features = model.encoder(x)\n",
    "                reconstruction = model.decoder(features)\n",
    "                reconstruction = reconstruction.view(batch_size, num_instances,\n",
    "                                    1, patch_size, patch_size)\n",
    "                ae_loss = rec_criterion(batch_samples, reconstruction)\n",
    "                val_ae_loss_list.append(ae_loss.item())\n",
    "\n",
    "            if clf_mode:\n",
    "                ucc_logits, _ = model(batch_samples)\n",
    "                ucc_val_loss = F.cross_entropy(ucc_logits, batch_labels)\n",
    "                # acculate accuracy\n",
    "                _, ucc_predicts = torch.max(ucc_logits, dim=1)\n",
    "                acc = torch.sum(\n",
    "                    ucc_predicts == batch_labels).item() / len(batch_labels)\n",
    "                val_acc_list.append(acc)\n",
    "                val_ucc_loss_list.append(ucc_val_loss.item())\n",
    "\n",
    "        if ae_mode and clf_mode:\n",
    "            return {\n",
    "                \"eval_ae_loss\": np.round(np.mean(val_ae_loss_list), 5),\n",
    "                \"eval_ucc_loss\": np.round(np.mean(val_ucc_loss_list), 5),\n",
    "                \"eval_ucc_acc\": np.round(np.mean(val_acc_list), 5)\n",
    "            }\n",
    "        elif ae_mode:\n",
    "            return {\n",
    "                \"eval_ae_loss\": np.round(np.mean(val_ae_loss_list), 5),\n",
    "            }\n",
    "        elif clf_mode:\n",
    "            return {\n",
    "                \"eval_ucc_loss\": np.round(np.mean(val_ucc_loss_list), 5),\n",
    "                \"eval_ucc_acc\": np.round(np.mean(val_acc_list), 5)\n",
    "            }\n",
    "\n",
    "\n",
    "def train(args, model, optimizer, lr_scheduler, train_loader, val_loader, device):\n",
    "    # mlflow.pytorch.log_model(model, \"init_model\")\n",
    "    # output_dir = hydra.core.hydra_config.HydraConfig.get().runtime.output_dir\n",
    "    model.train()\n",
    "    step = 0\n",
    "    best_eval_acc = 0\n",
    "    patience = 2\n",
    "    ae_steps = 500\n",
    "\n",
    "    rec_criterion = nn.MSELoss()\n",
    "    if step == 0:\n",
    "        mlflow.pytorch.log_model(\n",
    "            model,\n",
    "            \"best_model.pth\"\n",
    "        )\n",
    "    for batch_samples, batch_labels in tqdm(train_loader):\n",
    "        batch_samples = batch_samples.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if ae_steps > 0:\n",
    "            batch_size, num_instances, num_channel, patch_size, _ = batch_samples.shape\n",
    "            x = batch_samples.view(-1, num_channel,\n",
    "                                   batch_samples.shape[-2], batch_samples.shape[-1])\n",
    "            feature = model.encoder(x)\n",
    "\n",
    "            reconstruction = model.decoder(feature)\n",
    "            reconstruction = reconstruction.view(\n",
    "                batch_size, num_instances, 1, patch_size, patch_size)\n",
    "            loss = rec_criterion(batch_samples, reconstruction)\n",
    "            ae_loss = loss\n",
    "            ae_steps -= 1\n",
    "\n",
    "        if ae_steps == 0:\n",
    "            ucc_logits, reconstruction = model(batch_samples, batch_labels)\n",
    "            loss: torch.Tensor = F.cross_entropy(\n",
    "                ucc_logits,\n",
    "                batch_labels\n",
    "            )\n",
    "            ae_loss = F.mse_loss(batch_samples, reconstruction)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                metric_dict = {}\n",
    "                grad_log = {name: torch.mean(param.grad).cpu().item(\n",
    "                ) for name, param in model.named_parameters() if isinstance(param.grad, torch.Tensor)}\n",
    "                mlflow.log_metrics(grad_log, step=step)\n",
    "                metric_dict[\"train_ae_loss\"] = np.round(\n",
    "                    ae_loss.detach().item(), 5)\n",
    "                if ae_steps == 0:\n",
    "                    _, pred = torch.max(ucc_logits, dim=1)\n",
    "                    accuracy = torch.sum(\n",
    "                        pred.flatten() == batch_labels.flatten())/len(batch_labels)\n",
    "                    metric_dict[\"train_ucc_loss\"] = np.round(\n",
    "                        loss.detach().item(), 5)\n",
    "                    metric_dict[\"train_ucc_acc\"] = np.round(float(accuracy), 5)\n",
    "\n",
    "            mlflow.log_metrics(metric_dict, step=step)\n",
    "\n",
    "        if step % args.save_interval == 0:\n",
    "\n",
    "            eval_metric_dict = evaluate(\n",
    "                model,\n",
    "                val_loader,\n",
    "                device,\n",
    "                ae_mode=True,\n",
    "                clf_mode=(ae_steps == 0))\n",
    "\n",
    "            print(\n",
    "                f\"step: {step},\" + \",\".join([f\"{key}: {value}\"for key, value in eval_metric_dict.items()]))\n",
    "            mlflow.log_metrics(eval_metric_dict, step=step)\n",
    "            # early stop\n",
    "            if ae_steps == 0:\n",
    "                eval_acc = eval_metric_dict[\"eval_ucc_acc\"]\n",
    "                if eval_acc > best_eval_acc:\n",
    "                    patience = 2\n",
    "                    best_eval_acc = eval_acc\n",
    "                    mlflow.pytorch.log_model(\n",
    "                        model,\n",
    "                        \"best_model.pth\"\n",
    "                    )\n",
    "                else:\n",
    "                    patience -= 1\n",
    "\n",
    "            if patience <= 0:\n",
    "                break\n",
    "            if step == 10000:\n",
    "                break\n",
    "            model.train()\n",
    "\n",
    "    print(\"Training finished!!!\")\n",
    "    return best_eval_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fce5596",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(f\"mlruns/{experiment_id}/{run_id}/artifacts/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fbd7041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'args': {'batch_size': 20, 'dataset': 'mnist', 'learning_rate': 0.005, 'model_dir': 'saved_models/', 'model_name': 'mnist_ucc_drn', 'num_bins': 11, 'num_features': 10, 'num_instances': 32, 'num_samples_per_class': 5, 'num_workers': 4, 'save_interval': 1000, 'seed': 22, 'train_num_steps': 100000, 'ucc_end': 4, 'ucc_start': 1, 'val_num_steps': 200}, 'model': {'decoder': {'block1_num_layer': 1, 'block1_output_channel': 64, 'block2_num_layer': 1, 'block2_output_channel': 32, 'block3_num_layer': 1, 'block3_output_channel': 16, 'linear_size': 6272, 'output_channel': 1, 'reshape_size': [7, 7, 128]}, 'drn': {'hidden_q': 100, 'init_method': 'xavier_uniform', 'num_bins': 11, 'num_layers': 2, 'num_nodes': 9, 'output_bins': 4, 'output_nodes': 1}, 'encoder': {'block1_num_layer': 1, 'block1_output_channel': 321, 'block2_num_layer': 1, 'block2_output_channel': 64, 'block3_num_layer': 1, 'block3_output_channel': 128, 'conv_input_channel': 1, 'conv_output_channel': 16, 'flatten_size': 6272, 'num_features': 10}, 'input_shape': [28, 28, 1], 'kde_model': {'num_bins': 11, 'sigma': 0.1}, 'loss': {'alpha': -1}, 'num_channels': 1, 'ucc_classifier': 'None'}}\n"
     ]
    }
   ],
   "source": [
    "print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ce1d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'args': {'batch_size': 20, 'dataset': 'mnist', 'learning_rate': 0.005, 'model_dir': 'saved_models/', 'model_name': 'mnist_ucc_drn', 'num_bins': 11, 'num_features': 10, 'num_instances': 32, 'num_samples_per_class': 5, 'num_workers': 4, 'save_interval': 1000, 'seed': 22, 'train_num_steps': 100000, 'ucc_end': 4, 'ucc_start': 1, 'val_num_steps': 200}, 'model': {'decoder': {'block1_num_layer': 1, 'block1_output_channel': 64, 'block2_num_layer': 1, 'block2_output_channel': 32, 'block3_num_layer': 1, 'block3_output_channel': 16, 'linear_size': 6272, 'output_channel': 1, 'reshape_size': [7, 7, 128]}, 'drn': {'hidden_q': 100, 'init_method': 'xavier_uniform', 'num_bins': 11, 'num_layers': 2, 'num_nodes': 9, 'output_bins': 4, 'output_nodes': 1}, 'encoder': {'block1_num_layer': 1, 'block1_output_channel': 321, 'block2_num_layer': 1, 'block2_output_channel': 64, 'block3_num_layer': 1, 'block3_output_channel': 128, 'conv_input_channel': 1, 'conv_output_channel': 16, 'flatten_size': 6272, 'num_features': 10}, 'input_shape': [28, 28, 1], 'kde_model': {'num_bins': 11, 'sigma': 0.1}, 'loss': {'alpha': -1}, 'num_channels': 1, 'ucc_classifier': 'None'}}\n",
      "x_train shape: torch.Size([50000, 1, 28, 28])\n",
      "50000 train samples\n",
      "10000 val samples\n",
      "x_train shape: torch.Size([50000, 1, 28, 28])\n",
      "50000 train samples\n",
      "10000 val samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/18 20:36:14 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/18 20:36:29 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/18 20:36:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/18 20:36:29 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/18 20:36:38 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/18 20:36:38 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "  1%|          | 999/100000 [07:58<21:30:47,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1000,eval_ae_loss: 1.48017,eval_ucc_loss: 1.22309,eval_ucc_acc: 0.49575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/18 20:45:51 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/18 20:46:12 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/18 20:46:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "  2%|▏         | 1999/100000 [18:57<18:02:53,  1.51it/s] 2025/05/18 20:56:45 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2000,eval_ae_loss: 1.48795,eval_ucc_loss: 1.11717,eval_ucc_acc: 0.6495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/18 20:56:54 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/18 20:56:54 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "  3%|▎         | 2999/100000 [31:02<14:31:17,  1.86it/s] 2025/05/18 21:08:50 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3000,eval_ae_loss: 1.48912,eval_ucc_loss: 1.03602,eval_ucc_acc: 0.80025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/18 21:09:02 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/18 21:09:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "  4%|▍         | 3999/100000 [44:33<26:19:21,  1.01it/s] 2025/05/18 21:22:35 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 4000,eval_ae_loss: 1.48602,eval_ucc_loss: 1.01747,eval_ucc_acc: 0.80325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/18 21:22:51 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/18 21:22:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "  5%|▍         | 4999/100000 [1:00:29<21:51:01,  1.21it/s]2025/05/18 21:38:28 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 5000,eval_ae_loss: 1.48712,eval_ucc_loss: 0.99745,eval_ucc_acc: 0.813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/18 21:38:41 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/18 21:38:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "  6%|▌         | 6000/100000 [1:12:43<547:27:46, 20.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 6000,eval_ae_loss: 1.49043,eval_ucc_loss: 0.99573,eval_ucc_acc: 0.80775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 6999/100000 [1:22:21<17:08:02,  1.51it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 7000,eval_ae_loss: 1.48624,eval_ucc_loss: 0.98656,eval_ucc_acc: 0.79775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 6999/100000 [1:23:33<18:30:12,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlflow.set_tracking_uri(\"mlruns\")\n",
    "run_name = \"ucc-drn-multi-step-recreation-same-init\"\n",
    "experiment_id = get_or_create_experiment(experiment_name=run_name)\n",
    "mlflow.set_experiment(experiment_id=experiment_id)\n",
    "with mlflow.start_run(nested=True):\n",
    "\n",
    "    defaults = {\n",
    "        # \"init_method\": {\n",
    "        #     \"type\": \"categorical\",\n",
    "        #     \"range\": [\"uniform\", \"normal\", \"xavier_uniform\", \"xavier_normal\", \"kaiming_uniform\", \"kaiming_normal\"],\n",
    "        #     \"aliases\": [\n",
    "        #         \"model.drn.init_method\",\n",
    "        #     ]\n",
    "        # },\n",
    "        # \"num_bins\": {\n",
    "        #     \"type\": \"int\",\n",
    "        #     \"value\": 10,\n",
    "        #     \"range\": [5, 100],\n",
    "        #     \"aliases\": [\n",
    "        #         \"model.drn.num_bins\",\n",
    "        #         \"args.num_bins\",\n",
    "        #         \"model.kde_model.num_bins\"\n",
    "        #     ]\n",
    "        # },\n",
    "        \"lr\": {\n",
    "            \"type\": \"float\",\n",
    "            \"value\": 0.005,\n",
    "            \"range\": [0.008, 0.08],\n",
    "            \"aliases\": [\"args.learning_rate\"]\n",
    "        },\n",
    "        \"hidden_q\": {\n",
    "            \"type\": \"int\",\n",
    "            \"value\": 100,\n",
    "            \"range\": [4, 100],\n",
    "            \"aliases\": [\"model.drn.hidden_q\"]\n",
    "        },\n",
    "        \"num_layers\": {\n",
    "            \"type\": \"int\",\n",
    "            \"value\": 2,\n",
    "            \"range\": [1, 10],\n",
    "            \"aliases\": [\"model.drn.num_layers\"]\n",
    "        },\n",
    "        \"num_nodes\": {\n",
    "            \"type\": \"int\",\n",
    "            \"value\": 9,\n",
    "            \"range\": [1, 10],\n",
    "            \"aliases\": [\"model.drn.num_nodes\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(cfg)\n",
    "    mlflow.log_dict(dict(OmegaConf.to_object(cfg)), \"config.yaml\")\n",
    "\n",
    "    args = cfg.args\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=args.learning_rate, amsgrad=True)\n",
    "    train_loader, val_loader = init_dataloader(args)\n",
    "    mlflow.pytorch.log_model(model, \"init_model\")\n",
    "    best_acc = train(args, model, optimizer, None,\n",
    "                     train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b79318d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 11)\n",
      "(100, 100)\n",
      "(4, 100)\n"
     ]
    }
   ],
   "source": [
    "# reinitialize encoder\n",
    "\n",
    "initial_model = torch.load(f\"mlruns/{experiment_id}/{run_id}/artifacts/init_model/data/model.pth\", weights_only=False)\n",
    "new_model = UCCDRNModel(cfg)\n",
    "\n",
    "\n",
    "encoder_dict = new_model.encoder.state_dict()\n",
    "# load state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1649d839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_model.encoder.load_state_dict(encoder_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8349d779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'args': {'batch_size': 20, 'dataset': 'mnist', 'learning_rate': 0.005, 'model_dir': 'saved_models/', 'model_name': 'mnist_ucc_drn', 'num_bins': 11, 'num_features': 10, 'num_instances': 32, 'num_samples_per_class': 5, 'num_workers': 4, 'save_interval': 1000, 'seed': 22, 'train_num_steps': 100000, 'ucc_end': 4, 'ucc_start': 1, 'val_num_steps': 200}, 'model': {'decoder': {'block1_num_layer': 1, 'block1_output_channel': 64, 'block2_num_layer': 1, 'block2_output_channel': 32, 'block3_num_layer': 1, 'block3_output_channel': 16, 'linear_size': 6272, 'output_channel': 1, 'reshape_size': [7, 7, 128]}, 'drn': {'hidden_q': 100, 'init_method': 'xavier_uniform', 'num_bins': 11, 'num_layers': 2, 'num_nodes': 9, 'output_bins': 4, 'output_nodes': 1}, 'encoder': {'block1_num_layer': 1, 'block1_output_channel': 321, 'block2_num_layer': 1, 'block2_output_channel': 64, 'block3_num_layer': 1, 'block3_output_channel': 128, 'conv_input_channel': 1, 'conv_output_channel': 16, 'flatten_size': 6272, 'num_features': 10}, 'input_shape': [28, 28, 1], 'kde_model': {'num_bins': 11, 'sigma': 0.1}, 'loss': {'alpha': -1}, 'num_channels': 1, 'ucc_classifier': 'None'}}\n",
      "x_train shape: torch.Size([50000, 1, 28, 28])\n",
      "50000 train samples\n",
      "10000 val samples\n",
      "x_train shape: torch.Size([50000, 1, 28, 28])\n",
      "50000 train samples\n",
      "10000 val samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/18 23:19:10 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/18 23:19:22 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/18 23:19:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/18 23:19:22 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/18 23:19:31 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/18 23:19:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "  1%|          | 999/100000 [08:26<16:21:34,  1.68it/s]2025/05/18 23:29:09 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1000,eval_ae_loss: 1.29104,eval_ucc_loss: 0.97103,eval_ucc_acc: 0.80625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/18 23:29:20 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/18 23:29:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "  2%|▏         | 1999/100000 [18:59<13:39:07,  1.99it/s] 2025/05/18 23:39:41 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2000,eval_ae_loss: 1.28917,eval_ucc_loss: 0.96103,eval_ucc_acc: 0.82175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/18 23:39:51 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/18 23:39:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "  3%|▎         | 3000/100000 [30:54<570:15:46, 21.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3000,eval_ae_loss: 1.28838,eval_ucc_loss: 0.96541,eval_ucc_acc: 0.8145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3999/100000 [40:09<13:13:45,  2.02it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 4000,eval_ae_loss: 1.29037,eval_ucc_loss: 0.96947,eval_ucc_acc: 0.8105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 3999/100000 [41:20<16:32:15,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlflow.set_tracking_uri(\"mlruns\")\n",
    "run_name = \"ucc-drn-multi-step-recreation-same-init\"\n",
    "experiment_id = get_or_create_experiment(experiment_name=run_name)\n",
    "mlflow.set_experiment(experiment_id=experiment_id)\n",
    "with mlflow.start_run(nested=True, run_name=\"substituted_encoder\"):\n",
    "\n",
    "    defaults = {\n",
    "        # \"init_method\": {\n",
    "        #     \"type\": \"categorical\",\n",
    "        #     \"range\": [\"uniform\", \"normal\", \"xavier_uniform\", \"xavier_normal\", \"kaiming_uniform\", \"kaiming_normal\"],\n",
    "        #     \"aliases\": [\n",
    "        #         \"model.drn.init_method\",\n",
    "        #     ]\n",
    "        # },\n",
    "        # \"num_bins\": {\n",
    "        #     \"type\": \"int\",\n",
    "        #     \"value\": 10,\n",
    "        #     \"range\": [5, 100],\n",
    "        #     \"aliases\": [\n",
    "        #         \"model.drn.num_bins\",\n",
    "        #         \"args.num_bins\",\n",
    "        #         \"model.kde_model.num_bins\"\n",
    "        #     ]\n",
    "        # },\n",
    "        \"lr\": {\n",
    "            \"type\": \"float\",\n",
    "            \"value\": 0.005,\n",
    "            \"range\": [0.008, 0.08],\n",
    "            \"aliases\": [\"args.learning_rate\"]\n",
    "        },\n",
    "        \"hidden_q\": {\n",
    "            \"type\": \"int\",\n",
    "            \"value\": 100,\n",
    "            \"range\": [4, 100],\n",
    "            \"aliases\": [\"model.drn.hidden_q\"]\n",
    "        },\n",
    "        \"num_layers\": {\n",
    "            \"type\": \"int\",\n",
    "            \"value\": 2,\n",
    "            \"range\": [1, 10],\n",
    "            \"aliases\": [\"model.drn.num_layers\"]\n",
    "        },\n",
    "        \"num_nodes\": {\n",
    "            \"type\": \"int\",\n",
    "            \"value\": 9,\n",
    "            \"range\": [1, 10],\n",
    "            \"aliases\": [\"model.drn.num_nodes\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(cfg)\n",
    "    mlflow.log_dict(dict(OmegaConf.to_object(cfg)), \"config.yaml\")\n",
    "\n",
    "    args = cfg.args\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        initial_model.parameters(), lr=args.learning_rate, amsgrad=True)\n",
    "    train_loader, val_loader = init_dataloader(args)\n",
    "    mlflow.pytorch.log_model(initial_model, \"init_model\")\n",
    "    best_acc = train(args, model, optimizer, None,\n",
    "                     train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7480cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_initial_model = torch.load(f\"mlruns/{experiment_id}/{sucessful_runs[1].info.run_id}/artifacts/init_model/data/model.pth\", weights_only=False)\n",
    "\n",
    "drn_model = new_initial_model.ucc_classifier\n",
    "layers = list(drn_model.modules())[1:-1]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with torch.no_grad():\n",
    "    for layer in layers:\n",
    "        weights = layer.W.transpose(1,0).cpu().detach().numpy()\n",
    "        b_a = layer.ba.cpu().detach().numpy()\n",
    "        b_q = layer.bq.cpu().detach().numpy()\n",
    "        lama = layer.lama.cpu().detach().numpy()\n",
    "        lamq = layer.lamq.cpu().detach().numpy()\n",
    "        for weight in weights:\n",
    "            plt.scatter(range(len(weight)),weight)\n",
    "        plt.show()\n",
    "        plt.scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d8a72a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 10])\n",
      "b_a_0\n",
      "Parameter containing:\n",
      "tensor([[ 0.1863],\n",
      "        [-0.2506],\n",
      "        [ 0.0959],\n",
      "        [-0.1937],\n",
      "        [ 0.2539],\n",
      "        [-0.0005],\n",
      "        [-0.2566],\n",
      "        [ 0.2855],\n",
      "        [ 0.2728]], device='cuda:0', requires_grad=True)\n",
      "b_q_0\n",
      "Parameter containing:\n",
      "tensor([[-0.1282],\n",
      "        [ 0.2378],\n",
      "        [ 0.1510],\n",
      "        [-0.0034],\n",
      "        [-0.0597],\n",
      "        [-0.2492],\n",
      "        [-0.2633],\n",
      "        [-0.1694],\n",
      "        [ 0.1526]], device='cuda:0', requires_grad=True)\n",
      "lam_a_0\n",
      "Parameter containing:\n",
      "tensor([[0.2792],\n",
      "        [0.3202],\n",
      "        [0.4613],\n",
      "        [0.4577],\n",
      "        [0.9302],\n",
      "        [0.1173],\n",
      "        [0.1408],\n",
      "        [0.0528],\n",
      "        [0.1193]], device='cuda:0', requires_grad=True)\n",
      "lam_q_0\n",
      "Parameter containing:\n",
      "tensor([[0.6827],\n",
      "        [0.7361],\n",
      "        [0.4714],\n",
      "        [0.3601],\n",
      "        [0.4410],\n",
      "        [0.2559],\n",
      "        [0.1342],\n",
      "        [0.7681],\n",
      "        [0.7807]], device='cuda:0', requires_grad=True)\n",
      "torch.Size([9, 9])\n",
      "b_a_1\n",
      "Parameter containing:\n",
      "tensor([[ 0.2757],\n",
      "        [ 0.1012],\n",
      "        [-0.1337],\n",
      "        [ 0.2449],\n",
      "        [-0.1997],\n",
      "        [ 0.0336],\n",
      "        [-0.2837],\n",
      "        [ 0.2830],\n",
      "        [-0.1957]], device='cuda:0', requires_grad=True)\n",
      "b_q_1\n",
      "Parameter containing:\n",
      "tensor([[ 0.2607],\n",
      "        [-0.2847],\n",
      "        [ 0.2174],\n",
      "        [ 0.3259],\n",
      "        [-0.3291],\n",
      "        [-0.1393],\n",
      "        [-0.2695],\n",
      "        [ 0.0667],\n",
      "        [-0.2988]], device='cuda:0', requires_grad=True)\n",
      "lam_a_1\n",
      "Parameter containing:\n",
      "tensor([[0.8000],\n",
      "        [0.7471],\n",
      "        [0.4973],\n",
      "        [0.3333],\n",
      "        [0.4726],\n",
      "        [0.9785],\n",
      "        [0.3268],\n",
      "        [0.5051],\n",
      "        [0.3882]], device='cuda:0', requires_grad=True)\n",
      "lam_q_1\n",
      "Parameter containing:\n",
      "tensor([[0.6212],\n",
      "        [0.5064],\n",
      "        [0.0845],\n",
      "        [0.2740],\n",
      "        [0.5456],\n",
      "        [0.4056],\n",
      "        [0.2039],\n",
      "        [0.8584],\n",
      "        [0.0396]], device='cuda:0', requires_grad=True)\n",
      "torch.Size([1, 9])\n",
      "b_a_2\n",
      "Parameter containing:\n",
      "tensor([[-0.3166]], device='cuda:0', requires_grad=True)\n",
      "b_q_2\n",
      "Parameter containing:\n",
      "tensor([[-0.0036]], device='cuda:0', requires_grad=True)\n",
      "lam_a_2\n",
      "Parameter containing:\n",
      "tensor([[0.6472]], device='cuda:0', requires_grad=True)\n",
      "lam_q_2\n",
      "Parameter containing:\n",
      "tensor([[0.8162]], device='cuda:0', requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for index, layer in enumerate(layers):\n",
    "    print(layer.W.shape)\n",
    "    print(f\"b_a_{index}\")\n",
    "    print(layer.ba)\n",
    "    print(f\"b_q_{index}\")\n",
    "    print(layer.bq)\n",
    "    print(f\"lam_a_{index}\")\n",
    "    print(layer.lama)\n",
    "    print(f\"lam_q_{index}\")\n",
    "    print(layer.lamq)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bb66eaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.81225\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.90875\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "records = []\n",
    "for run in runs:\n",
    "    record_dict = {}\n",
    "    \n",
    "    new_init_model = torch.load(f\"mlruns/{experiment_id}/{run.info.run_id}/artifacts/init_model/data/model.pth\", weights_only=False)\n",
    "    drn = new_init_model.ucc_classifier\n",
    "    layers = list(drn.modules())[1:-1]\n",
    "    print(run.data.metrics[\"eval_ucc_acc\"])\n",
    "    \n",
    "    for index, layer in enumerate(layers):\n",
    "        weights = layer.W.detach().cpu().numpy()\n",
    "        record_dict[f\"weights_{index}_std\"] = weights.std()\n",
    "        record_dict[f\"weights_{index}_mean\"] = weights.mean()\n",
    "        \n",
    "        bias_a = layer.ba.detach().cpu().numpy()\n",
    "        record_dict[f\"bias_a_{index}_std\"] = bias_a.std()\n",
    "        record_dict[f\"bias_a_{index}_mean\"] = bias_a.mean()\n",
    "        \n",
    "        bias_q = layer.bq.detach().cpu().numpy()\n",
    "        record_dict[f\"bias_q_{index}_std\"] = bias_q.std()\n",
    "        record_dict[f\"bias_q_{index}_mean\"] = bias_q.mean()\n",
    "        \n",
    "        record_dict[f\"lambda_a_{index}_std\"] = layer.lama.detach().cpu().numpy().std()\n",
    "        record_dict[f\"lambda_a_{index}_mean\"] = layer.lama.detach().cpu().numpy().mean()\n",
    "        record_dict[f\"lambda_q_{index}_std\"] = layer.lamq.detach().cpu().numpy().std()\n",
    "        record_dict[f\"lambda_q_{index}_mean\"] = layer.lamq.detach().cpu().numpy().mean()\n",
    "        \n",
    "    record_dict[\"acc\"] = run.data.metrics[\"eval_ucc_acc\"]\n",
    "    records.append(record_dict)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cb17ecd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'weights_0_std': 0.32177463,\n",
       "  'weights_0_mean': 0.05391548,\n",
       "  'bias_a_0_std': 0.20895219,\n",
       "  'bias_a_0_mean': -0.006174455,\n",
       "  'bias_q_0_std': 0.1309087,\n",
       "  'bias_q_0_mean': -0.074829236,\n",
       "  'lambda_a_0_std': 0.340735,\n",
       "  'lambda_a_0_mean': 0.46042743,\n",
       "  'lambda_q_0_std': 0.2839391,\n",
       "  'lambda_q_0_mean': 0.3668749,\n",
       "  'weights_1_std': 0.2900124,\n",
       "  'weights_1_mean': 0.023747973,\n",
       "  'bias_a_1_std': 0.1790416,\n",
       "  'bias_a_1_mean': 0.014829354,\n",
       "  'bias_q_1_std': 0.16898686,\n",
       "  'bias_q_1_mean': 0.07317514,\n",
       "  'lambda_a_1_std': 0.2220997,\n",
       "  'lambda_a_1_mean': 0.5977582,\n",
       "  'lambda_q_1_std': 0.2734221,\n",
       "  'lambda_q_1_mean': 0.47675562,\n",
       "  'weights_2_std': 0.49250466,\n",
       "  'weights_2_mean': -0.22220376,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.038149804,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.022425205,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.23235112,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.35825145,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.32354942,\n",
       "  'weights_0_mean': -0.010821161,\n",
       "  'bias_a_0_std': 0.19997372,\n",
       "  'bias_a_0_mean': -0.09799463,\n",
       "  'bias_q_0_std': 0.16529095,\n",
       "  'bias_q_0_mean': -0.0040431074,\n",
       "  'lambda_a_0_std': 0.2229991,\n",
       "  'lambda_a_0_mean': 0.61087424,\n",
       "  'lambda_q_0_std': 0.2642305,\n",
       "  'lambda_q_0_mean': 0.49238333,\n",
       "  'weights_1_std': 0.29089263,\n",
       "  'weights_1_mean': 0.034629446,\n",
       "  'bias_a_1_std': 0.21431988,\n",
       "  'bias_a_1_mean': 0.03317108,\n",
       "  'bias_q_1_std': 0.18187276,\n",
       "  'bias_q_1_mean': 0.008500899,\n",
       "  'lambda_a_1_std': 0.22471236,\n",
       "  'lambda_a_1_mean': 0.33233476,\n",
       "  'lambda_q_1_std': 0.30011138,\n",
       "  'lambda_q_1_mean': 0.6647445,\n",
       "  'weights_2_std': 0.40269592,\n",
       "  'weights_2_mean': 0.016238153,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.09413636,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.14151542,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.5748133,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.65729517,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.29264587,\n",
       "  'weights_0_mean': 0.06932346,\n",
       "  'bias_a_0_std': 0.21710074,\n",
       "  'bias_a_0_mean': 0.021970801,\n",
       "  'bias_q_0_std': 0.17042261,\n",
       "  'bias_q_0_mean': -0.10502528,\n",
       "  'lambda_a_0_std': 0.2862667,\n",
       "  'lambda_a_0_mean': 0.45261437,\n",
       "  'lambda_q_0_std': 0.27021512,\n",
       "  'lambda_q_0_mean': 0.5516813,\n",
       "  'weights_1_std': 0.34298137,\n",
       "  'weights_1_mean': 0.060525965,\n",
       "  'bias_a_1_std': 0.1421318,\n",
       "  'bias_a_1_mean': 0.06514611,\n",
       "  'bias_q_1_std': 0.22528505,\n",
       "  'bias_q_1_mean': 0.09662971,\n",
       "  'lambda_a_1_std': 0.32251063,\n",
       "  'lambda_a_1_mean': 0.5508662,\n",
       "  'lambda_q_1_std': 0.28339565,\n",
       "  'lambda_q_1_mean': 0.5888481,\n",
       "  'weights_2_std': 0.5276492,\n",
       "  'weights_2_mean': -0.061889622,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.06059906,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.30978397,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.74081254,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.50077254,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.327465,\n",
       "  'weights_0_mean': 0.0075014182,\n",
       "  'bias_a_0_std': 0.19627787,\n",
       "  'bias_a_0_mean': -0.08397725,\n",
       "  'bias_q_0_std': 0.20203544,\n",
       "  'bias_q_0_mean': 0.05484917,\n",
       "  'lambda_a_0_std': 0.19480588,\n",
       "  'lambda_a_0_mean': 0.38065135,\n",
       "  'lambda_q_0_std': 0.24177784,\n",
       "  'lambda_q_0_mean': 0.34017265,\n",
       "  'weights_1_std': 0.31589854,\n",
       "  'weights_1_mean': -0.034127146,\n",
       "  'bias_a_1_std': 0.21930416,\n",
       "  'bias_a_1_mean': 0.11097399,\n",
       "  'bias_q_1_std': 0.19369097,\n",
       "  'bias_q_1_mean': 0.010578775,\n",
       "  'lambda_a_1_std': 0.3251846,\n",
       "  'lambda_a_1_mean': 0.28255877,\n",
       "  'lambda_q_1_std': 0.264031,\n",
       "  'lambda_q_1_mean': 0.61718434,\n",
       "  'weights_2_std': 0.3337491,\n",
       "  'weights_2_mean': -0.11093754,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.037956864,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.13388193,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.5134074,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.099888206,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.2994237,\n",
       "  'weights_0_mean': -0.047711775,\n",
       "  'bias_a_0_std': 0.16646549,\n",
       "  'bias_a_0_mean': 0.023635264,\n",
       "  'bias_q_0_std': 0.09591156,\n",
       "  'bias_q_0_mean': -0.013653517,\n",
       "  'lambda_a_0_std': 0.32213804,\n",
       "  'lambda_a_0_mean': 0.54410565,\n",
       "  'lambda_q_0_std': 0.26263687,\n",
       "  'lambda_q_0_mean': 0.5369658,\n",
       "  'weights_1_std': 0.33980742,\n",
       "  'weights_1_mean': -0.023860874,\n",
       "  'bias_a_1_std': 0.21974233,\n",
       "  'bias_a_1_mean': -0.019073674,\n",
       "  'bias_q_1_std': 0.13364081,\n",
       "  'bias_q_1_mean': 0.08561739,\n",
       "  'lambda_a_1_std': 0.28098652,\n",
       "  'lambda_a_1_mean': 0.54749864,\n",
       "  'lambda_q_1_std': 0.20637044,\n",
       "  'lambda_q_1_mean': 0.7094143,\n",
       "  'weights_2_std': 0.29054278,\n",
       "  'weights_2_mean': -0.2650899,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.08108604,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.043184876,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.21689159,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.1890223,\n",
       "  'acc': 0.81225},\n",
       " {'weights_0_std': 0.3140138,\n",
       "  'weights_0_mean': 0.078402564,\n",
       "  'bias_a_0_std': 0.20461796,\n",
       "  'bias_a_0_mean': -0.0031683147,\n",
       "  'bias_q_0_std': 0.12534039,\n",
       "  'bias_q_0_mean': 0.0026949644,\n",
       "  'lambda_a_0_std': 0.1650144,\n",
       "  'lambda_a_0_mean': 0.46207225,\n",
       "  'lambda_q_0_std': 0.22121985,\n",
       "  'lambda_q_0_mean': 0.60177875,\n",
       "  'weights_1_std': 0.3357422,\n",
       "  'weights_1_mean': 0.06853591,\n",
       "  'bias_a_1_std': 0.16037597,\n",
       "  'bias_a_1_mean': -0.04269737,\n",
       "  'bias_q_1_std': 0.21718518,\n",
       "  'bias_q_1_mean': -0.08282557,\n",
       "  'lambda_a_1_std': 0.26774183,\n",
       "  'lambda_a_1_mean': 0.5480323,\n",
       "  'lambda_q_1_std': 0.22247428,\n",
       "  'lambda_q_1_mean': 0.5427588,\n",
       "  'weights_2_std': 0.27464134,\n",
       "  'weights_2_mean': 0.35731784,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.08580899,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.15642385,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.15781397,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.8719981,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.33754972,\n",
       "  'weights_0_mean': 0.028466707,\n",
       "  'bias_a_0_std': 0.12537244,\n",
       "  'bias_a_0_mean': -0.047667347,\n",
       "  'bias_q_0_std': 0.06668563,\n",
       "  'bias_q_0_mean': 0.08438154,\n",
       "  'lambda_a_0_std': 0.2603507,\n",
       "  'lambda_a_0_mean': 0.46819735,\n",
       "  'lambda_q_0_std': 0.27391985,\n",
       "  'lambda_q_0_mean': 0.4868997,\n",
       "  'weights_1_std': 0.306132,\n",
       "  'weights_1_mean': -0.0152758695,\n",
       "  'bias_a_1_std': 0.16862482,\n",
       "  'bias_a_1_mean': 0.015396506,\n",
       "  'bias_q_1_std': 0.20412812,\n",
       "  'bias_q_1_mean': 0.062405653,\n",
       "  'lambda_a_1_std': 0.32829002,\n",
       "  'lambda_a_1_mean': 0.5597722,\n",
       "  'lambda_q_1_std': 0.2603451,\n",
       "  'lambda_q_1_mean': 0.49629104,\n",
       "  'weights_2_std': 0.46794438,\n",
       "  'weights_2_mean': -0.20279042,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.24751219,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.2506116,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.0007495284,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.11430198,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.30848005,\n",
       "  'weights_0_mean': -0.019163046,\n",
       "  'bias_a_0_std': 0.17900774,\n",
       "  'bias_a_0_mean': 0.044738095,\n",
       "  'bias_q_0_std': 0.15918005,\n",
       "  'bias_q_0_mean': 0.06501777,\n",
       "  'lambda_a_0_std': 0.30873275,\n",
       "  'lambda_a_0_mean': 0.33876643,\n",
       "  'lambda_q_0_std': 0.22413108,\n",
       "  'lambda_q_0_mean': 0.5503484,\n",
       "  'weights_1_std': 0.32928225,\n",
       "  'weights_1_mean': -0.0037543376,\n",
       "  'bias_a_1_std': 0.20847917,\n",
       "  'bias_a_1_mean': 0.0010207726,\n",
       "  'bias_q_1_std': 0.12597984,\n",
       "  'bias_q_1_mean': 0.006683636,\n",
       "  'lambda_a_1_std': 0.2271547,\n",
       "  'lambda_a_1_mean': 0.66346,\n",
       "  'lambda_q_1_std': 0.2530185,\n",
       "  'lambda_q_1_mean': 0.5075196,\n",
       "  'weights_2_std': 0.47007573,\n",
       "  'weights_2_mean': 0.013013297,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.1313133,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.22289535,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.50857145,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.996174,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.2942445,\n",
       "  'weights_0_mean': 0.01171762,\n",
       "  'bias_a_0_std': 0.16912922,\n",
       "  'bias_a_0_mean': -0.030568859,\n",
       "  'bias_q_0_std': 0.21083254,\n",
       "  'bias_q_0_mean': -0.023238368,\n",
       "  'lambda_a_0_std': 0.25133604,\n",
       "  'lambda_a_0_mean': 0.5078752,\n",
       "  'lambda_q_0_std': 0.31728938,\n",
       "  'lambda_q_0_mean': 0.43659124,\n",
       "  'weights_1_std': 0.30814224,\n",
       "  'weights_1_mean': -0.03171656,\n",
       "  'bias_a_1_std': 0.16226703,\n",
       "  'bias_a_1_mean': -0.08441918,\n",
       "  'bias_q_1_std': 0.18263406,\n",
       "  'bias_q_1_mean': 0.07878787,\n",
       "  'lambda_a_1_std': 0.22566938,\n",
       "  'lambda_a_1_mean': 0.58353984,\n",
       "  'lambda_q_1_std': 0.26872247,\n",
       "  'lambda_q_1_mean': 0.42629662,\n",
       "  'weights_2_std': 0.32492656,\n",
       "  'weights_2_mean': -0.17691594,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.035292953,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.23385778,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.3598907,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.23581779,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.30964896,\n",
       "  'weights_0_mean': -0.02187609,\n",
       "  'bias_a_0_std': 0.14775982,\n",
       "  'bias_a_0_mean': -0.021969672,\n",
       "  'bias_q_0_std': 0.1815585,\n",
       "  'bias_q_0_mean': 0.009862769,\n",
       "  'lambda_a_0_std': 0.32822058,\n",
       "  'lambda_a_0_mean': 0.38289076,\n",
       "  'lambda_q_0_std': 0.26614955,\n",
       "  'lambda_q_0_mean': 0.4552998,\n",
       "  'weights_1_std': 0.34127954,\n",
       "  'weights_1_mean': -0.040078633,\n",
       "  'bias_a_1_std': 0.1896703,\n",
       "  'bias_a_1_mean': -0.039403785,\n",
       "  'bias_q_1_std': 0.16502763,\n",
       "  'bias_q_1_mean': 0.017977346,\n",
       "  'lambda_a_1_std': 0.30211484,\n",
       "  'lambda_a_1_mean': 0.6698644,\n",
       "  'lambda_q_1_std': 0.25744742,\n",
       "  'lambda_q_1_mean': 0.45181486,\n",
       "  'weights_2_std': 0.4289097,\n",
       "  'weights_2_mean': 0.1324157,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.08487134,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.19384465,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.7960875,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.9969835,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3102639,\n",
       "  'weights_0_mean': 0.012976208,\n",
       "  'bias_a_0_std': 0.22014035,\n",
       "  'bias_a_0_mean': -0.050611235,\n",
       "  'bias_q_0_std': 0.15405527,\n",
       "  'bias_q_0_mean': -0.077684514,\n",
       "  'lambda_a_0_std': 0.25016004,\n",
       "  'lambda_a_0_mean': 0.4867089,\n",
       "  'lambda_q_0_std': 0.3637646,\n",
       "  'lambda_q_0_mean': 0.56757337,\n",
       "  'weights_1_std': 0.3281249,\n",
       "  'weights_1_mean': -0.03862906,\n",
       "  'bias_a_1_std': 0.10817887,\n",
       "  'bias_a_1_mean': 0.05505724,\n",
       "  'bias_q_1_std': 0.16756669,\n",
       "  'bias_q_1_mean': -0.062014367,\n",
       "  'lambda_a_1_std': 0.31681022,\n",
       "  'lambda_a_1_mean': 0.46335867,\n",
       "  'lambda_q_1_std': 0.2864549,\n",
       "  'lambda_q_1_mean': 0.41264987,\n",
       "  'weights_2_std': 0.4022698,\n",
       "  'weights_2_mean': 0.15561822,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.32661563,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.22360751,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.96549976,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.32091796,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.2993405,\n",
       "  'weights_0_mean': 0.049818028,\n",
       "  'bias_a_0_std': 0.16649841,\n",
       "  'bias_a_0_mean': -0.023667715,\n",
       "  'bias_q_0_std': 0.1802388,\n",
       "  'bias_q_0_mean': -0.05007767,\n",
       "  'lambda_a_0_std': 0.2777101,\n",
       "  'lambda_a_0_mean': 0.47776943,\n",
       "  'lambda_q_0_std': 0.2748089,\n",
       "  'lambda_q_0_mean': 0.40651694,\n",
       "  'weights_1_std': 0.3386973,\n",
       "  'weights_1_mean': 0.057710566,\n",
       "  'bias_a_1_std': 0.22066098,\n",
       "  'bias_a_1_mean': 0.11042713,\n",
       "  'bias_q_1_std': 0.13754204,\n",
       "  'bias_q_1_mean': -0.04142276,\n",
       "  'lambda_a_1_std': 0.26374593,\n",
       "  'lambda_a_1_mean': 0.486785,\n",
       "  'lambda_q_1_std': 0.34365627,\n",
       "  'lambda_q_1_mean': 0.39652407,\n",
       "  'weights_2_std': 0.546415,\n",
       "  'weights_2_mean': 0.062005553,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.1601871,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.11781101,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.10051274,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.42941225,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3099808,\n",
       "  'weights_0_mean': 0.031240432,\n",
       "  'bias_a_0_std': 0.14467795,\n",
       "  'bias_a_0_mean': 0.020291002,\n",
       "  'bias_q_0_std': 0.17531285,\n",
       "  'bias_q_0_mean': -0.037074268,\n",
       "  'lambda_a_0_std': 0.30073965,\n",
       "  'lambda_a_0_mean': 0.357168,\n",
       "  'lambda_q_0_std': 0.29896343,\n",
       "  'lambda_q_0_mean': 0.43299067,\n",
       "  'weights_1_std': 0.30830574,\n",
       "  'weights_1_mean': 0.05661364,\n",
       "  'bias_a_1_std': 0.102602735,\n",
       "  'bias_a_1_mean': 0.107526354,\n",
       "  'bias_q_1_std': 0.15157124,\n",
       "  'bias_q_1_mean': 0.03274946,\n",
       "  'lambda_a_1_std': 0.27332255,\n",
       "  'lambda_a_1_mean': 0.4117156,\n",
       "  'lambda_q_1_std': 0.35575414,\n",
       "  'lambda_q_1_mean': 0.43526113,\n",
       "  'weights_2_std': 0.501801,\n",
       "  'weights_2_mean': -0.08803727,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.29083097,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.08463848,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.14384371,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.7698247,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.32869726,\n",
       "  'weights_0_mean': 0.026478384,\n",
       "  'bias_a_0_std': 0.11120027,\n",
       "  'bias_a_0_mean': -0.03707145,\n",
       "  'bias_q_0_std': 0.19945985,\n",
       "  'bias_q_0_mean': -0.03964313,\n",
       "  'lambda_a_0_std': 0.28269958,\n",
       "  'lambda_a_0_mean': 0.43366152,\n",
       "  'lambda_q_0_std': 0.30032218,\n",
       "  'lambda_q_0_mean': 0.42303333,\n",
       "  'weights_1_std': 0.31218982,\n",
       "  'weights_1_mean': 0.022100955,\n",
       "  'bias_a_1_std': 0.18836714,\n",
       "  'bias_a_1_mean': 0.054115076,\n",
       "  'bias_q_1_std': 0.16634336,\n",
       "  'bias_q_1_mean': -0.069520034,\n",
       "  'lambda_a_1_std': 0.3166249,\n",
       "  'lambda_a_1_mean': 0.6426601,\n",
       "  'lambda_q_1_std': 0.22225818,\n",
       "  'lambda_q_1_mean': 0.339734,\n",
       "  'weights_2_std': 0.33563313,\n",
       "  'weights_2_mean': 0.020474765,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.070387036,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.3038479,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.6579826,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.05652094,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.31255296,\n",
       "  'weights_0_mean': 0.0050075226,\n",
       "  'bias_a_0_std': 0.2184423,\n",
       "  'bias_a_0_mean': -0.09016579,\n",
       "  'bias_q_0_std': 0.13964882,\n",
       "  'bias_q_0_mean': 0.07406914,\n",
       "  'lambda_a_0_std': 0.2677584,\n",
       "  'lambda_a_0_mean': 0.59611994,\n",
       "  'lambda_q_0_std': 0.32988065,\n",
       "  'lambda_q_0_mean': 0.43688223,\n",
       "  'weights_1_std': 0.32911935,\n",
       "  'weights_1_mean': -0.008688158,\n",
       "  'bias_a_1_std': 0.20247778,\n",
       "  'bias_a_1_mean': -0.13886973,\n",
       "  'bias_q_1_std': 0.21790147,\n",
       "  'bias_q_1_mean': -0.024978032,\n",
       "  'lambda_a_1_std': 0.25303507,\n",
       "  'lambda_a_1_mean': 0.4043986,\n",
       "  'lambda_q_1_std': 0.28766507,\n",
       "  'lambda_q_1_mean': 0.56872785,\n",
       "  'weights_2_std': 0.4509234,\n",
       "  'weights_2_mean': 0.031487558,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.20440748,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.27812228,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.4350381,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.23982882,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3050966,\n",
       "  'weights_0_mean': 0.053040758,\n",
       "  'bias_a_0_std': 0.1930057,\n",
       "  'bias_a_0_mean': -0.016781172,\n",
       "  'bias_q_0_std': 0.16306353,\n",
       "  'bias_q_0_mean': -0.0061740926,\n",
       "  'lambda_a_0_std': 0.3315948,\n",
       "  'lambda_a_0_mean': 0.4007314,\n",
       "  'lambda_q_0_std': 0.34216243,\n",
       "  'lambda_q_0_mean': 0.40203473,\n",
       "  'weights_1_std': 0.33155295,\n",
       "  'weights_1_mean': -0.019013012,\n",
       "  'bias_a_1_std': 0.2440382,\n",
       "  'bias_a_1_mean': 0.050514486,\n",
       "  'bias_q_1_std': 0.20321961,\n",
       "  'bias_q_1_mean': 0.07799844,\n",
       "  'lambda_a_1_std': 0.290526,\n",
       "  'lambda_a_1_mean': 0.37770203,\n",
       "  'lambda_q_1_std': 0.2190716,\n",
       "  'lambda_q_1_mean': 0.42972103,\n",
       "  'weights_2_std': 0.3607008,\n",
       "  'weights_2_mean': -0.069275886,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.24832371,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.24588457,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.34446675,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.65723246,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.33000833,\n",
       "  'weights_0_mean': 0.018512402,\n",
       "  'bias_a_0_std': 0.17144483,\n",
       "  'bias_a_0_mean': 0.073149696,\n",
       "  'bias_q_0_std': 0.1873015,\n",
       "  'bias_q_0_mean': 0.022026595,\n",
       "  'lambda_a_0_std': 0.26150045,\n",
       "  'lambda_a_0_mean': 0.4801727,\n",
       "  'lambda_q_0_std': 0.27618894,\n",
       "  'lambda_q_0_mean': 0.44651598,\n",
       "  'weights_1_std': 0.3115115,\n",
       "  'weights_1_mean': 0.088966906,\n",
       "  'bias_a_1_std': 0.14889766,\n",
       "  'bias_a_1_mean': 0.095590025,\n",
       "  'bias_q_1_std': 0.18588652,\n",
       "  'bias_q_1_mean': 0.007970661,\n",
       "  'lambda_a_1_std': 0.18772498,\n",
       "  'lambda_a_1_mean': 0.47492048,\n",
       "  'lambda_q_1_std': 0.2620309,\n",
       "  'lambda_q_1_mean': 0.5011791,\n",
       "  'weights_2_std': 0.5255943,\n",
       "  'weights_2_mean': -0.066569485,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.1162256,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.16700515,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.0042905807,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.26265365,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3022226,\n",
       "  'weights_0_mean': -0.050203435,\n",
       "  'bias_a_0_std': 0.20032988,\n",
       "  'bias_a_0_mean': 0.01786903,\n",
       "  'bias_q_0_std': 0.20577459,\n",
       "  'bias_q_0_mean': -0.08856836,\n",
       "  'lambda_a_0_std': 0.24062014,\n",
       "  'lambda_a_0_mean': 0.49127662,\n",
       "  'lambda_q_0_std': 0.2671064,\n",
       "  'lambda_q_0_mean': 0.4768894,\n",
       "  'weights_1_std': 0.30076462,\n",
       "  'weights_1_mean': -0.02268776,\n",
       "  'bias_a_1_std': 0.19334814,\n",
       "  'bias_a_1_mean': -0.016484397,\n",
       "  'bias_q_1_std': 0.20340735,\n",
       "  'bias_q_1_mean': 0.007666806,\n",
       "  'lambda_a_1_std': 0.24080427,\n",
       "  'lambda_a_1_mean': 0.7199578,\n",
       "  'lambda_q_1_std': 0.19958213,\n",
       "  'lambda_q_1_mean': 0.2861843,\n",
       "  'weights_2_std': 0.4434877,\n",
       "  'weights_2_mean': -0.04306355,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.0359765,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.048580438,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.10851848,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.56410635,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.32469964,\n",
       "  'weights_0_mean': -0.010873697,\n",
       "  'bias_a_0_std': 0.18177246,\n",
       "  'bias_a_0_mean': -0.07176951,\n",
       "  'bias_q_0_std': 0.24524017,\n",
       "  'bias_q_0_mean': -0.0024467972,\n",
       "  'lambda_a_0_std': 0.27906147,\n",
       "  'lambda_a_0_mean': 0.42442095,\n",
       "  'lambda_q_0_std': 0.20458257,\n",
       "  'lambda_q_0_mean': 0.6317313,\n",
       "  'weights_1_std': 0.3425575,\n",
       "  'weights_1_mean': -0.01875519,\n",
       "  'bias_a_1_std': 0.17971984,\n",
       "  'bias_a_1_mean': -0.043919127,\n",
       "  'bias_q_1_std': 0.20726264,\n",
       "  'bias_q_1_mean': -0.02027352,\n",
       "  'lambda_a_1_std': 0.27694717,\n",
       "  'lambda_a_1_mean': 0.3199834,\n",
       "  'lambda_q_1_std': 0.28078797,\n",
       "  'lambda_q_1_mean': 0.56450176,\n",
       "  'weights_2_std': 0.44492862,\n",
       "  'weights_2_mean': -0.11003576,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.096146256,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.07327446,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.5087295,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.89463,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.30817968,\n",
       "  'weights_0_mean': -0.007903334,\n",
       "  'bias_a_0_std': 0.13437913,\n",
       "  'bias_a_0_mean': 0.1065524,\n",
       "  'bias_q_0_std': 0.1727257,\n",
       "  'bias_q_0_mean': 0.041095033,\n",
       "  'lambda_a_0_std': 0.28638816,\n",
       "  'lambda_a_0_mean': 0.64898074,\n",
       "  'lambda_q_0_std': 0.2170407,\n",
       "  'lambda_q_0_mean': 0.63457966,\n",
       "  'weights_1_std': 0.31948608,\n",
       "  'weights_1_mean': 0.030802727,\n",
       "  'bias_a_1_std': 0.18411413,\n",
       "  'bias_a_1_mean': 0.14463148,\n",
       "  'bias_q_1_std': 0.16274153,\n",
       "  'bias_q_1_mean': -0.12828025,\n",
       "  'lambda_a_1_std': 0.24066857,\n",
       "  'lambda_a_1_mean': 0.5646395,\n",
       "  'lambda_q_1_std': 0.29178312,\n",
       "  'lambda_q_1_mean': 0.6053541,\n",
       "  'weights_2_std': 0.4964379,\n",
       "  'weights_2_mean': -0.0755902,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.28885177,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.20274687,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.8315935,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.44863033,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.32357684,\n",
       "  'weights_0_mean': 0.009445118,\n",
       "  'bias_a_0_std': 0.21106988,\n",
       "  'bias_a_0_mean': 0.057507887,\n",
       "  'bias_q_0_std': 0.18371527,\n",
       "  'bias_q_0_mean': -0.08269097,\n",
       "  'lambda_a_0_std': 0.3064264,\n",
       "  'lambda_a_0_mean': 0.46334994,\n",
       "  'lambda_q_0_std': 0.34163207,\n",
       "  'lambda_q_0_mean': 0.38317904,\n",
       "  'weights_1_std': 0.31591347,\n",
       "  'weights_1_mean': -0.0053790896,\n",
       "  'bias_a_1_std': 0.19057436,\n",
       "  'bias_a_1_mean': 0.018133717,\n",
       "  'bias_q_1_std': 0.20075713,\n",
       "  'bias_q_1_mean': 0.0813851,\n",
       "  'lambda_a_1_std': 0.329621,\n",
       "  'lambda_a_1_mean': 0.57054156,\n",
       "  'lambda_q_1_std': 0.2602542,\n",
       "  'lambda_q_1_mean': 0.65049314,\n",
       "  'weights_2_std': 0.37346238,\n",
       "  'weights_2_mean': 0.21573035,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.10941395,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.24138919,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.99514025,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.9564417,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.32975858,\n",
       "  'weights_0_mean': -0.03588198,\n",
       "  'bias_a_0_std': 0.17420758,\n",
       "  'bias_a_0_mean': -0.08717343,\n",
       "  'bias_q_0_std': 0.17389914,\n",
       "  'bias_q_0_mean': 0.019286314,\n",
       "  'lambda_a_0_std': 0.23554426,\n",
       "  'lambda_a_0_mean': 0.29403627,\n",
       "  'lambda_q_0_std': 0.2766938,\n",
       "  'lambda_q_0_mean': 0.6239541,\n",
       "  'weights_1_std': 0.33797577,\n",
       "  'weights_1_mean': 0.029187497,\n",
       "  'bias_a_1_std': 0.14202465,\n",
       "  'bias_a_1_mean': -0.0700694,\n",
       "  'bias_q_1_std': 0.18747441,\n",
       "  'bias_q_1_mean': 0.059702978,\n",
       "  'lambda_a_1_std': 0.1925636,\n",
       "  'lambda_a_1_mean': 0.42155918,\n",
       "  'lambda_q_1_std': 0.22366312,\n",
       "  'lambda_q_1_mean': 0.44163358,\n",
       "  'weights_2_std': 0.40574697,\n",
       "  'weights_2_mean': -0.009966682,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.14578858,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.24859759,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.09086084,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.4087429,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.32582378,\n",
       "  'weights_0_mean': -0.036243882,\n",
       "  'bias_a_0_std': 0.17568332,\n",
       "  'bias_a_0_mean': 0.006158567,\n",
       "  'bias_q_0_std': 0.15762231,\n",
       "  'bias_q_0_mean': -0.024135057,\n",
       "  'lambda_a_0_std': 0.26891193,\n",
       "  'lambda_a_0_mean': 0.55509555,\n",
       "  'lambda_q_0_std': 0.3423453,\n",
       "  'lambda_q_0_mean': 0.514194,\n",
       "  'weights_1_std': 0.3208984,\n",
       "  'weights_1_mean': 0.009304317,\n",
       "  'bias_a_1_std': 0.19081742,\n",
       "  'bias_a_1_mean': -0.015982697,\n",
       "  'bias_q_1_std': 0.20939448,\n",
       "  'bias_q_1_mean': -0.036892015,\n",
       "  'lambda_a_1_std': 0.18285762,\n",
       "  'lambda_a_1_mean': 0.28632239,\n",
       "  'lambda_q_1_std': 0.29940483,\n",
       "  'lambda_q_1_mean': 0.483822,\n",
       "  'weights_2_std': 0.48332468,\n",
       "  'weights_2_mean': -0.095388025,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.19955778,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.22853568,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.51330197,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.6618502,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.33824477,\n",
       "  'weights_0_mean': -0.032332473,\n",
       "  'bias_a_0_std': 0.16035806,\n",
       "  'bias_a_0_mean': -0.10060263,\n",
       "  'bias_q_0_std': 0.19640373,\n",
       "  'bias_q_0_mean': -0.024572948,\n",
       "  'lambda_a_0_std': 0.31095546,\n",
       "  'lambda_a_0_mean': 0.4267355,\n",
       "  'lambda_q_0_std': 0.26649362,\n",
       "  'lambda_q_0_mean': 0.40130728,\n",
       "  'weights_1_std': 0.36662298,\n",
       "  'weights_1_mean': 0.060313065,\n",
       "  'bias_a_1_std': 0.18537122,\n",
       "  'bias_a_1_mean': 0.025332484,\n",
       "  'bias_q_1_std': 0.14726473,\n",
       "  'bias_q_1_mean': -0.017199893,\n",
       "  'lambda_a_1_std': 0.21986495,\n",
       "  'lambda_a_1_mean': 0.57117283,\n",
       "  'lambda_q_1_std': 0.21429905,\n",
       "  'lambda_q_1_mean': 0.52207965,\n",
       "  'weights_2_std': 0.3982198,\n",
       "  'weights_2_mean': -0.22141218,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.016444176,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.2361376,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.39662582,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.35015655,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.32838586,\n",
       "  'weights_0_mean': -0.012956634,\n",
       "  'bias_a_0_std': 0.19057083,\n",
       "  'bias_a_0_mean': -0.10783817,\n",
       "  'bias_q_0_std': 0.18403508,\n",
       "  'bias_q_0_mean': 0.035435405,\n",
       "  'lambda_a_0_std': 0.32726008,\n",
       "  'lambda_a_0_mean': 0.4396702,\n",
       "  'lambda_q_0_std': 0.15224427,\n",
       "  'lambda_q_0_mean': 0.63548535,\n",
       "  'weights_1_std': 0.3560282,\n",
       "  'weights_1_mean': -0.0067764027,\n",
       "  'bias_a_1_std': 0.20991196,\n",
       "  'bias_a_1_mean': 0.07282563,\n",
       "  'bias_q_1_std': 0.15981865,\n",
       "  'bias_q_1_mean': -0.027646592,\n",
       "  'lambda_a_1_std': 0.2194965,\n",
       "  'lambda_a_1_mean': 0.5162671,\n",
       "  'lambda_q_1_std': 0.26374316,\n",
       "  'lambda_q_1_mean': 0.39781463,\n",
       "  'weights_2_std': 0.4047097,\n",
       "  'weights_2_mean': 0.03727836,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.053073317,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.23081343,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.8553673,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.70600235,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.33475783,\n",
       "  'weights_0_mean': 0.013613625,\n",
       "  'bias_a_0_std': 0.15466401,\n",
       "  'bias_a_0_mean': 0.09088821,\n",
       "  'bias_q_0_std': 0.1743203,\n",
       "  'bias_q_0_mean': -0.049503736,\n",
       "  'lambda_a_0_std': 0.28708607,\n",
       "  'lambda_a_0_mean': 0.5548942,\n",
       "  'lambda_q_0_std': 0.17549744,\n",
       "  'lambda_q_0_mean': 0.70693725,\n",
       "  'weights_1_std': 0.30483726,\n",
       "  'weights_1_mean': -0.013177937,\n",
       "  'bias_a_1_std': 0.18135037,\n",
       "  'bias_a_1_mean': 0.0025483535,\n",
       "  'bias_q_1_std': 0.17828256,\n",
       "  'bias_q_1_mean': 0.045336705,\n",
       "  'lambda_a_1_std': 0.28457096,\n",
       "  'lambda_a_1_mean': 0.55136824,\n",
       "  'lambda_q_1_std': 0.24223171,\n",
       "  'lambda_q_1_mean': 0.50290304,\n",
       "  'weights_2_std': 0.53717977,\n",
       "  'weights_2_mean': 0.107881054,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.1376481,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.04160586,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.685814,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.21988976,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.32023978,\n",
       "  'weights_0_mean': -0.037138026,\n",
       "  'bias_a_0_std': 0.14372475,\n",
       "  'bias_a_0_mean': -0.014699873,\n",
       "  'bias_q_0_std': 0.1885845,\n",
       "  'bias_q_0_mean': 0.0075554485,\n",
       "  'lambda_a_0_std': 0.32972062,\n",
       "  'lambda_a_0_mean': 0.5031996,\n",
       "  'lambda_q_0_std': 0.21028842,\n",
       "  'lambda_q_0_mean': 0.5734047,\n",
       "  'weights_1_std': 0.3385115,\n",
       "  'weights_1_mean': -0.013241903,\n",
       "  'bias_a_1_std': 0.20668156,\n",
       "  'bias_a_1_mean': -0.06988376,\n",
       "  'bias_q_1_std': 0.14958425,\n",
       "  'bias_q_1_mean': 0.027973847,\n",
       "  'lambda_a_1_std': 0.28843182,\n",
       "  'lambda_a_1_mean': 0.5347151,\n",
       "  'lambda_q_1_std': 0.26648325,\n",
       "  'lambda_q_1_mean': 0.45991835,\n",
       "  'weights_2_std': 0.33783442,\n",
       "  'weights_2_mean': 0.13137892,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.27542052,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.298606,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.7693786,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.27639955,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3086889,\n",
       "  'weights_0_mean': 0.022240289,\n",
       "  'bias_a_0_std': 0.23144422,\n",
       "  'bias_a_0_mean': 0.014290798,\n",
       "  'bias_q_0_std': 0.1604966,\n",
       "  'bias_q_0_mean': -0.02855272,\n",
       "  'lambda_a_0_std': 0.30855733,\n",
       "  'lambda_a_0_mean': 0.5370446,\n",
       "  'lambda_q_0_std': 0.2783695,\n",
       "  'lambda_q_0_mean': 0.57254773,\n",
       "  'weights_1_std': 0.30477837,\n",
       "  'weights_1_mean': 0.046157636,\n",
       "  'bias_a_1_std': 0.2509431,\n",
       "  'bias_a_1_mean': -0.013358621,\n",
       "  'bias_q_1_std': 0.16864705,\n",
       "  'bias_q_1_mean': -0.002352294,\n",
       "  'lambda_a_1_std': 0.26402694,\n",
       "  'lambda_a_1_mean': 0.5495209,\n",
       "  'lambda_q_1_std': 0.33325347,\n",
       "  'lambda_q_1_mean': 0.68905187,\n",
       "  'weights_2_std': 0.3407485,\n",
       "  'weights_2_mean': -0.24433547,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.29747078,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.19309255,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.24872345,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.8034078,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.29702798,\n",
       "  'weights_0_mean': -0.015576727,\n",
       "  'bias_a_0_std': 0.21429116,\n",
       "  'bias_a_0_mean': 0.043672867,\n",
       "  'bias_q_0_std': 0.17338267,\n",
       "  'bias_q_0_mean': -0.036873326,\n",
       "  'lambda_a_0_std': 0.25771302,\n",
       "  'lambda_a_0_mean': 0.31987154,\n",
       "  'lambda_q_0_std': 0.2249,\n",
       "  'lambda_q_0_mean': 0.51446754,\n",
       "  'weights_1_std': 0.32498246,\n",
       "  'weights_1_mean': 0.031384323,\n",
       "  'bias_a_1_std': 0.21140721,\n",
       "  'bias_a_1_mean': 0.013965107,\n",
       "  'bias_q_1_std': 0.2525305,\n",
       "  'bias_q_1_mean': -0.050080772,\n",
       "  'lambda_a_1_std': 0.21539849,\n",
       "  'lambda_a_1_mean': 0.560974,\n",
       "  'lambda_q_1_std': 0.25275594,\n",
       "  'lambda_q_1_mean': 0.3932514,\n",
       "  'weights_2_std': 0.4076741,\n",
       "  'weights_2_mean': -0.1742363,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.3166299,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.00362584,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.6471564,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.81623995,\n",
       "  'acc': 0.90875},\n",
       " {'weights_0_std': 0.32376495,\n",
       "  'weights_0_mean': -0.0028881344,\n",
       "  'bias_a_0_std': 0.18591967,\n",
       "  'bias_a_0_mean': -0.0037203564,\n",
       "  'bias_q_0_std': 0.16134197,\n",
       "  'bias_q_0_mean': 0.09737033,\n",
       "  'lambda_a_0_std': 0.37635908,\n",
       "  'lambda_a_0_mean': 0.50488067,\n",
       "  'lambda_q_0_std': 0.25417495,\n",
       "  'lambda_q_0_mean': 0.80072415,\n",
       "  'weights_1_std': 0.33734384,\n",
       "  'weights_1_mean': 0.02793363,\n",
       "  'bias_a_1_std': 0.11786028,\n",
       "  'bias_a_1_mean': -0.1037528,\n",
       "  'bias_q_1_std': 0.19355331,\n",
       "  'bias_q_1_mean': -0.009503911,\n",
       "  'lambda_a_1_std': 0.28611338,\n",
       "  'lambda_a_1_mean': 0.5397358,\n",
       "  'lambda_q_1_std': 0.33185378,\n",
       "  'lambda_q_1_mean': 0.6058732,\n",
       "  'weights_2_std': 0.3737434,\n",
       "  'weights_2_mean': -0.0747469,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.05619347,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.29544643,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.28219062,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.80325145,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3433567,\n",
       "  'weights_0_mean': -0.041357838,\n",
       "  'bias_a_0_std': 0.21477735,\n",
       "  'bias_a_0_mean': -0.049552113,\n",
       "  'bias_q_0_std': 0.20249364,\n",
       "  'bias_q_0_mean': -0.064081825,\n",
       "  'lambda_a_0_std': 0.2762003,\n",
       "  'lambda_a_0_mean': 0.64413935,\n",
       "  'lambda_q_0_std': 0.22636518,\n",
       "  'lambda_q_0_mean': 0.50202084,\n",
       "  'weights_1_std': 0.321655,\n",
       "  'weights_1_mean': -0.01226804,\n",
       "  'bias_a_1_std': 0.15946765,\n",
       "  'bias_a_1_mean': 0.1147736,\n",
       "  'bias_q_1_std': 0.19773172,\n",
       "  'bias_q_1_mean': 0.08807263,\n",
       "  'lambda_a_1_std': 0.24226534,\n",
       "  'lambda_a_1_mean': 0.50760514,\n",
       "  'lambda_q_1_std': 0.20164834,\n",
       "  'lambda_q_1_mean': 0.75788826,\n",
       "  'weights_2_std': 0.37982628,\n",
       "  'weights_2_mean': 0.056674812,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.010532349,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.14029959,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.3135664,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.952131,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.32223824,\n",
       "  'weights_0_mean': 0.070904076,\n",
       "  'bias_a_0_std': 0.15586095,\n",
       "  'bias_a_0_mean': -0.072343275,\n",
       "  'bias_q_0_std': 0.2029484,\n",
       "  'bias_q_0_mean': -0.02516274,\n",
       "  'lambda_a_0_std': 0.30387098,\n",
       "  'lambda_a_0_mean': 0.3560067,\n",
       "  'lambda_q_0_std': 0.25604105,\n",
       "  'lambda_q_0_mean': 0.5629604,\n",
       "  'weights_1_std': 0.32408977,\n",
       "  'weights_1_mean': 0.049268063,\n",
       "  'bias_a_1_std': 0.17500311,\n",
       "  'bias_a_1_mean': -0.029201068,\n",
       "  'bias_q_1_std': 0.17389882,\n",
       "  'bias_q_1_mean': 0.014911513,\n",
       "  'lambda_a_1_std': 0.29537696,\n",
       "  'lambda_a_1_mean': 0.43305972,\n",
       "  'lambda_q_1_std': 0.36261842,\n",
       "  'lambda_q_1_mean': 0.45913717,\n",
       "  'weights_2_std': 0.4816361,\n",
       "  'weights_2_mean': -0.09581772,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.086583525,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.18579563,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.14604622,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.8547225,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.28804255,\n",
       "  'weights_0_mean': -0.021007448,\n",
       "  'bias_a_0_std': 0.15145229,\n",
       "  'bias_a_0_mean': 0.11096212,\n",
       "  'bias_q_0_std': 0.15897074,\n",
       "  'bias_q_0_mean': 0.050975528,\n",
       "  'lambda_a_0_std': 0.17981412,\n",
       "  'lambda_a_0_mean': 0.6115753,\n",
       "  'lambda_q_0_std': 0.30660328,\n",
       "  'lambda_q_0_mean': 0.70037055,\n",
       "  'weights_1_std': 0.34253255,\n",
       "  'weights_1_mean': -0.0047158827,\n",
       "  'bias_a_1_std': 0.15680213,\n",
       "  'bias_a_1_mean': -0.04886419,\n",
       "  'bias_q_1_std': 0.084483996,\n",
       "  'bias_q_1_mean': 0.025751011,\n",
       "  'lambda_a_1_std': 0.297188,\n",
       "  'lambda_a_1_mean': 0.5333623,\n",
       "  'lambda_q_1_std': 0.23054563,\n",
       "  'lambda_q_1_mean': 0.53577805,\n",
       "  'weights_2_std': 0.33191276,\n",
       "  'weights_2_mean': 0.02815195,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.08664715,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.28213677,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.74315757,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.7719613,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.31610677,\n",
       "  'weights_0_mean': 0.027342152,\n",
       "  'bias_a_0_std': 0.16328402,\n",
       "  'bias_a_0_mean': 0.06278769,\n",
       "  'bias_q_0_std': 0.13983996,\n",
       "  'bias_q_0_mean': -0.0006995334,\n",
       "  'lambda_a_0_std': 0.16222179,\n",
       "  'lambda_a_0_mean': 0.6961582,\n",
       "  'lambda_q_0_std': 0.2819963,\n",
       "  'lambda_q_0_mean': 0.58346295,\n",
       "  'weights_1_std': 0.33932978,\n",
       "  'weights_1_mean': 0.049670603,\n",
       "  'bias_a_1_std': 0.19695912,\n",
       "  'bias_a_1_mean': 0.027053114,\n",
       "  'bias_q_1_std': 0.17590022,\n",
       "  'bias_q_1_mean': 0.019901512,\n",
       "  'lambda_a_1_std': 0.23287946,\n",
       "  'lambda_a_1_mean': 0.38050908,\n",
       "  'lambda_q_1_std': 0.28994453,\n",
       "  'lambda_q_1_mean': 0.5205122,\n",
       "  'weights_2_std': 0.4140739,\n",
       "  'weights_2_mean': 0.04224007,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.02634132,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.21250853,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.5199992,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.26027298,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.2957282,\n",
       "  'weights_0_mean': -0.010845486,\n",
       "  'bias_a_0_std': 0.15411104,\n",
       "  'bias_a_0_mean': -0.05095747,\n",
       "  'bias_q_0_std': 0.20155542,\n",
       "  'bias_q_0_mean': 0.031739727,\n",
       "  'lambda_a_0_std': 0.2684123,\n",
       "  'lambda_a_0_mean': 0.38230145,\n",
       "  'lambda_q_0_std': 0.3349945,\n",
       "  'lambda_q_0_mean': 0.47453636,\n",
       "  'weights_1_std': 0.31166422,\n",
       "  'weights_1_mean': -0.092438854,\n",
       "  'bias_a_1_std': 0.1587134,\n",
       "  'bias_a_1_mean': 0.1082392,\n",
       "  'bias_q_1_std': 0.17531511,\n",
       "  'bias_q_1_mean': 0.030849496,\n",
       "  'lambda_a_1_std': 0.28001213,\n",
       "  'lambda_a_1_mean': 0.51459885,\n",
       "  'lambda_q_1_std': 0.2889419,\n",
       "  'lambda_q_1_mean': 0.6006296,\n",
       "  'weights_2_std': 0.47558123,\n",
       "  'weights_2_mean': 0.053979054,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.10890731,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.31078416,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.6418123,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.05876851,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.29438615,\n",
       "  'weights_0_mean': -0.026069354,\n",
       "  'bias_a_0_std': 0.23850921,\n",
       "  'bias_a_0_mean': 0.0019036564,\n",
       "  'bias_q_0_std': 0.19187088,\n",
       "  'bias_q_0_mean': -0.114270635,\n",
       "  'lambda_a_0_std': 0.3108531,\n",
       "  'lambda_a_0_mean': 0.57570696,\n",
       "  'lambda_q_0_std': 0.2369305,\n",
       "  'lambda_q_0_mean': 0.52920955,\n",
       "  'weights_1_std': 0.33199447,\n",
       "  'weights_1_mean': -0.017394349,\n",
       "  'bias_a_1_std': 0.14567178,\n",
       "  'bias_a_1_mean': 0.05058555,\n",
       "  'bias_q_1_std': 0.1434074,\n",
       "  'bias_q_1_mean': -0.08897653,\n",
       "  'lambda_a_1_std': 0.3537149,\n",
       "  'lambda_a_1_mean': 0.5349271,\n",
       "  'lambda_q_1_std': 0.30863363,\n",
       "  'lambda_q_1_mean': 0.36323225,\n",
       "  'weights_2_std': 0.38524112,\n",
       "  'weights_2_mean': -0.00079141394,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.17876592,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.040070415,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.3392868,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.5633506,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.314883,\n",
       "  'weights_0_mean': 0.039434347,\n",
       "  'bias_a_0_std': 0.15483281,\n",
       "  'bias_a_0_mean': -0.032075234,\n",
       "  'bias_q_0_std': 0.23464166,\n",
       "  'bias_q_0_mean': -0.027362159,\n",
       "  'lambda_a_0_std': 0.19887318,\n",
       "  'lambda_a_0_mean': 0.37599277,\n",
       "  'lambda_q_0_std': 0.30036733,\n",
       "  'lambda_q_0_mean': 0.5533944,\n",
       "  'weights_1_std': 0.3052202,\n",
       "  'weights_1_mean': 0.021177463,\n",
       "  'bias_a_1_std': 0.18110916,\n",
       "  'bias_a_1_mean': 0.08432104,\n",
       "  'bias_q_1_std': 0.18399693,\n",
       "  'bias_q_1_mean': -0.031704795,\n",
       "  'lambda_a_1_std': 0.24736968,\n",
       "  'lambda_a_1_mean': 0.6546859,\n",
       "  'lambda_q_1_std': 0.34975842,\n",
       "  'lambda_q_1_mean': 0.47878805,\n",
       "  'weights_2_std': 0.43317112,\n",
       "  'weights_2_mean': 0.0043910677,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.3054453,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.24703309,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.19047892,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.2951352,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3177857,\n",
       "  'weights_0_mean': 0.007776817,\n",
       "  'bias_a_0_std': 0.15752928,\n",
       "  'bias_a_0_mean': 0.15328535,\n",
       "  'bias_q_0_std': 0.18024911,\n",
       "  'bias_q_0_mean': -0.07638965,\n",
       "  'lambda_a_0_std': 0.3299815,\n",
       "  'lambda_a_0_mean': 0.53380936,\n",
       "  'lambda_q_0_std': 0.28381744,\n",
       "  'lambda_q_0_mean': 0.39329112,\n",
       "  'weights_1_std': 0.3435876,\n",
       "  'weights_1_mean': 0.03958463,\n",
       "  'bias_a_1_std': 0.20690656,\n",
       "  'bias_a_1_mean': -0.14241838,\n",
       "  'bias_q_1_std': 0.097211994,\n",
       "  'bias_q_1_mean': 0.1801111,\n",
       "  'lambda_a_1_std': 0.27093947,\n",
       "  'lambda_a_1_mean': 0.44844186,\n",
       "  'lambda_q_1_std': 0.2553401,\n",
       "  'lambda_q_1_mean': 0.66917205,\n",
       "  'weights_2_std': 0.40282056,\n",
       "  'weights_2_mean': 0.051493168,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.14483473,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.088991016,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.37961823,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.14015818,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.33506414,\n",
       "  'weights_0_mean': -0.057408147,\n",
       "  'bias_a_0_std': 0.2016625,\n",
       "  'bias_a_0_mean': 0.0009154015,\n",
       "  'bias_q_0_std': 0.17402275,\n",
       "  'bias_q_0_mean': 0.076407075,\n",
       "  'lambda_a_0_std': 0.22923835,\n",
       "  'lambda_a_0_mean': 0.5836341,\n",
       "  'lambda_q_0_std': 0.24588221,\n",
       "  'lambda_q_0_mean': 0.35805002,\n",
       "  'weights_1_std': 0.33614472,\n",
       "  'weights_1_mean': -0.06461149,\n",
       "  'bias_a_1_std': 0.18442023,\n",
       "  'bias_a_1_mean': 0.012554498,\n",
       "  'bias_q_1_std': 0.2018381,\n",
       "  'bias_q_1_mean': 0.04955865,\n",
       "  'lambda_a_1_std': 0.26249543,\n",
       "  'lambda_a_1_mean': 0.42569548,\n",
       "  'lambda_q_1_std': 0.2565247,\n",
       "  'lambda_q_1_mean': 0.5546644,\n",
       "  'weights_2_std': 0.39320797,\n",
       "  'weights_2_mean': -0.20998678,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.32240763,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.08973849,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.9805826,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.37642306,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3306475,\n",
       "  'weights_0_mean': 0.038544927,\n",
       "  'bias_a_0_std': 0.18052779,\n",
       "  'bias_a_0_mean': 0.058202624,\n",
       "  'bias_q_0_std': 0.16147266,\n",
       "  'bias_q_0_mean': 0.1116486,\n",
       "  'lambda_a_0_std': 0.27219537,\n",
       "  'lambda_a_0_mean': 0.438659,\n",
       "  'lambda_q_0_std': 0.23974618,\n",
       "  'lambda_q_0_mean': 0.23875481,\n",
       "  'weights_1_std': 0.333659,\n",
       "  'weights_1_mean': -0.005085542,\n",
       "  'bias_a_1_std': 0.18390097,\n",
       "  'bias_a_1_mean': -0.056884553,\n",
       "  'bias_q_1_std': 0.21133842,\n",
       "  'bias_q_1_mean': -0.02141691,\n",
       "  'lambda_a_1_std': 0.22809015,\n",
       "  'lambda_a_1_mean': 0.5283645,\n",
       "  'lambda_q_1_std': 0.2602722,\n",
       "  'lambda_q_1_mean': 0.73597986,\n",
       "  'weights_2_std': 0.4512224,\n",
       "  'weights_2_mean': 0.0048449505,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.26896486,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.23287325,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.26063538,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.555112,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3064225,\n",
       "  'weights_0_mean': -0.03435138,\n",
       "  'bias_a_0_std': 0.18069871,\n",
       "  'bias_a_0_mean': -0.013093386,\n",
       "  'bias_q_0_std': 0.17001542,\n",
       "  'bias_q_0_mean': 0.028772494,\n",
       "  'lambda_a_0_std': 0.23839922,\n",
       "  'lambda_a_0_mean': 0.47644246,\n",
       "  'lambda_q_0_std': 0.25809264,\n",
       "  'lambda_q_0_mean': 0.38966072,\n",
       "  'weights_1_std': 0.31405774,\n",
       "  'weights_1_mean': 0.11408363,\n",
       "  'bias_a_1_std': 0.1844905,\n",
       "  'bias_a_1_mean': -0.08151514,\n",
       "  'bias_q_1_std': 0.14609613,\n",
       "  'bias_q_1_mean': 0.018558314,\n",
       "  'lambda_a_1_std': 0.300493,\n",
       "  'lambda_a_1_mean': 0.502548,\n",
       "  'lambda_q_1_std': 0.33320764,\n",
       "  'lambda_q_1_mean': 0.5009906,\n",
       "  'weights_2_std': 0.47706932,\n",
       "  'weights_2_mean': -0.0335567,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.3333047,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.04816273,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.71571755,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.31967515,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.30899483,\n",
       "  'weights_0_mean': 0.02202203,\n",
       "  'bias_a_0_std': 0.17092459,\n",
       "  'bias_a_0_mean': -0.05185451,\n",
       "  'bias_q_0_std': 0.2303506,\n",
       "  'bias_q_0_mean': 0.06929374,\n",
       "  'lambda_a_0_std': 0.16569032,\n",
       "  'lambda_a_0_mean': 0.3817181,\n",
       "  'lambda_q_0_std': 0.23331718,\n",
       "  'lambda_q_0_mean': 0.49848524,\n",
       "  'weights_1_std': 0.3147162,\n",
       "  'weights_1_mean': 0.046863046,\n",
       "  'bias_a_1_std': 0.18949197,\n",
       "  'bias_a_1_mean': 0.00471987,\n",
       "  'bias_q_1_std': 0.13801874,\n",
       "  'bias_q_1_mean': 0.05928717,\n",
       "  'lambda_a_1_std': 0.2834193,\n",
       "  'lambda_a_1_mean': 0.38298592,\n",
       "  'lambda_q_1_std': 0.29832622,\n",
       "  'lambda_q_1_mean': 0.48237595,\n",
       "  'weights_2_std': 0.39769644,\n",
       "  'weights_2_mean': 0.096364975,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.3085548,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.25658187,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.9242021,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.9542463,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3149865,\n",
       "  'weights_0_mean': 0.030413948,\n",
       "  'bias_a_0_std': 0.16308871,\n",
       "  'bias_a_0_mean': -0.035836477,\n",
       "  'bias_q_0_std': 0.20822014,\n",
       "  'bias_q_0_mean': 0.00013962388,\n",
       "  'lambda_a_0_std': 0.27103442,\n",
       "  'lambda_a_0_mean': 0.51931393,\n",
       "  'lambda_q_0_std': 0.21916376,\n",
       "  'lambda_q_0_mean': 0.43549156,\n",
       "  'weights_1_std': 0.31094646,\n",
       "  'weights_1_mean': -0.0053239986,\n",
       "  'bias_a_1_std': 0.15183055,\n",
       "  'bias_a_1_mean': -0.053578258,\n",
       "  'bias_q_1_std': 0.2031515,\n",
       "  'bias_q_1_mean': 0.0065412456,\n",
       "  'lambda_a_1_std': 0.2904716,\n",
       "  'lambda_a_1_mean': 0.55787873,\n",
       "  'lambda_q_1_std': 0.28795436,\n",
       "  'lambda_q_1_mean': 0.4012686,\n",
       "  'weights_2_std': 0.42360216,\n",
       "  'weights_2_mean': -0.043552596,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.15581036,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.17149356,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.5874659,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.40875655,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3211586,\n",
       "  'weights_0_mean': -0.050096914,\n",
       "  'bias_a_0_std': 0.19395243,\n",
       "  'bias_a_0_mean': 0.029675683,\n",
       "  'bias_q_0_std': 0.2184664,\n",
       "  'bias_q_0_mean': -0.009508405,\n",
       "  'lambda_a_0_std': 0.22328947,\n",
       "  'lambda_a_0_mean': 0.42510018,\n",
       "  'lambda_q_0_std': 0.3099614,\n",
       "  'lambda_q_0_mean': 0.53277194,\n",
       "  'weights_1_std': 0.3606542,\n",
       "  'weights_1_mean': 0.010137321,\n",
       "  'bias_a_1_std': 0.134422,\n",
       "  'bias_a_1_mean': 0.071321726,\n",
       "  'bias_q_1_std': 0.15937911,\n",
       "  'bias_q_1_mean': 0.0072077545,\n",
       "  'lambda_a_1_std': 0.28418186,\n",
       "  'lambda_a_1_mean': 0.56303346,\n",
       "  'lambda_q_1_std': 0.3270926,\n",
       "  'lambda_q_1_mean': 0.44767624,\n",
       "  'weights_2_std': 0.32923555,\n",
       "  'weights_2_mean': 0.008271615,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.10477345,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.15953442,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.4425001,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.8567372,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.31004772,\n",
       "  'weights_0_mean': -0.046321526,\n",
       "  'bias_a_0_std': 0.15131478,\n",
       "  'bias_a_0_mean': -0.14582337,\n",
       "  'bias_q_0_std': 0.12001175,\n",
       "  'bias_q_0_mean': -0.012974716,\n",
       "  'lambda_a_0_std': 0.32337752,\n",
       "  'lambda_a_0_mean': 0.42228824,\n",
       "  'lambda_q_0_std': 0.28679705,\n",
       "  'lambda_q_0_mean': 0.28494072,\n",
       "  'weights_1_std': 0.36434233,\n",
       "  'weights_1_mean': 0.033676095,\n",
       "  'bias_a_1_std': 0.14333872,\n",
       "  'bias_a_1_mean': -0.035916284,\n",
       "  'bias_q_1_std': 0.17269324,\n",
       "  'bias_q_1_mean': 0.041472342,\n",
       "  'lambda_a_1_std': 0.23016387,\n",
       "  'lambda_a_1_mean': 0.5941249,\n",
       "  'lambda_q_1_std': 0.31704614,\n",
       "  'lambda_q_1_mean': 0.50385034,\n",
       "  'weights_2_std': 0.47336382,\n",
       "  'weights_2_mean': 0.21740477,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.06525728,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.21818939,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.51109743,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.2187826,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3164215,\n",
       "  'weights_0_mean': -0.00047668186,\n",
       "  'bias_a_0_std': 0.19491312,\n",
       "  'bias_a_0_mean': -0.08609492,\n",
       "  'bias_q_0_std': 0.171112,\n",
       "  'bias_q_0_mean': -0.13204108,\n",
       "  'lambda_a_0_std': 0.3156227,\n",
       "  'lambda_a_0_mean': 0.5590974,\n",
       "  'lambda_q_0_std': 0.22824974,\n",
       "  'lambda_q_0_mean': 0.37805367,\n",
       "  'weights_1_std': 0.34422258,\n",
       "  'weights_1_mean': 0.007382806,\n",
       "  'bias_a_1_std': 0.21679464,\n",
       "  'bias_a_1_mean': 0.06538871,\n",
       "  'bias_q_1_std': 0.1475144,\n",
       "  'bias_q_1_mean': -0.046788204,\n",
       "  'lambda_a_1_std': 0.2355861,\n",
       "  'lambda_a_1_mean': 0.54670084,\n",
       "  'lambda_q_1_std': 0.3479067,\n",
       "  'lambda_q_1_mean': 0.55045223,\n",
       "  'weights_2_std': 0.46765456,\n",
       "  'weights_2_mean': -0.045400005,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.1886591,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.09141597,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.9429875,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.9162032,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.30639616,\n",
       "  'weights_0_mean': 0.018125856,\n",
       "  'bias_a_0_std': 0.16248529,\n",
       "  'bias_a_0_mean': 0.13206933,\n",
       "  'bias_q_0_std': 0.17087342,\n",
       "  'bias_q_0_mean': 0.039231505,\n",
       "  'lambda_a_0_std': 0.29091078,\n",
       "  'lambda_a_0_mean': 0.42676857,\n",
       "  'lambda_q_0_std': 0.29008514,\n",
       "  'lambda_q_0_mean': 0.5419239,\n",
       "  'weights_1_std': 0.3636367,\n",
       "  'weights_1_mean': 0.027758762,\n",
       "  'bias_a_1_std': 0.22530147,\n",
       "  'bias_a_1_mean': -0.060633183,\n",
       "  'bias_q_1_std': 0.17813273,\n",
       "  'bias_q_1_mean': -0.052489214,\n",
       "  'lambda_a_1_std': 0.26074877,\n",
       "  'lambda_a_1_mean': 0.5093178,\n",
       "  'lambda_q_1_std': 0.23675801,\n",
       "  'lambda_q_1_mean': 0.6021899,\n",
       "  'weights_2_std': 0.3260867,\n",
       "  'weights_2_mean': -0.13291916,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.09277868,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.3270338,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.98161215,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.8693906,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3258069,\n",
       "  'weights_0_mean': -0.03787863,\n",
       "  'bias_a_0_std': 0.18544962,\n",
       "  'bias_a_0_mean': 0.01197968,\n",
       "  'bias_q_0_std': 0.18179384,\n",
       "  'bias_q_0_mean': -0.031219473,\n",
       "  'lambda_a_0_std': 0.28710303,\n",
       "  'lambda_a_0_mean': 0.5119436,\n",
       "  'lambda_q_0_std': 0.20812444,\n",
       "  'lambda_q_0_mean': 0.5731753,\n",
       "  'weights_1_std': 0.33023253,\n",
       "  'weights_1_mean': 0.022696642,\n",
       "  'bias_a_1_std': 0.16829735,\n",
       "  'bias_a_1_mean': 0.003443198,\n",
       "  'bias_q_1_std': 0.22834948,\n",
       "  'bias_q_1_mean': 0.025563557,\n",
       "  'lambda_a_1_std': 0.28853744,\n",
       "  'lambda_a_1_mean': 0.47184134,\n",
       "  'lambda_q_1_std': 0.28510356,\n",
       "  'lambda_q_1_mean': 0.49637926,\n",
       "  'weights_2_std': 0.48372063,\n",
       "  'weights_2_mean': 0.07682299,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.0756751,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.005804181,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.0062805414,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.36826152,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3248574,\n",
       "  'weights_0_mean': -0.005829305,\n",
       "  'bias_a_0_std': 0.14460407,\n",
       "  'bias_a_0_mean': -0.0006107208,\n",
       "  'bias_q_0_std': 0.17583789,\n",
       "  'bias_q_0_mean': 0.016563082,\n",
       "  'lambda_a_0_std': 0.26328003,\n",
       "  'lambda_a_0_mean': 0.4553436,\n",
       "  'lambda_q_0_std': 0.30060834,\n",
       "  'lambda_q_0_mean': 0.5353845,\n",
       "  'weights_1_std': 0.3233862,\n",
       "  'weights_1_mean': -0.032280706,\n",
       "  'bias_a_1_std': 0.1521622,\n",
       "  'bias_a_1_mean': -0.07283875,\n",
       "  'bias_q_1_std': 0.19126494,\n",
       "  'bias_q_1_mean': 0.0015460583,\n",
       "  'lambda_a_1_std': 0.23340727,\n",
       "  'lambda_a_1_mean': 0.5729366,\n",
       "  'lambda_q_1_std': 0.2759185,\n",
       "  'lambda_q_1_mean': 0.46792856,\n",
       "  'weights_2_std': 0.32993892,\n",
       "  'weights_2_mean': -0.13372898,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.1649245,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.03583154,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.9057411,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.8421474,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.32724473,\n",
       "  'weights_0_mean': 0.037598275,\n",
       "  'bias_a_0_std': 0.11122734,\n",
       "  'bias_a_0_mean': -0.011829747,\n",
       "  'bias_q_0_std': 0.15780026,\n",
       "  'bias_q_0_mean': 0.00049771206,\n",
       "  'lambda_a_0_std': 0.3008823,\n",
       "  'lambda_a_0_mean': 0.5005419,\n",
       "  'lambda_q_0_std': 0.33807892,\n",
       "  'lambda_q_0_mean': 0.5837712,\n",
       "  'weights_1_std': 0.3079603,\n",
       "  'weights_1_mean': -0.03282329,\n",
       "  'bias_a_1_std': 0.20797347,\n",
       "  'bias_a_1_mean': -0.06525879,\n",
       "  'bias_q_1_std': 0.2357426,\n",
       "  'bias_q_1_mean': 0.05616624,\n",
       "  'lambda_a_1_std': 0.2577315,\n",
       "  'lambda_a_1_mean': 0.5002169,\n",
       "  'lambda_q_1_std': 0.21585956,\n",
       "  'lambda_q_1_mean': 0.47912994,\n",
       "  'weights_2_std': 0.4405957,\n",
       "  'weights_2_mean': -0.014091021,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.10672915,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.14527604,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.7929604,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.012861192,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3183384,\n",
       "  'weights_0_mean': -0.0062497808,\n",
       "  'bias_a_0_std': 0.21092927,\n",
       "  'bias_a_0_mean': 0.012515376,\n",
       "  'bias_q_0_std': 0.1620628,\n",
       "  'bias_q_0_mean': 0.034263194,\n",
       "  'lambda_a_0_std': 0.23830217,\n",
       "  'lambda_a_0_mean': 0.45643806,\n",
       "  'lambda_q_0_std': 0.20369072,\n",
       "  'lambda_q_0_mean': 0.43570173,\n",
       "  'weights_1_std': 0.3211284,\n",
       "  'weights_1_mean': 0.052251752,\n",
       "  'bias_a_1_std': 0.18371035,\n",
       "  'bias_a_1_mean': -0.009851102,\n",
       "  'bias_q_1_std': 0.13622816,\n",
       "  'bias_q_1_mean': 0.012456117,\n",
       "  'lambda_a_1_std': 0.3496703,\n",
       "  'lambda_a_1_mean': 0.5059066,\n",
       "  'lambda_q_1_std': 0.27094424,\n",
       "  'lambda_q_1_mean': 0.5840262,\n",
       "  'weights_2_std': 0.3896321,\n",
       "  'weights_2_mean': 0.23863322,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.20993643,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.19447276,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.7844708,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.23953539,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.34739107,\n",
       "  'weights_0_mean': 0.0151123805,\n",
       "  'bias_a_0_std': 0.20133176,\n",
       "  'bias_a_0_mean': -0.03933747,\n",
       "  'bias_q_0_std': 0.14085005,\n",
       "  'bias_q_0_mean': 0.11577368,\n",
       "  'lambda_a_0_std': 0.25331905,\n",
       "  'lambda_a_0_mean': 0.53791714,\n",
       "  'lambda_q_0_std': 0.2855013,\n",
       "  'lambda_q_0_mean': 0.4061913,\n",
       "  'weights_1_std': 0.32800353,\n",
       "  'weights_1_mean': -0.07026408,\n",
       "  'bias_a_1_std': 0.12800822,\n",
       "  'bias_a_1_mean': -0.045264665,\n",
       "  'bias_q_1_std': 0.2249534,\n",
       "  'bias_q_1_mean': 0.03359647,\n",
       "  'lambda_a_1_std': 0.22063218,\n",
       "  'lambda_a_1_mean': 0.6566961,\n",
       "  'lambda_q_1_std': 0.30847952,\n",
       "  'lambda_q_1_mean': 0.5810027,\n",
       "  'weights_2_std': 0.53318936,\n",
       "  'weights_2_mean': 0.17423569,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.16585124,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.26226994,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.57034147,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.8232472,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.33587202,\n",
       "  'weights_0_mean': -0.045023654,\n",
       "  'bias_a_0_std': 0.14636724,\n",
       "  'bias_a_0_mean': -0.053627186,\n",
       "  'bias_q_0_std': 0.18281567,\n",
       "  'bias_q_0_mean': 0.06948428,\n",
       "  'lambda_a_0_std': 0.31810293,\n",
       "  'lambda_a_0_mean': 0.47779548,\n",
       "  'lambda_q_0_std': 0.1564692,\n",
       "  'lambda_q_0_mean': 0.7744356,\n",
       "  'weights_1_std': 0.3461212,\n",
       "  'weights_1_mean': -0.0465653,\n",
       "  'bias_a_1_std': 0.10745961,\n",
       "  'bias_a_1_mean': -0.030051999,\n",
       "  'bias_q_1_std': 0.18367077,\n",
       "  'bias_q_1_mean': -0.0575481,\n",
       "  'lambda_a_1_std': 0.23698278,\n",
       "  'lambda_a_1_mean': 0.56093717,\n",
       "  'lambda_q_1_std': 0.29358384,\n",
       "  'lambda_q_1_mean': 0.4737152,\n",
       "  'weights_2_std': 0.45874602,\n",
       "  'weights_2_mean': 0.2154396,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.29845494,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.25934276,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.64857,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.61433154,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.30233678,\n",
       "  'weights_0_mean': -0.052151967,\n",
       "  'bias_a_0_std': 0.18735008,\n",
       "  'bias_a_0_mean': 0.029555878,\n",
       "  'bias_q_0_std': 0.15995926,\n",
       "  'bias_q_0_mean': -0.03856914,\n",
       "  'lambda_a_0_std': 0.30027878,\n",
       "  'lambda_a_0_mean': 0.6070935,\n",
       "  'lambda_q_0_std': 0.25744882,\n",
       "  'lambda_q_0_mean': 0.51390916,\n",
       "  'weights_1_std': 0.32668284,\n",
       "  'weights_1_mean': -0.038637917,\n",
       "  'bias_a_1_std': 0.15118104,\n",
       "  'bias_a_1_mean': -0.10049986,\n",
       "  'bias_q_1_std': 0.16641268,\n",
       "  'bias_q_1_mean': 0.034754965,\n",
       "  'lambda_a_1_std': 0.193847,\n",
       "  'lambda_a_1_mean': 0.43893144,\n",
       "  'lambda_q_1_std': 0.25268403,\n",
       "  'lambda_q_1_mean': 0.41508055,\n",
       "  'weights_2_std': 0.43523994,\n",
       "  'weights_2_mean': 0.12933835,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.117150426,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.15938231,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.4300949,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.80544144,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.328154,\n",
       "  'weights_0_mean': 0.014074588,\n",
       "  'bias_a_0_std': 0.18086688,\n",
       "  'bias_a_0_mean': 0.0047641564,\n",
       "  'bias_q_0_std': 0.17230085,\n",
       "  'bias_q_0_mean': 0.04003679,\n",
       "  'lambda_a_0_std': 0.20482098,\n",
       "  'lambda_a_0_mean': 0.690349,\n",
       "  'lambda_q_0_std': 0.16518499,\n",
       "  'lambda_q_0_mean': 0.59052867,\n",
       "  'weights_1_std': 0.31183088,\n",
       "  'weights_1_mean': -0.055854537,\n",
       "  'bias_a_1_std': 0.23740137,\n",
       "  'bias_a_1_mean': 0.00020314257,\n",
       "  'bias_q_1_std': 0.1859855,\n",
       "  'bias_q_1_mean': 0.06819688,\n",
       "  'lambda_a_1_std': 0.26858008,\n",
       "  'lambda_a_1_mean': 0.49898517,\n",
       "  'lambda_q_1_std': 0.26256722,\n",
       "  'lambda_q_1_mean': 0.5936924,\n",
       "  'weights_2_std': 0.48336723,\n",
       "  'weights_2_mean': -0.020636491,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.11737013,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.1346105,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.7349394,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.42185426,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3365953,\n",
       "  'weights_0_mean': -0.0060369116,\n",
       "  'bias_a_0_std': 0.18232942,\n",
       "  'bias_a_0_mean': 0.008204869,\n",
       "  'bias_q_0_std': 0.1907259,\n",
       "  'bias_q_0_mean': 0.060669124,\n",
       "  'lambda_a_0_std': 0.23588003,\n",
       "  'lambda_a_0_mean': 0.38447338,\n",
       "  'lambda_q_0_std': 0.3047781,\n",
       "  'lambda_q_0_mean': 0.5307748,\n",
       "  'weights_1_std': 0.31951162,\n",
       "  'weights_1_mean': 0.016589668,\n",
       "  'bias_a_1_std': 0.13582218,\n",
       "  'bias_a_1_mean': -0.13538541,\n",
       "  'bias_q_1_std': 0.20903946,\n",
       "  'bias_q_1_mean': 0.07945898,\n",
       "  'lambda_a_1_std': 0.22445261,\n",
       "  'lambda_a_1_mean': 0.57367224,\n",
       "  'lambda_q_1_std': 0.30504605,\n",
       "  'lambda_q_1_mean': 0.6473379,\n",
       "  'weights_2_std': 0.48328546,\n",
       "  'weights_2_mean': 0.26685956,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.014289975,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.3326858,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.10142797,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.8638086,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3392549,\n",
       "  'weights_0_mean': 0.0033780746,\n",
       "  'bias_a_0_std': 0.16457616,\n",
       "  'bias_a_0_mean': 0.032789007,\n",
       "  'bias_q_0_std': 0.1672213,\n",
       "  'bias_q_0_mean': 0.009901078,\n",
       "  'lambda_a_0_std': 0.2353716,\n",
       "  'lambda_a_0_mean': 0.5137715,\n",
       "  'lambda_q_0_std': 0.33869052,\n",
       "  'lambda_q_0_mean': 0.5700937,\n",
       "  'weights_1_std': 0.33983207,\n",
       "  'weights_1_mean': 0.0011850212,\n",
       "  'bias_a_1_std': 0.18024272,\n",
       "  'bias_a_1_mean': -0.08467071,\n",
       "  'bias_q_1_std': 0.16919266,\n",
       "  'bias_q_1_mean': 0.0602344,\n",
       "  'lambda_a_1_std': 0.174591,\n",
       "  'lambda_a_1_mean': 0.7186117,\n",
       "  'lambda_q_1_std': 0.26264584,\n",
       "  'lambda_q_1_mean': 0.46525717,\n",
       "  'weights_2_std': 0.35315508,\n",
       "  'weights_2_mean': 0.02906268,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.28186023,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.23912528,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.9351365,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.78867227,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3201795,\n",
       "  'weights_0_mean': 0.02410571,\n",
       "  'bias_a_0_std': 0.19008392,\n",
       "  'bias_a_0_mean': -0.053562645,\n",
       "  'bias_q_0_std': 0.15507331,\n",
       "  'bias_q_0_mean': 0.019929213,\n",
       "  'lambda_a_0_std': 0.19777025,\n",
       "  'lambda_a_0_mean': 0.49977344,\n",
       "  'lambda_q_0_std': 0.2391674,\n",
       "  'lambda_q_0_mean': 0.40716332,\n",
       "  'weights_1_std': 0.3327821,\n",
       "  'weights_1_mean': 0.026330141,\n",
       "  'bias_a_1_std': 0.19396871,\n",
       "  'bias_a_1_mean': 0.11281158,\n",
       "  'bias_q_1_std': 0.19386652,\n",
       "  'bias_q_1_mean': -0.048178274,\n",
       "  'lambda_a_1_std': 0.32224092,\n",
       "  'lambda_a_1_mean': 0.38732016,\n",
       "  'lambda_q_1_std': 0.2962172,\n",
       "  'lambda_q_1_mean': 0.3798636,\n",
       "  'weights_2_std': 0.43858996,\n",
       "  'weights_2_mean': 0.09226243,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.16892207,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.09244077,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.18403953,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.22488403,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3432137,\n",
       "  'weights_0_mean': -0.013251282,\n",
       "  'bias_a_0_std': 0.20783599,\n",
       "  'bias_a_0_mean': 0.07130049,\n",
       "  'bias_q_0_std': 0.13470359,\n",
       "  'bias_q_0_mean': -0.09883681,\n",
       "  'lambda_a_0_std': 0.21454085,\n",
       "  'lambda_a_0_mean': 0.72512335,\n",
       "  'lambda_q_0_std': 0.3325211,\n",
       "  'lambda_q_0_mean': 0.44201696,\n",
       "  'weights_1_std': 0.32542738,\n",
       "  'weights_1_mean': -0.0011860684,\n",
       "  'bias_a_1_std': 0.088469006,\n",
       "  'bias_a_1_mean': -0.124623366,\n",
       "  'bias_q_1_std': 0.21190949,\n",
       "  'bias_q_1_mean': -0.01902886,\n",
       "  'lambda_a_1_std': 0.2850824,\n",
       "  'lambda_a_1_mean': 0.4798921,\n",
       "  'lambda_q_1_std': 0.21562195,\n",
       "  'lambda_q_1_mean': 0.6369897,\n",
       "  'weights_2_std': 0.3760683,\n",
       "  'weights_2_mean': -0.05919856,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.062940925,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.32299492,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.26020932,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.89518595,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.32581756,\n",
       "  'weights_0_mean': 0.06611831,\n",
       "  'bias_a_0_std': 0.21910523,\n",
       "  'bias_a_0_mean': -0.015692016,\n",
       "  'bias_q_0_std': 0.21110505,\n",
       "  'bias_q_0_mean': -0.07527974,\n",
       "  'lambda_a_0_std': 0.3149239,\n",
       "  'lambda_a_0_mean': 0.39761412,\n",
       "  'lambda_q_0_std': 0.2884426,\n",
       "  'lambda_q_0_mean': 0.35783622,\n",
       "  'weights_1_std': 0.33932987,\n",
       "  'weights_1_mean': -0.010734306,\n",
       "  'bias_a_1_std': 0.1695072,\n",
       "  'bias_a_1_mean': -0.009361261,\n",
       "  'bias_q_1_std': 0.14094129,\n",
       "  'bias_q_1_mean': 0.03237962,\n",
       "  'lambda_a_1_std': 0.25898287,\n",
       "  'lambda_a_1_mean': 0.46116912,\n",
       "  'lambda_q_1_std': 0.17650326,\n",
       "  'lambda_q_1_mean': 0.3791701,\n",
       "  'weights_2_std': 0.39277247,\n",
       "  'weights_2_mean': 0.033364534,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.32137224,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.03295061,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.41384166,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.9724636,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3295414,\n",
       "  'weights_0_mean': -0.024003657,\n",
       "  'bias_a_0_std': 0.1878478,\n",
       "  'bias_a_0_mean': 0.030877776,\n",
       "  'bias_q_0_std': 0.18750809,\n",
       "  'bias_q_0_mean': 0.0022797186,\n",
       "  'lambda_a_0_std': 0.25830266,\n",
       "  'lambda_a_0_mean': 0.620064,\n",
       "  'lambda_q_0_std': 0.22123678,\n",
       "  'lambda_q_0_mean': 0.5392677,\n",
       "  'weights_1_std': 0.33939865,\n",
       "  'weights_1_mean': -0.048620734,\n",
       "  'bias_a_1_std': 0.20304164,\n",
       "  'bias_a_1_mean': -0.08521837,\n",
       "  'bias_q_1_std': 0.16137016,\n",
       "  'bias_q_1_mean': 0.027813567,\n",
       "  'lambda_a_1_std': 0.26011357,\n",
       "  'lambda_a_1_mean': 0.5107858,\n",
       "  'lambda_q_1_std': 0.18150505,\n",
       "  'lambda_q_1_mean': 0.5575343,\n",
       "  'weights_2_std': 0.34692118,\n",
       "  'weights_2_mean': 0.058943707,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.078650445,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.23923662,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.91996735,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.3344344,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.31108025,\n",
       "  'weights_0_mean': 0.015379095,\n",
       "  'bias_a_0_std': 0.14438994,\n",
       "  'bias_a_0_mean': 0.074046165,\n",
       "  'bias_q_0_std': 0.17317052,\n",
       "  'bias_q_0_mean': 0.07639531,\n",
       "  'lambda_a_0_std': 0.28192165,\n",
       "  'lambda_a_0_mean': 0.462206,\n",
       "  'lambda_q_0_std': 0.2255928,\n",
       "  'lambda_q_0_mean': 0.4877049,\n",
       "  'weights_1_std': 0.36792046,\n",
       "  'weights_1_mean': -0.03132907,\n",
       "  'bias_a_1_std': 0.16836813,\n",
       "  'bias_a_1_mean': -0.068865895,\n",
       "  'bias_q_1_std': 0.14510718,\n",
       "  'bias_q_1_mean': -0.013408985,\n",
       "  'lambda_a_1_std': 0.30352223,\n",
       "  'lambda_a_1_mean': 0.6829439,\n",
       "  'lambda_q_1_std': 0.29505306,\n",
       "  'lambda_q_1_mean': 0.58121634,\n",
       "  'weights_2_std': 0.4354363,\n",
       "  'weights_2_mean': -0.00983823,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.2549787,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.18694434,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.031857014,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.019553542,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3209429,\n",
       "  'weights_0_mean': 0.004403368,\n",
       "  'bias_a_0_std': 0.12798385,\n",
       "  'bias_a_0_mean': 0.022542704,\n",
       "  'bias_q_0_std': 0.14360756,\n",
       "  'bias_q_0_mean': -0.069788866,\n",
       "  'lambda_a_0_std': 0.26466477,\n",
       "  'lambda_a_0_mean': 0.5908469,\n",
       "  'lambda_q_0_std': 0.3279252,\n",
       "  'lambda_q_0_mean': 0.48900822,\n",
       "  'weights_1_std': 0.36232084,\n",
       "  'weights_1_mean': -0.036087815,\n",
       "  'bias_a_1_std': 0.1630364,\n",
       "  'bias_a_1_mean': 0.03400223,\n",
       "  'bias_q_1_std': 0.19932197,\n",
       "  'bias_q_1_mean': 0.0058932602,\n",
       "  'lambda_a_1_std': 0.24548227,\n",
       "  'lambda_a_1_mean': 0.598949,\n",
       "  'lambda_q_1_std': 0.22627304,\n",
       "  'lambda_q_1_mean': 0.55122906,\n",
       "  'weights_2_std': 0.49363813,\n",
       "  'weights_2_mean': -0.009135564,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.22040403,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.022884369,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.5764861,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.35702932,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.33260018,\n",
       "  'weights_0_mean': 0.05913275,\n",
       "  'bias_a_0_std': 0.17118905,\n",
       "  'bias_a_0_mean': 0.04432184,\n",
       "  'bias_q_0_std': 0.15201904,\n",
       "  'bias_q_0_mean': -0.07224062,\n",
       "  'lambda_a_0_std': 0.25284567,\n",
       "  'lambda_a_0_mean': 0.45716202,\n",
       "  'lambda_q_0_std': 0.29823098,\n",
       "  'lambda_q_0_mean': 0.53930515,\n",
       "  'weights_1_std': 0.35113043,\n",
       "  'weights_1_mean': -0.03482194,\n",
       "  'bias_a_1_std': 0.21748048,\n",
       "  'bias_a_1_mean': 0.018653389,\n",
       "  'bias_q_1_std': 0.16914447,\n",
       "  'bias_q_1_mean': 0.057223327,\n",
       "  'lambda_a_1_std': 0.26425433,\n",
       "  'lambda_a_1_mean': 0.40801924,\n",
       "  'lambda_q_1_std': 0.32650393,\n",
       "  'lambda_q_1_mean': 0.49837738,\n",
       "  'weights_2_std': 0.39470828,\n",
       "  'weights_2_mean': 0.15789634,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.07707837,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.15879062,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.9022465,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.015328705,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.31343636,\n",
       "  'weights_0_mean': -0.00473337,\n",
       "  'bias_a_0_std': 0.2022005,\n",
       "  'bias_a_0_mean': -0.045986112,\n",
       "  'bias_q_0_std': 0.16091588,\n",
       "  'bias_q_0_mean': 0.008054459,\n",
       "  'lambda_a_0_std': 0.3022297,\n",
       "  'lambda_a_0_mean': 0.48535526,\n",
       "  'lambda_q_0_std': 0.22601867,\n",
       "  'lambda_q_0_mean': 0.6607467,\n",
       "  'weights_1_std': 0.3045351,\n",
       "  'weights_1_mean': 0.078804165,\n",
       "  'bias_a_1_std': 0.15456495,\n",
       "  'bias_a_1_mean': -0.018036183,\n",
       "  'bias_q_1_std': 0.22448009,\n",
       "  'bias_q_1_mean': 0.018320153,\n",
       "  'lambda_a_1_std': 0.2386362,\n",
       "  'lambda_a_1_mean': 0.45392334,\n",
       "  'lambda_q_1_std': 0.21079874,\n",
       "  'lambda_q_1_mean': 0.56467754,\n",
       "  'weights_2_std': 0.36919013,\n",
       "  'weights_2_mean': 0.04616447,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.024884075,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.20833048,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.8139849,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.5230633,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.31961164,\n",
       "  'weights_0_mean': 0.002762793,\n",
       "  'bias_a_0_std': 0.17586316,\n",
       "  'bias_a_0_mean': -0.010746347,\n",
       "  'bias_q_0_std': 0.14753391,\n",
       "  'bias_q_0_mean': 0.06446138,\n",
       "  'lambda_a_0_std': 0.23535839,\n",
       "  'lambda_a_0_mean': 0.60690814,\n",
       "  'lambda_q_0_std': 0.29368192,\n",
       "  'lambda_q_0_mean': 0.54857785,\n",
       "  'weights_1_std': 0.31707168,\n",
       "  'weights_1_mean': 0.025539536,\n",
       "  'bias_a_1_std': 0.15434663,\n",
       "  'bias_a_1_mean': 0.05008541,\n",
       "  'bias_q_1_std': 0.15126508,\n",
       "  'bias_q_1_mean': 0.045716643,\n",
       "  'lambda_a_1_std': 0.24390087,\n",
       "  'lambda_a_1_mean': 0.54801595,\n",
       "  'lambda_q_1_std': 0.2753475,\n",
       "  'lambda_q_1_mean': 0.58109784,\n",
       "  'weights_2_std': 0.3471245,\n",
       "  'weights_2_mean': 0.13529104,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.16152331,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.12691092,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.33652264,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.9380177,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.2825078,\n",
       "  'weights_0_mean': 0.0009950419,\n",
       "  'bias_a_0_std': 0.16512804,\n",
       "  'bias_a_0_mean': 0.101144426,\n",
       "  'bias_q_0_std': 0.1902149,\n",
       "  'bias_q_0_mean': 0.10660932,\n",
       "  'lambda_a_0_std': 0.24134508,\n",
       "  'lambda_a_0_mean': 0.4386183,\n",
       "  'lambda_q_0_std': 0.25181133,\n",
       "  'lambda_q_0_mean': 0.33486208,\n",
       "  'weights_1_std': 0.3285026,\n",
       "  'weights_1_mean': -0.024649922,\n",
       "  'bias_a_1_std': 0.064936034,\n",
       "  'bias_a_1_mean': -0.009230399,\n",
       "  'bias_q_1_std': 0.15690596,\n",
       "  'bias_q_1_mean': 0.0061840713,\n",
       "  'lambda_a_1_std': 0.37044248,\n",
       "  'lambda_a_1_mean': 0.5452974,\n",
       "  'lambda_q_1_std': 0.2607913,\n",
       "  'lambda_q_1_mean': 0.31331235,\n",
       "  'weights_2_std': 0.30482078,\n",
       "  'weights_2_mean': -0.26886356,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.1253047,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.19562462,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.36211437,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.49202955,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.32838562,\n",
       "  'weights_0_mean': -0.014849412,\n",
       "  'bias_a_0_std': 0.16876538,\n",
       "  'bias_a_0_mean': 0.017658152,\n",
       "  'bias_q_0_std': 0.17849879,\n",
       "  'bias_q_0_mean': -0.089343816,\n",
       "  'lambda_a_0_std': 0.30670923,\n",
       "  'lambda_a_0_mean': 0.30427313,\n",
       "  'lambda_q_0_std': 0.17877167,\n",
       "  'lambda_q_0_mean': 0.30604717,\n",
       "  'weights_1_std': 0.33701152,\n",
       "  'weights_1_mean': 0.0009808629,\n",
       "  'bias_a_1_std': 0.18153122,\n",
       "  'bias_a_1_mean': 0.060029797,\n",
       "  'bias_q_1_std': 0.14487441,\n",
       "  'bias_q_1_mean': 0.09318035,\n",
       "  'lambda_a_1_std': 0.21951967,\n",
       "  'lambda_a_1_mean': 0.5022279,\n",
       "  'lambda_q_1_std': 0.25826424,\n",
       "  'lambda_q_1_mean': 0.6888721,\n",
       "  'weights_2_std': 0.36340117,\n",
       "  'weights_2_mean': -0.042681947,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.22344205,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.23480706,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.052980006,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.3065951,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.31410715,\n",
       "  'weights_0_mean': -0.037389506,\n",
       "  'bias_a_0_std': 0.10367681,\n",
       "  'bias_a_0_mean': -0.041038953,\n",
       "  'bias_q_0_std': 0.16482678,\n",
       "  'bias_q_0_mean': 0.106571846,\n",
       "  'lambda_a_0_std': 0.19023931,\n",
       "  'lambda_a_0_mean': 0.6266152,\n",
       "  'lambda_q_0_std': 0.23943955,\n",
       "  'lambda_q_0_mean': 0.48011193,\n",
       "  'weights_1_std': 0.32382032,\n",
       "  'weights_1_mean': -0.03254807,\n",
       "  'bias_a_1_std': 0.18292268,\n",
       "  'bias_a_1_mean': 0.00252075,\n",
       "  'bias_q_1_std': 0.2031612,\n",
       "  'bias_q_1_mean': 0.06239055,\n",
       "  'lambda_a_1_std': 0.2872946,\n",
       "  'lambda_a_1_mean': 0.39364386,\n",
       "  'lambda_q_1_std': 0.20513524,\n",
       "  'lambda_q_1_mean': 0.29632425,\n",
       "  'weights_2_std': 0.34139714,\n",
       "  'weights_2_mean': -0.14763063,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.15172768,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.18786347,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.39317942,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.6385303,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.31829488,\n",
       "  'weights_0_mean': 0.0033883431,\n",
       "  'bias_a_0_std': 0.18381423,\n",
       "  'bias_a_0_mean': 0.018037224,\n",
       "  'bias_q_0_std': 0.1977217,\n",
       "  'bias_q_0_mean': -0.041484177,\n",
       "  'lambda_a_0_std': 0.29116976,\n",
       "  'lambda_a_0_mean': 0.38341802,\n",
       "  'lambda_q_0_std': 0.32624173,\n",
       "  'lambda_q_0_mean': 0.48451343,\n",
       "  'weights_1_std': 0.32269356,\n",
       "  'weights_1_mean': 0.048926774,\n",
       "  'bias_a_1_std': 0.1536065,\n",
       "  'bias_a_1_mean': 0.008503735,\n",
       "  'bias_q_1_std': 0.14483862,\n",
       "  'bias_q_1_mean': -0.10781452,\n",
       "  'lambda_a_1_std': 0.17122246,\n",
       "  'lambda_a_1_mean': 0.63522565,\n",
       "  'lambda_q_1_std': 0.2346126,\n",
       "  'lambda_q_1_mean': 0.5795265,\n",
       "  'weights_2_std': 0.44713527,\n",
       "  'weights_2_mean': -0.015647657,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.18998793,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.19546215,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.73831326,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.40995264,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3428357,\n",
       "  'weights_0_mean': -0.025567856,\n",
       "  'bias_a_0_std': 0.16445714,\n",
       "  'bias_a_0_mean': 0.031019548,\n",
       "  'bias_q_0_std': 0.1934837,\n",
       "  'bias_q_0_mean': 0.03131827,\n",
       "  'lambda_a_0_std': 0.24106489,\n",
       "  'lambda_a_0_mean': 0.6279401,\n",
       "  'lambda_q_0_std': 0.18893148,\n",
       "  'lambda_q_0_mean': 0.60267746,\n",
       "  'weights_1_std': 0.30575117,\n",
       "  'weights_1_mean': -0.01792367,\n",
       "  'bias_a_1_std': 0.17917375,\n",
       "  'bias_a_1_mean': -0.028423164,\n",
       "  'bias_q_1_std': 0.18648505,\n",
       "  'bias_q_1_mean': 0.016188877,\n",
       "  'lambda_a_1_std': 0.23474163,\n",
       "  'lambda_a_1_mean': 0.39339733,\n",
       "  'lambda_q_1_std': 0.25823006,\n",
       "  'lambda_q_1_mean': 0.3747695,\n",
       "  'weights_2_std': 0.4330532,\n",
       "  'weights_2_mean': -0.14979915,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': 0.24414232,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': -0.15167439,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.5329077,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.1187222,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.30297887,\n",
       "  'weights_0_mean': 0.0078432355,\n",
       "  'bias_a_0_std': 0.15531346,\n",
       "  'bias_a_0_mean': -0.0028372274,\n",
       "  'bias_q_0_std': 0.1551459,\n",
       "  'bias_q_0_mean': -0.100357026,\n",
       "  'lambda_a_0_std': 0.2757517,\n",
       "  'lambda_a_0_mean': 0.5188936,\n",
       "  'lambda_q_0_std': 0.20655978,\n",
       "  'lambda_q_0_mean': 0.44336396,\n",
       "  'weights_1_std': 0.33893743,\n",
       "  'weights_1_mean': 0.059051678,\n",
       "  'bias_a_1_std': 0.2069261,\n",
       "  'bias_a_1_mean': 0.027533628,\n",
       "  'bias_q_1_std': 0.16098768,\n",
       "  'bias_q_1_mean': 0.02861522,\n",
       "  'lambda_a_1_std': 0.29079205,\n",
       "  'lambda_a_1_mean': 0.51819646,\n",
       "  'lambda_q_1_std': 0.31945193,\n",
       "  'lambda_q_1_mean': 0.7019855,\n",
       "  'weights_2_std': 0.44804132,\n",
       "  'weights_2_mean': -0.19857776,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.24552552,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.1746867,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.84538925,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.6393096,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.331758,\n",
       "  'weights_0_mean': -0.0017580641,\n",
       "  'bias_a_0_std': 0.15201023,\n",
       "  'bias_a_0_mean': -0.02069575,\n",
       "  'bias_q_0_std': 0.1817107,\n",
       "  'bias_q_0_mean': -0.00018753277,\n",
       "  'lambda_a_0_std': 0.32401946,\n",
       "  'lambda_a_0_mean': 0.50467896,\n",
       "  'lambda_q_0_std': 0.21045928,\n",
       "  'lambda_q_0_mean': 0.44395527,\n",
       "  'weights_1_std': 0.3374116,\n",
       "  'weights_1_mean': -0.024983214,\n",
       "  'bias_a_1_std': 0.15337001,\n",
       "  'bias_a_1_mean': 0.014514241,\n",
       "  'bias_q_1_std': 0.11351028,\n",
       "  'bias_q_1_mean': -0.10092383,\n",
       "  'lambda_a_1_std': 0.28589278,\n",
       "  'lambda_a_1_mean': 0.43932942,\n",
       "  'lambda_q_1_std': 0.26546642,\n",
       "  'lambda_q_1_mean': 0.6159509,\n",
       "  'weights_2_std': 0.41575706,\n",
       "  'weights_2_mean': 0.2742862,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.0039577186,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.16086304,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.2639798,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.9835757,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.3129806,\n",
       "  'weights_0_mean': -0.0417573,\n",
       "  'bias_a_0_std': 0.16581681,\n",
       "  'bias_a_0_mean': 0.01253577,\n",
       "  'bias_q_0_std': 0.15644978,\n",
       "  'bias_q_0_mean': -0.046231758,\n",
       "  'lambda_a_0_std': 0.30196768,\n",
       "  'lambda_a_0_mean': 0.43967146,\n",
       "  'lambda_q_0_std': 0.26443315,\n",
       "  'lambda_q_0_mean': 0.6530325,\n",
       "  'weights_1_std': 0.34416413,\n",
       "  'weights_1_mean': 0.024064593,\n",
       "  'bias_a_1_std': 0.21347064,\n",
       "  'bias_a_1_mean': 0.0023684038,\n",
       "  'bias_q_1_std': 0.20701516,\n",
       "  'bias_q_1_mean': 0.019452894,\n",
       "  'lambda_a_1_std': 0.28292057,\n",
       "  'lambda_a_1_mean': 0.35727793,\n",
       "  'lambda_q_1_std': 0.22428517,\n",
       "  'lambda_q_1_mean': 0.33084032,\n",
       "  'weights_2_std': 0.43214902,\n",
       "  'weights_2_mean': 0.094427854,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.23872814,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.13717318,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.51786304,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.9893942,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.31322917,\n",
       "  'weights_0_mean': 0.03379959,\n",
       "  'bias_a_0_std': 0.14877656,\n",
       "  'bias_a_0_mean': 0.026569806,\n",
       "  'bias_q_0_std': 0.16348962,\n",
       "  'bias_q_0_mean': -0.033912115,\n",
       "  'lambda_a_0_std': 0.3057741,\n",
       "  'lambda_a_0_mean': 0.43096453,\n",
       "  'lambda_q_0_std': 0.289845,\n",
       "  'lambda_q_0_mean': 0.5826779,\n",
       "  'weights_1_std': 0.32149673,\n",
       "  'weights_1_mean': -0.04472586,\n",
       "  'bias_a_1_std': 0.1912376,\n",
       "  'bias_a_1_mean': 0.0512923,\n",
       "  'bias_q_1_std': 0.22871575,\n",
       "  'bias_q_1_mean': -0.016923986,\n",
       "  'lambda_a_1_std': 0.3139274,\n",
       "  'lambda_a_1_mean': 0.5041121,\n",
       "  'lambda_q_1_std': 0.25978285,\n",
       "  'lambda_q_1_mean': 0.5818983,\n",
       "  'weights_2_std': 0.31365672,\n",
       "  'weights_2_mean': 0.06513366,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.26127595,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.25600103,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.31877643,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.25827342,\n",
       "  'acc': 0.25},\n",
       " {'weights_0_std': 0.32229212,\n",
       "  'weights_0_mean': -0.032553073,\n",
       "  'bias_a_0_std': 0.13871321,\n",
       "  'bias_a_0_mean': 0.06850701,\n",
       "  'bias_q_0_std': 0.16811492,\n",
       "  'bias_q_0_mean': -0.09498064,\n",
       "  'lambda_a_0_std': 0.33091328,\n",
       "  'lambda_a_0_mean': 0.4894539,\n",
       "  'lambda_q_0_std': 0.24498124,\n",
       "  'lambda_q_0_mean': 0.34669307,\n",
       "  'weights_1_std': 0.36569813,\n",
       "  'weights_1_mean': -0.0009120379,\n",
       "  'bias_a_1_std': 0.19757086,\n",
       "  'bias_a_1_mean': 0.019149316,\n",
       "  'bias_q_1_std': 0.20175827,\n",
       "  'bias_q_1_mean': -0.020665633,\n",
       "  'lambda_a_1_std': 0.22604756,\n",
       "  'lambda_a_1_mean': 0.4794674,\n",
       "  'lambda_q_1_std': 0.22512202,\n",
       "  'lambda_q_1_mean': 0.31778428,\n",
       "  'weights_2_std': 0.46501073,\n",
       "  'weights_2_mean': -0.110615045,\n",
       "  'bias_a_2_std': 0.0,\n",
       "  'bias_a_2_mean': -0.22785625,\n",
       "  'bias_q_2_std': 0.0,\n",
       "  'bias_q_2_mean': 0.14266947,\n",
       "  'lambda_a_2_std': 0.0,\n",
       "  'lambda_a_2_mean': 0.8386806,\n",
       "  'lambda_q_2_std': 0.0,\n",
       "  'lambda_q_2_mean': 0.88602126,\n",
       "  'acc': 0.25}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "283b4e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame().from_records(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "48aafb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weights_0_std</th>\n",
       "      <th>weights_0_mean</th>\n",
       "      <th>bias_a_0_std</th>\n",
       "      <th>bias_a_0_mean</th>\n",
       "      <th>bias_q_0_std</th>\n",
       "      <th>bias_q_0_mean</th>\n",
       "      <th>lambda_a_0_std</th>\n",
       "      <th>lambda_a_0_mean</th>\n",
       "      <th>lambda_q_0_std</th>\n",
       "      <th>lambda_q_0_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>weights_2_mean</th>\n",
       "      <th>bias_a_2_std</th>\n",
       "      <th>bias_a_2_mean</th>\n",
       "      <th>bias_q_2_std</th>\n",
       "      <th>bias_q_2_mean</th>\n",
       "      <th>lambda_a_2_std</th>\n",
       "      <th>lambda_a_2_mean</th>\n",
       "      <th>lambda_q_2_std</th>\n",
       "      <th>lambda_q_2_mean</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.321775</td>\n",
       "      <td>0.053915</td>\n",
       "      <td>0.208952</td>\n",
       "      <td>-0.006174</td>\n",
       "      <td>0.130909</td>\n",
       "      <td>-0.074829</td>\n",
       "      <td>0.340735</td>\n",
       "      <td>0.460427</td>\n",
       "      <td>0.283939</td>\n",
       "      <td>0.366875</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.022425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232351</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.358251</td>\n",
       "      <td>0.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.323549</td>\n",
       "      <td>-0.010821</td>\n",
       "      <td>0.199974</td>\n",
       "      <td>-0.097995</td>\n",
       "      <td>0.165291</td>\n",
       "      <td>-0.004043</td>\n",
       "      <td>0.222999</td>\n",
       "      <td>0.610874</td>\n",
       "      <td>0.264230</td>\n",
       "      <td>0.492383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.141515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.574813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.657295</td>\n",
       "      <td>0.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.292646</td>\n",
       "      <td>0.069323</td>\n",
       "      <td>0.217101</td>\n",
       "      <td>0.021971</td>\n",
       "      <td>0.170423</td>\n",
       "      <td>-0.105025</td>\n",
       "      <td>0.286267</td>\n",
       "      <td>0.452614</td>\n",
       "      <td>0.270215</td>\n",
       "      <td>0.551681</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.309784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.740813</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500773</td>\n",
       "      <td>0.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.327465</td>\n",
       "      <td>0.007501</td>\n",
       "      <td>0.196278</td>\n",
       "      <td>-0.083977</td>\n",
       "      <td>0.202035</td>\n",
       "      <td>0.054849</td>\n",
       "      <td>0.194806</td>\n",
       "      <td>0.380651</td>\n",
       "      <td>0.241778</td>\n",
       "      <td>0.340173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.037957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.513407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099888</td>\n",
       "      <td>0.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.299424</td>\n",
       "      <td>-0.047712</td>\n",
       "      <td>0.166465</td>\n",
       "      <td>0.023635</td>\n",
       "      <td>0.095912</td>\n",
       "      <td>-0.013654</td>\n",
       "      <td>0.322138</td>\n",
       "      <td>0.544106</td>\n",
       "      <td>0.262637</td>\n",
       "      <td>0.536966</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.265090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.081086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.043185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.216892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.189022</td>\n",
       "      <td>0.81225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.302979</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>0.155313</td>\n",
       "      <td>-0.002837</td>\n",
       "      <td>0.155146</td>\n",
       "      <td>-0.100357</td>\n",
       "      <td>0.275752</td>\n",
       "      <td>0.518894</td>\n",
       "      <td>0.206560</td>\n",
       "      <td>0.443364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.198578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.245526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.174687</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.845389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.639310</td>\n",
       "      <td>0.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.331758</td>\n",
       "      <td>-0.001758</td>\n",
       "      <td>0.152010</td>\n",
       "      <td>-0.020696</td>\n",
       "      <td>0.181711</td>\n",
       "      <td>-0.000188</td>\n",
       "      <td>0.324019</td>\n",
       "      <td>0.504679</td>\n",
       "      <td>0.210459</td>\n",
       "      <td>0.443955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.263980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983576</td>\n",
       "      <td>0.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.312981</td>\n",
       "      <td>-0.041757</td>\n",
       "      <td>0.165817</td>\n",
       "      <td>0.012536</td>\n",
       "      <td>0.156450</td>\n",
       "      <td>-0.046232</td>\n",
       "      <td>0.301968</td>\n",
       "      <td>0.439671</td>\n",
       "      <td>0.264433</td>\n",
       "      <td>0.653032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094428</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.238728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989394</td>\n",
       "      <td>0.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.313229</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>0.148777</td>\n",
       "      <td>0.026570</td>\n",
       "      <td>0.163490</td>\n",
       "      <td>-0.033912</td>\n",
       "      <td>0.305774</td>\n",
       "      <td>0.430965</td>\n",
       "      <td>0.289845</td>\n",
       "      <td>0.582678</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.261276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.256001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258273</td>\n",
       "      <td>0.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.322292</td>\n",
       "      <td>-0.032553</td>\n",
       "      <td>0.138713</td>\n",
       "      <td>0.068507</td>\n",
       "      <td>0.168115</td>\n",
       "      <td>-0.094981</td>\n",
       "      <td>0.330913</td>\n",
       "      <td>0.489454</td>\n",
       "      <td>0.244981</td>\n",
       "      <td>0.346693</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.227856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.838681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.886021</td>\n",
       "      <td>0.25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    weights_0_std  weights_0_mean  bias_a_0_std  bias_a_0_mean  bias_q_0_std  \\\n",
       "0        0.321775        0.053915      0.208952      -0.006174      0.130909   \n",
       "1        0.323549       -0.010821      0.199974      -0.097995      0.165291   \n",
       "2        0.292646        0.069323      0.217101       0.021971      0.170423   \n",
       "3        0.327465        0.007501      0.196278      -0.083977      0.202035   \n",
       "4        0.299424       -0.047712      0.166465       0.023635      0.095912   \n",
       "..            ...             ...           ...            ...           ...   \n",
       "71       0.302979        0.007843      0.155313      -0.002837      0.155146   \n",
       "72       0.331758       -0.001758      0.152010      -0.020696      0.181711   \n",
       "73       0.312981       -0.041757      0.165817       0.012536      0.156450   \n",
       "74       0.313229        0.033800      0.148777       0.026570      0.163490   \n",
       "75       0.322292       -0.032553      0.138713       0.068507      0.168115   \n",
       "\n",
       "    bias_q_0_mean  lambda_a_0_std  lambda_a_0_mean  lambda_q_0_std  \\\n",
       "0       -0.074829        0.340735         0.460427        0.283939   \n",
       "1       -0.004043        0.222999         0.610874        0.264230   \n",
       "2       -0.105025        0.286267         0.452614        0.270215   \n",
       "3        0.054849        0.194806         0.380651        0.241778   \n",
       "4       -0.013654        0.322138         0.544106        0.262637   \n",
       "..            ...             ...              ...             ...   \n",
       "71      -0.100357        0.275752         0.518894        0.206560   \n",
       "72      -0.000188        0.324019         0.504679        0.210459   \n",
       "73      -0.046232        0.301968         0.439671        0.264433   \n",
       "74      -0.033912        0.305774         0.430965        0.289845   \n",
       "75      -0.094981        0.330913         0.489454        0.244981   \n",
       "\n",
       "    lambda_q_0_mean  ...  weights_2_mean  bias_a_2_std  bias_a_2_mean  \\\n",
       "0          0.366875  ...       -0.222204           0.0       0.038150   \n",
       "1          0.492383  ...        0.016238           0.0       0.094136   \n",
       "2          0.551681  ...       -0.061890           0.0       0.060599   \n",
       "3          0.340173  ...       -0.110938           0.0      -0.037957   \n",
       "4          0.536966  ...       -0.265090           0.0      -0.081086   \n",
       "..              ...  ...             ...           ...            ...   \n",
       "71         0.443364  ...       -0.198578           0.0      -0.245526   \n",
       "72         0.443955  ...        0.274286           0.0      -0.003958   \n",
       "73         0.653032  ...        0.094428           0.0      -0.238728   \n",
       "74         0.582678  ...        0.065134           0.0      -0.261276   \n",
       "75         0.346693  ...       -0.110615           0.0      -0.227856   \n",
       "\n",
       "    bias_q_2_std  bias_q_2_mean  lambda_a_2_std  lambda_a_2_mean  \\\n",
       "0            0.0      -0.022425             0.0         0.232351   \n",
       "1            0.0      -0.141515             0.0         0.574813   \n",
       "2            0.0       0.309784             0.0         0.740813   \n",
       "3            0.0       0.133882             0.0         0.513407   \n",
       "4            0.0      -0.043185             0.0         0.216892   \n",
       "..           ...            ...             ...              ...   \n",
       "71           0.0       0.174687             0.0         0.845389   \n",
       "72           0.0       0.160863             0.0         0.263980   \n",
       "73           0.0       0.137173             0.0         0.517863   \n",
       "74           0.0       0.256001             0.0         0.318776   \n",
       "75           0.0       0.142669             0.0         0.838681   \n",
       "\n",
       "    lambda_q_2_std  lambda_q_2_mean      acc  \n",
       "0              0.0         0.358251  0.25000  \n",
       "1              0.0         0.657295  0.25000  \n",
       "2              0.0         0.500773  0.25000  \n",
       "3              0.0         0.099888  0.25000  \n",
       "4              0.0         0.189022  0.81225  \n",
       "..             ...              ...      ...  \n",
       "71             0.0         0.639310  0.25000  \n",
       "72             0.0         0.983576  0.25000  \n",
       "73             0.0         0.989394  0.25000  \n",
       "74             0.0         0.258273  0.25000  \n",
       "75             0.0         0.886021  0.25000  \n",
       "\n",
       "[76 rows x 31 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fa7de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weights_0_std</th>\n",
       "      <th>weights_0_mean</th>\n",
       "      <th>bias_a_0_std</th>\n",
       "      <th>bias_a_0_mean</th>\n",
       "      <th>bias_q_0_std</th>\n",
       "      <th>bias_q_0_mean</th>\n",
       "      <th>lambda_a_0_std</th>\n",
       "      <th>lambda_a_0_mean</th>\n",
       "      <th>lambda_q_0_std</th>\n",
       "      <th>lambda_q_0_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>weights_2_mean</th>\n",
       "      <th>bias_a_2_std</th>\n",
       "      <th>bias_a_2_mean</th>\n",
       "      <th>bias_q_2_std</th>\n",
       "      <th>bias_q_2_mean</th>\n",
       "      <th>lambda_a_2_std</th>\n",
       "      <th>lambda_a_2_mean</th>\n",
       "      <th>lambda_q_2_std</th>\n",
       "      <th>lambda_q_2_mean</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>weights_0_std</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.047570</td>\n",
       "      <td>-0.047979</td>\n",
       "      <td>-0.173574</td>\n",
       "      <td>-0.022374</td>\n",
       "      <td>0.111147</td>\n",
       "      <td>-0.012980</td>\n",
       "      <td>0.138581</td>\n",
       "      <td>-0.129002</td>\n",
       "      <td>0.028137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.056790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.054415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.025208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.004155</td>\n",
       "      <td>-0.239098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights_0_mean</th>\n",
       "      <td>-0.047570</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.031378</td>\n",
       "      <td>0.053660</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>-0.093372</td>\n",
       "      <td>-0.061621</td>\n",
       "      <td>-0.208204</td>\n",
       "      <td>0.208271</td>\n",
       "      <td>-0.104822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016890</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.119772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.102091</td>\n",
       "      <td>-0.156055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias_a_0_std</th>\n",
       "      <td>-0.047979</td>\n",
       "      <td>0.031378</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.099953</td>\n",
       "      <td>0.044055</td>\n",
       "      <td>-0.219797</td>\n",
       "      <td>-0.044460</td>\n",
       "      <td>0.048941</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>-0.081942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.215610</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.235449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.017394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.267248</td>\n",
       "      <td>0.100794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias_a_0_mean</th>\n",
       "      <td>-0.173574</td>\n",
       "      <td>0.053660</td>\n",
       "      <td>-0.099953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.074233</td>\n",
       "      <td>-0.067187</td>\n",
       "      <td>-0.019445</td>\n",
       "      <td>0.197675</td>\n",
       "      <td>0.062822</td>\n",
       "      <td>0.077027</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.103480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.089935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020092</td>\n",
       "      <td>0.099233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias_q_0_std</th>\n",
       "      <td>-0.022374</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>0.044055</td>\n",
       "      <td>-0.074233</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.088236</td>\n",
       "      <td>-0.049883</td>\n",
       "      <td>-0.284018</td>\n",
       "      <td>-0.152684</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.225573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.025461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.092946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>-0.201416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias_q_0_mean</th>\n",
       "      <td>0.111147</td>\n",
       "      <td>-0.093372</td>\n",
       "      <td>-0.219797</td>\n",
       "      <td>-0.067187</td>\n",
       "      <td>-0.088236</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.291588</td>\n",
       "      <td>-0.004694</td>\n",
       "      <td>-0.156005</td>\n",
       "      <td>0.137075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.055988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.125217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.044334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.045811</td>\n",
       "      <td>-0.059538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambda_a_0_std</th>\n",
       "      <td>-0.012980</td>\n",
       "      <td>-0.061621</td>\n",
       "      <td>-0.044460</td>\n",
       "      <td>-0.019445</td>\n",
       "      <td>-0.049883</td>\n",
       "      <td>-0.291588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.232704</td>\n",
       "      <td>-0.075614</td>\n",
       "      <td>-0.019988</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.022818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.205679</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.006960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083157</td>\n",
       "      <td>0.058536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambda_a_0_mean</th>\n",
       "      <td>0.138581</td>\n",
       "      <td>-0.208204</td>\n",
       "      <td>0.048941</td>\n",
       "      <td>0.197675</td>\n",
       "      <td>-0.284018</td>\n",
       "      <td>-0.004694</td>\n",
       "      <td>-0.232704</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.061615</td>\n",
       "      <td>0.174070</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.089134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.147497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.049270</td>\n",
       "      <td>-0.114971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambda_q_0_std</th>\n",
       "      <td>-0.129002</td>\n",
       "      <td>0.208271</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>0.062822</td>\n",
       "      <td>-0.152684</td>\n",
       "      <td>-0.156005</td>\n",
       "      <td>-0.075614</td>\n",
       "      <td>-0.061615</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.189590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.066946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.092247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000550</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.025157</td>\n",
       "      <td>-0.069697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambda_q_0_mean</th>\n",
       "      <td>0.028137</td>\n",
       "      <td>-0.104822</td>\n",
       "      <td>-0.081942</td>\n",
       "      <td>0.077027</td>\n",
       "      <td>0.010482</td>\n",
       "      <td>0.137075</td>\n",
       "      <td>-0.019988</td>\n",
       "      <td>0.174070</td>\n",
       "      <td>-0.189590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.144672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.118793</td>\n",
       "      <td>0.036986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights_1_std</th>\n",
       "      <td>-0.015910</td>\n",
       "      <td>-0.191193</td>\n",
       "      <td>-0.125168</td>\n",
       "      <td>0.082967</td>\n",
       "      <td>-0.065431</td>\n",
       "      <td>-0.056608</td>\n",
       "      <td>0.214593</td>\n",
       "      <td>-0.094564</td>\n",
       "      <td>-0.072109</td>\n",
       "      <td>-0.030579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.034457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143840</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.132610</td>\n",
       "      <td>0.024576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights_1_mean</th>\n",
       "      <td>-0.141173</td>\n",
       "      <td>0.202174</td>\n",
       "      <td>0.123358</td>\n",
       "      <td>0.026223</td>\n",
       "      <td>-0.027797</td>\n",
       "      <td>-0.170514</td>\n",
       "      <td>-0.035847</td>\n",
       "      <td>-0.176299</td>\n",
       "      <td>-0.025745</td>\n",
       "      <td>-0.006747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035766</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.031607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.073574</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.161057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095641</td>\n",
       "      <td>0.007035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias_a_1_std</th>\n",
       "      <td>-0.042876</td>\n",
       "      <td>0.099521</td>\n",
       "      <td>-0.012289</td>\n",
       "      <td>-0.020056</td>\n",
       "      <td>-0.042104</td>\n",
       "      <td>-0.122439</td>\n",
       "      <td>0.070481</td>\n",
       "      <td>0.027551</td>\n",
       "      <td>-0.139596</td>\n",
       "      <td>-0.065653</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.059285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.204948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.120260</td>\n",
       "      <td>0.180203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias_a_1_mean</th>\n",
       "      <td>-0.105386</td>\n",
       "      <td>0.147792</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>-0.153555</td>\n",
       "      <td>0.138135</td>\n",
       "      <td>-0.228181</td>\n",
       "      <td>-0.051063</td>\n",
       "      <td>-0.121881</td>\n",
       "      <td>-0.092153</td>\n",
       "      <td>-0.123373</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.044460</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.274328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.028347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.085115</td>\n",
       "      <td>0.000799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias_q_1_std</th>\n",
       "      <td>0.232699</td>\n",
       "      <td>0.088099</td>\n",
       "      <td>0.120794</td>\n",
       "      <td>-0.166273</td>\n",
       "      <td>-0.122739</td>\n",
       "      <td>0.059329</td>\n",
       "      <td>-0.110643</td>\n",
       "      <td>0.020948</td>\n",
       "      <td>0.095459</td>\n",
       "      <td>0.094257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.139881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.262934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.054389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001923</td>\n",
       "      <td>0.101017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias_q_1_mean</th>\n",
       "      <td>0.080640</td>\n",
       "      <td>-0.002481</td>\n",
       "      <td>-0.029264</td>\n",
       "      <td>0.075303</td>\n",
       "      <td>-0.102281</td>\n",
       "      <td>-0.024629</td>\n",
       "      <td>-0.002822</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>0.109019</td>\n",
       "      <td>-0.142762</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.071535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.124848</td>\n",
       "      <td>0.001329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambda_a_1_std</th>\n",
       "      <td>-0.309668</td>\n",
       "      <td>0.186635</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>0.064198</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.022682</td>\n",
       "      <td>-0.056320</td>\n",
       "      <td>-0.011231</td>\n",
       "      <td>-0.076679</td>\n",
       "      <td>-0.046653</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036385</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.031135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.066375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.145151</td>\n",
       "      <td>-0.068862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambda_a_1_mean</th>\n",
       "      <td>-0.085763</td>\n",
       "      <td>0.001120</td>\n",
       "      <td>-0.108390</td>\n",
       "      <td>0.167900</td>\n",
       "      <td>-0.029704</td>\n",
       "      <td>-0.020220</td>\n",
       "      <td>0.181368</td>\n",
       "      <td>-0.130840</td>\n",
       "      <td>0.066390</td>\n",
       "      <td>-0.005575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.089011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016820</td>\n",
       "      <td>0.078422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambda_q_1_std</th>\n",
       "      <td>-0.130733</td>\n",
       "      <td>0.198030</td>\n",
       "      <td>0.052967</td>\n",
       "      <td>-0.185362</td>\n",
       "      <td>0.087686</td>\n",
       "      <td>0.035043</td>\n",
       "      <td>-0.001780</td>\n",
       "      <td>-0.125542</td>\n",
       "      <td>0.007183</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.177440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.075203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>-0.144052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambda_q_1_mean</th>\n",
       "      <td>0.209161</td>\n",
       "      <td>0.060103</td>\n",
       "      <td>0.191912</td>\n",
       "      <td>0.111259</td>\n",
       "      <td>-0.190043</td>\n",
       "      <td>0.052036</td>\n",
       "      <td>0.054765</td>\n",
       "      <td>0.159852</td>\n",
       "      <td>-0.031194</td>\n",
       "      <td>-0.035856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.086101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.136061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.005688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005652</td>\n",
       "      <td>0.037356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights_2_std</th>\n",
       "      <td>0.133064</td>\n",
       "      <td>0.101429</td>\n",
       "      <td>-0.071191</td>\n",
       "      <td>-0.073812</td>\n",
       "      <td>-0.030425</td>\n",
       "      <td>-0.090973</td>\n",
       "      <td>0.163685</td>\n",
       "      <td>-0.014423</td>\n",
       "      <td>-0.084969</td>\n",
       "      <td>-0.067049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.078998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.077258</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.074439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.093600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.085439</td>\n",
       "      <td>-0.158389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weights_2_mean</th>\n",
       "      <td>0.181063</td>\n",
       "      <td>0.050459</td>\n",
       "      <td>0.087302</td>\n",
       "      <td>-0.103480</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.016356</td>\n",
       "      <td>-0.085326</td>\n",
       "      <td>-0.025535</td>\n",
       "      <td>-0.029704</td>\n",
       "      <td>0.153547</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.024986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.090292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.130883</td>\n",
       "      <td>-0.262512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias_a_2_std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias_a_2_mean</th>\n",
       "      <td>0.056790</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.215610</td>\n",
       "      <td>0.026001</td>\n",
       "      <td>0.225573</td>\n",
       "      <td>0.055988</td>\n",
       "      <td>-0.022818</td>\n",
       "      <td>0.093718</td>\n",
       "      <td>-0.066946</td>\n",
       "      <td>-0.144672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.144278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.044281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042442</td>\n",
       "      <td>-0.166620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias_q_2_std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bias_q_2_mean</th>\n",
       "      <td>-0.054415</td>\n",
       "      <td>-0.016890</td>\n",
       "      <td>0.235449</td>\n",
       "      <td>0.089935</td>\n",
       "      <td>-0.025461</td>\n",
       "      <td>-0.125217</td>\n",
       "      <td>0.205679</td>\n",
       "      <td>0.089134</td>\n",
       "      <td>0.092247</td>\n",
       "      <td>0.054873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.144278</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.245790</td>\n",
       "      <td>-0.038868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambda_a_2_std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambda_a_2_mean</th>\n",
       "      <td>-0.025208</td>\n",
       "      <td>-0.119772</td>\n",
       "      <td>-0.017394</td>\n",
       "      <td>0.046057</td>\n",
       "      <td>0.092946</td>\n",
       "      <td>-0.044334</td>\n",
       "      <td>-0.006960</td>\n",
       "      <td>0.147497</td>\n",
       "      <td>-0.000550</td>\n",
       "      <td>0.119715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.044281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093541</td>\n",
       "      <td>-0.032795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambda_q_2_std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambda_q_2_mean</th>\n",
       "      <td>-0.004155</td>\n",
       "      <td>-0.102091</td>\n",
       "      <td>0.267248</td>\n",
       "      <td>0.020092</td>\n",
       "      <td>0.137200</td>\n",
       "      <td>-0.045811</td>\n",
       "      <td>0.083157</td>\n",
       "      <td>-0.049270</td>\n",
       "      <td>-0.025157</td>\n",
       "      <td>0.118793</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.042442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.245790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>-0.239098</td>\n",
       "      <td>-0.156055</td>\n",
       "      <td>0.100794</td>\n",
       "      <td>0.099233</td>\n",
       "      <td>-0.201416</td>\n",
       "      <td>-0.059538</td>\n",
       "      <td>0.058536</td>\n",
       "      <td>-0.114971</td>\n",
       "      <td>-0.069697</td>\n",
       "      <td>0.036986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.262512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.166620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.038868</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.032795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.005260</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 weights_0_std  weights_0_mean  bias_a_0_std  bias_a_0_mean  \\\n",
       "weights_0_std         1.000000       -0.047570     -0.047979      -0.173574   \n",
       "weights_0_mean       -0.047570        1.000000      0.031378       0.053660   \n",
       "bias_a_0_std         -0.047979        0.031378      1.000000      -0.099953   \n",
       "bias_a_0_mean        -0.173574        0.053660     -0.099953       1.000000   \n",
       "bias_q_0_std         -0.022374       -0.055080      0.044055      -0.074233   \n",
       "bias_q_0_mean         0.111147       -0.093372     -0.219797      -0.067187   \n",
       "lambda_a_0_std       -0.012980       -0.061621     -0.044460      -0.019445   \n",
       "lambda_a_0_mean       0.138581       -0.208204      0.048941       0.197675   \n",
       "lambda_q_0_std       -0.129002        0.208271      0.006197       0.062822   \n",
       "lambda_q_0_mean       0.028137       -0.104822     -0.081942       0.077027   \n",
       "weights_1_std        -0.015910       -0.191193     -0.125168       0.082967   \n",
       "weights_1_mean       -0.141173        0.202174      0.123358       0.026223   \n",
       "bias_a_1_std         -0.042876        0.099521     -0.012289      -0.020056   \n",
       "bias_a_1_mean        -0.105386        0.147792      0.005066      -0.153555   \n",
       "bias_q_1_std          0.232699        0.088099      0.120794      -0.166273   \n",
       "bias_q_1_mean         0.080640       -0.002481     -0.029264       0.075303   \n",
       "lambda_a_1_std       -0.309668        0.186635      0.003251       0.064198   \n",
       "lambda_a_1_mean      -0.085763        0.001120     -0.108390       0.167900   \n",
       "lambda_q_1_std       -0.130733        0.198030      0.052967      -0.185362   \n",
       "lambda_q_1_mean       0.209161        0.060103      0.191912       0.111259   \n",
       "weights_2_std         0.133064        0.101429     -0.071191      -0.073812   \n",
       "weights_2_mean        0.181063        0.050459      0.087302      -0.103480   \n",
       "bias_a_2_std               NaN             NaN           NaN            NaN   \n",
       "bias_a_2_mean         0.056790        0.089286      0.215610       0.026001   \n",
       "bias_q_2_std               NaN             NaN           NaN            NaN   \n",
       "bias_q_2_mean        -0.054415       -0.016890      0.235449       0.089935   \n",
       "lambda_a_2_std             NaN             NaN           NaN            NaN   \n",
       "lambda_a_2_mean      -0.025208       -0.119772     -0.017394       0.046057   \n",
       "lambda_q_2_std             NaN             NaN           NaN            NaN   \n",
       "lambda_q_2_mean      -0.004155       -0.102091      0.267248       0.020092   \n",
       "acc                  -0.239098       -0.156055      0.100794       0.099233   \n",
       "\n",
       "                 bias_q_0_std  bias_q_0_mean  lambda_a_0_std  lambda_a_0_mean  \\\n",
       "weights_0_std       -0.022374       0.111147       -0.012980         0.138581   \n",
       "weights_0_mean      -0.055080      -0.093372       -0.061621        -0.208204   \n",
       "bias_a_0_std         0.044055      -0.219797       -0.044460         0.048941   \n",
       "bias_a_0_mean       -0.074233      -0.067187       -0.019445         0.197675   \n",
       "bias_q_0_std         1.000000      -0.088236       -0.049883        -0.284018   \n",
       "bias_q_0_mean       -0.088236       1.000000       -0.291588        -0.004694   \n",
       "lambda_a_0_std      -0.049883      -0.291588        1.000000        -0.232704   \n",
       "lambda_a_0_mean     -0.284018      -0.004694       -0.232704         1.000000   \n",
       "lambda_q_0_std      -0.152684      -0.156005       -0.075614        -0.061615   \n",
       "lambda_q_0_mean      0.010482       0.137075       -0.019988         0.174070   \n",
       "weights_1_std       -0.065431      -0.056608        0.214593        -0.094564   \n",
       "weights_1_mean      -0.027797      -0.170514       -0.035847        -0.176299   \n",
       "bias_a_1_std        -0.042104      -0.122439        0.070481         0.027551   \n",
       "bias_a_1_mean        0.138135      -0.228181       -0.051063        -0.121881   \n",
       "bias_q_1_std        -0.122739       0.059329       -0.110643         0.020948   \n",
       "bias_q_1_mean       -0.102281      -0.024629       -0.002822         0.004428   \n",
       "lambda_a_1_std       0.000276       0.022682       -0.056320        -0.011231   \n",
       "lambda_a_1_mean     -0.029704      -0.020220        0.181368        -0.130840   \n",
       "lambda_q_1_std       0.087686       0.035043       -0.001780        -0.125542   \n",
       "lambda_q_1_mean     -0.190043       0.052036        0.054765         0.159852   \n",
       "weights_2_std       -0.030425      -0.090973        0.163685        -0.014423   \n",
       "weights_2_mean      -0.000025       0.016356       -0.085326        -0.025535   \n",
       "bias_a_2_std              NaN            NaN             NaN              NaN   \n",
       "bias_a_2_mean        0.225573       0.055988       -0.022818         0.093718   \n",
       "bias_q_2_std              NaN            NaN             NaN              NaN   \n",
       "bias_q_2_mean       -0.025461      -0.125217        0.205679         0.089134   \n",
       "lambda_a_2_std            NaN            NaN             NaN              NaN   \n",
       "lambda_a_2_mean      0.092946      -0.044334       -0.006960         0.147497   \n",
       "lambda_q_2_std            NaN            NaN             NaN              NaN   \n",
       "lambda_q_2_mean      0.137200      -0.045811        0.083157        -0.049270   \n",
       "acc                 -0.201416      -0.059538        0.058536        -0.114971   \n",
       "\n",
       "                 lambda_q_0_std  lambda_q_0_mean  ...  weights_2_mean  \\\n",
       "weights_0_std         -0.129002         0.028137  ...        0.181063   \n",
       "weights_0_mean         0.208271        -0.104822  ...        0.050459   \n",
       "bias_a_0_std           0.006197        -0.081942  ...        0.087302   \n",
       "bias_a_0_mean          0.062822         0.077027  ...       -0.103480   \n",
       "bias_q_0_std          -0.152684         0.010482  ...       -0.000025   \n",
       "bias_q_0_mean         -0.156005         0.137075  ...        0.016356   \n",
       "lambda_a_0_std        -0.075614        -0.019988  ...       -0.085326   \n",
       "lambda_a_0_mean       -0.061615         0.174070  ...       -0.025535   \n",
       "lambda_q_0_std         1.000000        -0.189590  ...       -0.029704   \n",
       "lambda_q_0_mean       -0.189590         1.000000  ...        0.153547   \n",
       "weights_1_std         -0.072109        -0.030579  ...        0.120011   \n",
       "weights_1_mean        -0.025745        -0.006747  ...       -0.035766   \n",
       "bias_a_1_std          -0.139596        -0.065653  ...       -0.147856   \n",
       "bias_a_1_mean         -0.092153        -0.123373  ...       -0.084097   \n",
       "bias_q_1_std           0.095459         0.094257  ...       -0.060860   \n",
       "bias_q_1_mean          0.109019        -0.142762  ...       -0.085379   \n",
       "lambda_a_1_std        -0.076679        -0.046653  ...        0.036385   \n",
       "lambda_a_1_mean        0.066390        -0.005575  ...        0.056891   \n",
       "lambda_q_1_std         0.007183         0.001229  ...        0.046801   \n",
       "lambda_q_1_mean       -0.031194        -0.035856  ...        0.072599   \n",
       "weights_2_std         -0.084969        -0.067049  ...        0.078998   \n",
       "weights_2_mean        -0.029704         0.153547  ...        1.000000   \n",
       "bias_a_2_std                NaN              NaN  ...             NaN   \n",
       "bias_a_2_mean         -0.066946        -0.144672  ...       -0.024986   \n",
       "bias_q_2_std                NaN              NaN  ...             NaN   \n",
       "bias_q_2_mean          0.092247         0.054873  ...        0.041150   \n",
       "lambda_a_2_std              NaN              NaN  ...             NaN   \n",
       "lambda_a_2_mean       -0.000550         0.119715  ...        0.090292   \n",
       "lambda_q_2_std              NaN              NaN  ...             NaN   \n",
       "lambda_q_2_mean       -0.025157         0.118793  ...        0.130883   \n",
       "acc                   -0.069697         0.036986  ...       -0.262512   \n",
       "\n",
       "                 bias_a_2_std  bias_a_2_mean  bias_q_2_std  bias_q_2_mean  \\\n",
       "weights_0_std             NaN       0.056790           NaN      -0.054415   \n",
       "weights_0_mean            NaN       0.089286           NaN      -0.016890   \n",
       "bias_a_0_std              NaN       0.215610           NaN       0.235449   \n",
       "bias_a_0_mean             NaN       0.026001           NaN       0.089935   \n",
       "bias_q_0_std              NaN       0.225573           NaN      -0.025461   \n",
       "bias_q_0_mean             NaN       0.055988           NaN      -0.125217   \n",
       "lambda_a_0_std            NaN      -0.022818           NaN       0.205679   \n",
       "lambda_a_0_mean           NaN       0.093718           NaN       0.089134   \n",
       "lambda_q_0_std            NaN      -0.066946           NaN       0.092247   \n",
       "lambda_q_0_mean           NaN      -0.144672           NaN       0.054873   \n",
       "weights_1_std             NaN       0.034457           NaN       0.006969   \n",
       "weights_1_mean            NaN      -0.031607           NaN      -0.073574   \n",
       "bias_a_1_std              NaN      -0.059285           NaN       0.011119   \n",
       "bias_a_1_mean             NaN      -0.044460           NaN      -0.274328   \n",
       "bias_q_1_std              NaN      -0.139881           NaN       0.262934   \n",
       "bias_q_1_mean             NaN       0.061354           NaN       0.095287   \n",
       "lambda_a_1_std            NaN      -0.031135           NaN       0.066375   \n",
       "lambda_a_1_mean           NaN      -0.089011           NaN       0.013266   \n",
       "lambda_q_1_std            NaN      -0.177440           NaN       0.014908   \n",
       "lambda_q_1_mean           NaN       0.086101           NaN       0.136061   \n",
       "weights_2_std             NaN      -0.077258           NaN      -0.074439   \n",
       "weights_2_mean            NaN      -0.024986           NaN       0.041150   \n",
       "bias_a_2_std              NaN            NaN           NaN            NaN   \n",
       "bias_a_2_mean             NaN       1.000000           NaN      -0.144278   \n",
       "bias_q_2_std              NaN            NaN           NaN            NaN   \n",
       "bias_q_2_mean             NaN      -0.144278           NaN       1.000000   \n",
       "lambda_a_2_std            NaN            NaN           NaN            NaN   \n",
       "lambda_a_2_mean           NaN      -0.044281           NaN       0.156316   \n",
       "lambda_q_2_std            NaN            NaN           NaN            NaN   \n",
       "lambda_q_2_mean           NaN       0.042442           NaN       0.245790   \n",
       "acc                       NaN      -0.166620           NaN      -0.038868   \n",
       "\n",
       "                 lambda_a_2_std  lambda_a_2_mean  lambda_q_2_std  \\\n",
       "weights_0_std               NaN        -0.025208             NaN   \n",
       "weights_0_mean              NaN        -0.119772             NaN   \n",
       "bias_a_0_std                NaN        -0.017394             NaN   \n",
       "bias_a_0_mean               NaN         0.046057             NaN   \n",
       "bias_q_0_std                NaN         0.092946             NaN   \n",
       "bias_q_0_mean               NaN        -0.044334             NaN   \n",
       "lambda_a_0_std              NaN        -0.006960             NaN   \n",
       "lambda_a_0_mean             NaN         0.147497             NaN   \n",
       "lambda_q_0_std              NaN        -0.000550             NaN   \n",
       "lambda_q_0_mean             NaN         0.119715             NaN   \n",
       "weights_1_std               NaN         0.143840             NaN   \n",
       "weights_1_mean              NaN        -0.161057             NaN   \n",
       "bias_a_1_std                NaN         0.204948             NaN   \n",
       "bias_a_1_mean               NaN        -0.028347             NaN   \n",
       "bias_q_1_std                NaN        -0.054389             NaN   \n",
       "bias_q_1_mean               NaN        -0.071535             NaN   \n",
       "lambda_a_1_std              NaN         0.005335             NaN   \n",
       "lambda_a_1_mean             NaN         0.017810             NaN   \n",
       "lambda_q_1_std              NaN        -0.075203             NaN   \n",
       "lambda_q_1_mean             NaN        -0.005688             NaN   \n",
       "weights_2_std               NaN        -0.093600             NaN   \n",
       "weights_2_mean              NaN         0.090292             NaN   \n",
       "bias_a_2_std                NaN              NaN             NaN   \n",
       "bias_a_2_mean               NaN        -0.044281             NaN   \n",
       "bias_q_2_std                NaN              NaN             NaN   \n",
       "bias_q_2_mean               NaN         0.156316             NaN   \n",
       "lambda_a_2_std              NaN              NaN             NaN   \n",
       "lambda_a_2_mean             NaN         1.000000             NaN   \n",
       "lambda_q_2_std              NaN              NaN             NaN   \n",
       "lambda_q_2_mean             NaN         0.093541             NaN   \n",
       "acc                         NaN        -0.032795             NaN   \n",
       "\n",
       "                 lambda_q_2_mean       acc  \n",
       "weights_0_std          -0.004155 -0.239098  \n",
       "weights_0_mean         -0.102091 -0.156055  \n",
       "bias_a_0_std            0.267248  0.100794  \n",
       "bias_a_0_mean           0.020092  0.099233  \n",
       "bias_q_0_std            0.137200 -0.201416  \n",
       "bias_q_0_mean          -0.045811 -0.059538  \n",
       "lambda_a_0_std          0.083157  0.058536  \n",
       "lambda_a_0_mean        -0.049270 -0.114971  \n",
       "lambda_q_0_std         -0.025157 -0.069697  \n",
       "lambda_q_0_mean         0.118793  0.036986  \n",
       "weights_1_std           0.132610  0.024576  \n",
       "weights_1_mean          0.095641  0.007035  \n",
       "bias_a_1_std           -0.120260  0.180203  \n",
       "bias_a_1_mean          -0.085115  0.000799  \n",
       "bias_q_1_std            0.001923  0.101017  \n",
       "bias_q_1_mean          -0.124848  0.001329  \n",
       "lambda_a_1_std         -0.145151 -0.068862  \n",
       "lambda_a_1_mean         0.016820  0.078422  \n",
       "lambda_q_1_std          0.001394 -0.144052  \n",
       "lambda_q_1_mean         0.005652  0.037356  \n",
       "weights_2_std          -0.085439 -0.158389  \n",
       "weights_2_mean          0.130883 -0.262512  \n",
       "bias_a_2_std                 NaN       NaN  \n",
       "bias_a_2_mean           0.042442 -0.166620  \n",
       "bias_q_2_std                 NaN       NaN  \n",
       "bias_q_2_mean           0.245790 -0.038868  \n",
       "lambda_a_2_std               NaN       NaN  \n",
       "lambda_a_2_mean         0.093541 -0.032795  \n",
       "lambda_q_2_std               NaN       NaN  \n",
       "lambda_q_2_mean         1.000000 -0.005260  \n",
       "acc                    -0.005260  1.000000  \n",
       "\n",
       "[31 rows x 31 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bayesian plot should be better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84306823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2786e4d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be15e8cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db52d0a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d80a3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
