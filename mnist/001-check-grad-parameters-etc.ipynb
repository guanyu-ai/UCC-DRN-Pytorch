{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import torch\n",
    "\n",
    "name = \"track-gradients\"\n",
    "mlflow.set_tracking_uri(\"/Users/tanguanyu/UCC-DRN-Pytorch/mnist/mlruns\")\n",
    "experiment_id = \"511211072178994368\"\n",
    "runs = mlflow.search_runs(experiment_names=[\"track-gradients\"], output_format=\"list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"../mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import DRNOnlyModel\n",
    "from hydra import compose, initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 11)\n",
      "(4, 10)\n"
     ]
    }
   ],
   "source": [
    "initial_params = {\n",
    "        \"hidden_q\": 10,\n",
    "        \"num_bins\": 11,\n",
    "        \"lr\": 0.0498,\n",
    "        \"num_layers\": 1,\n",
    "        \"num_nodes\": 10\n",
    "    }\n",
    "\n",
    "defaults = {\n",
    "                    \"num_bins\": {\n",
    "                        \"type\": \"int\",\n",
    "                        \"range\": [5,100],\n",
    "                        \"aliases\": [\n",
    "                            \"model.drn.num_bins\",\n",
    "                            \"args.num_bins\",\n",
    "                            \"model.kde_model.num_bins\"\n",
    "                        ]\n",
    "                    },\n",
    "                    \"lr\": {\n",
    "                        \"type\": \"float\",\n",
    "                        \"range\": [0.0001, 0.1],\n",
    "                        \"aliases\": [\"args.learning_rate\"]\n",
    "                    },\n",
    "                    \"hidden_q\": {\n",
    "                        \"type\": \"int\",\n",
    "                        \"range\": [4, 100],\n",
    "                        \"aliases\": [\"model.drn.hidden_q\"]\n",
    "                    },\n",
    "                    \"num_layers\": {\n",
    "                        \"type\": \"int\",\n",
    "                        \"range\": [1, 10],\n",
    "                        \"aliases\": [\"model.drn.num_layers\"]\n",
    "                    },\n",
    "                    \"num_nodes\": {\n",
    "                        \"type\": \"int\",\n",
    "                        \"range\": [1, 10],\n",
    "                        \"aliases\": [\"model.drn.num_nodes\"]\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "with initialize(version_base=None, config_path=\"../configs\"):\n",
    "    cfg = compose(config_name=\"train_drn\")\n",
    "for key, value in defaults.items():\n",
    "    v = initial_params[key]\n",
    "    for a in value[\"aliases\"]:\n",
    "        exec(f\"cfg.{a} = {v}\")\n",
    "model = DRNOnlyModel(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): DRN(in_features=10, in_bins=11, out_features=10, out_bins=10)\n",
       "  (1): DRN(in_features=10, in_bins=10, out_features=1, out_bins=4)\n",
       "  (2): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.drn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DRNOnlyModel(\n",
       "  (drn): Sequential(\n",
       "    (0): DRN(in_features=10, in_bins=11, out_features=10, out_bins=10)\n",
       "    (1): DRN(in_features=10, in_bins=10, out_features=1, out_bins=4)\n",
       "    (2): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir(\"../mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tanguanyu/UCC-DRN-Pytorch/mnist'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98d0cca708cc4f5ba40314aa134af4cd\n",
      "48ebf24973744164844891aa7584ff54_resume\n",
      "0.973\n",
      "W_max: 17.22736930847168\n",
      "W_min: -8.929351806640625\n",
      "W_mean: 1.7172229290008545\n",
      "ba_max: 4.961871147155762\n",
      "ba_min: 1.6309356689453125\n",
      "ba_mean: 3.4531285762786865\n",
      "bq_max: 2.393209218978882\n",
      "bq_min: -0.4197807312011719\n",
      "bq_mean: 0.7888431549072266\n",
      "lama_max: 0.8599966764450073\n",
      "lama_min: 0.07577153295278549\n",
      "lama_mean: 0.38784635066986084\n",
      "lamq_max: 0.3350653052330017\n",
      "lamq_min: -1.408508539199829\n",
      "lamq_mean: -0.6045825481414795\n",
      "48ebf24973744164844891aa7584ff54\n",
      "4d2f6b34d5f14599a6569c6f43b44037_resume\n",
      "0.9735\n",
      "W_max: 15.587149620056152\n",
      "W_min: -8.233423233032227\n",
      "W_mean: 1.4915902614593506\n",
      "ba_max: 4.322299480438232\n",
      "ba_min: 1.219214916229248\n",
      "ba_mean: 2.915407419204712\n",
      "bq_max: 2.2859647274017334\n",
      "bq_min: -0.44844210147857666\n",
      "bq_mean: 0.7488437294960022\n",
      "lama_max: 0.8612028360366821\n",
      "lama_min: 0.0786328986287117\n",
      "lama_mean: 0.3851850926876068\n",
      "lamq_max: 0.3438963294029236\n",
      "lamq_min: -1.3729379177093506\n",
      "lamq_mean: -0.5688416361808777\n",
      "12b7ddc6958a41abac57c19cd880ddbc\n",
      "orderly-elk-390\n",
      "0.94675\n",
      "W_max: 12.041666984558105\n",
      "W_min: -7.523175239562988\n",
      "W_mean: 1.6702762842178345\n",
      "ba_max: -0.1727411448955536\n",
      "ba_min: -2.3647069931030273\n",
      "ba_mean: -1.4866600036621094\n",
      "bq_max: 0.367230087518692\n",
      "bq_min: -1.6723514795303345\n",
      "bq_mean: -0.904609203338623\n",
      "lama_max: 0.9209178686141968\n",
      "lama_min: 0.13127098977565765\n",
      "lama_mean: 0.47768935561180115\n",
      "lamq_max: 2.0385937690734863\n",
      "lamq_min: 0.290100634098053\n",
      "lamq_mean: 1.155246376991272\n",
      "439ed7c180e645bab036bb4c00bcafcd\n",
      "overjoyed-dolphin-1\n",
      "0.95325\n",
      "W_max: 36.7330436706543\n",
      "W_min: -20.028785705566406\n",
      "W_mean: 7.175740718841553\n",
      "ba_max: 0.2447361946105957\n",
      "ba_min: -9.691357612609863\n",
      "ba_mean: -2.6093244552612305\n",
      "bq_max: 2.400628089904785\n",
      "bq_min: -0.23827870190143585\n",
      "bq_mean: 0.8510866165161133\n",
      "lama_max: 0.9450197219848633\n",
      "lama_min: 0.2527538239955902\n",
      "lama_mean: 0.6081811785697937\n",
      "lamq_max: 1.1159155368804932\n",
      "lamq_min: -1.2198046445846558\n",
      "lamq_mean: -0.24683606624603271\n",
      "4d2f6b34d5f14599a6569c6f43b44037\n",
      "luminous-perch-450\n",
      "0.96425\n",
      "W_max: 12.701089859008789\n",
      "W_min: -7.319586753845215\n",
      "W_mean: 1.1378389596939087\n",
      "ba_max: 3.132762908935547\n",
      "ba_min: 0.4643592834472656\n",
      "ba_mean: 1.9048305749893188\n",
      "bq_max: 2.1540956497192383\n",
      "bq_min: -0.4443497657775879\n",
      "bq_mean: 0.6626253128051758\n",
      "lama_max: 0.8583049774169922\n",
      "lama_min: 0.07996997982263565\n",
      "lama_mean: 0.37975189089775085\n",
      "lamq_max: 0.45845624804496765\n",
      "lamq_min: -1.2871010303497314\n",
      "lamq_mean: -0.49263352155685425\n",
      "db4adb552769484283b2c1fac28c7035\n",
      "lr-0.0005\n",
      "0.956\n",
      "W_max: 21.11465072631836\n",
      "W_min: -11.486035346984863\n",
      "W_mean: 3.7522213459014893\n",
      "ba_max: 7.485513210296631\n",
      "ba_min: -0.9232819676399231\n",
      "ba_mean: 3.634277582168579\n",
      "bq_max: 0.9096791744232178\n",
      "bq_min: -2.02286696434021\n",
      "bq_mean: -0.8775191903114319\n",
      "lama_max: 0.8299265503883362\n",
      "lama_min: 0.2543773353099823\n",
      "lama_mean: 0.48720237612724304\n",
      "lamq_max: 2.7909462451934814\n",
      "lamq_min: -0.06419721990823746\n",
      "lamq_mean: 1.2304611206054688\n",
      "[Errno 2] No such file or directory: 'mlruns/189454739472380536/b83683db887747e3aa416a74001f355a/metrics/eval_ucc_acc'\n",
      "[Errno 2] No such file or directory: 'mlruns/189454739472380536/4af9ea69d0d842628e7b5a19b53edfb0/metrics/eval_ucc_acc'\n",
      "79f73b9140ff4a0ea5b8b6a668cc85d1\n",
      "fun-shark-828\n",
      "0.961\n",
      "W_max: 21.11465072631836\n",
      "W_min: -11.486035346984863\n",
      "W_mean: 3.7522213459014893\n",
      "ba_max: 7.485513210296631\n",
      "ba_min: -0.9232819676399231\n",
      "ba_mean: 3.634277582168579\n",
      "bq_max: 0.9096791744232178\n",
      "bq_min: -2.02286696434021\n",
      "bq_mean: -0.8775191903114319\n",
      "lama_max: 0.8299265503883362\n",
      "lama_min: 0.2543773353099823\n",
      "lama_mean: 0.48720237612724304\n",
      "lamq_max: 2.7909462451934814\n",
      "lamq_min: -0.06419721990823746\n",
      "lamq_mean: 1.2304611206054688\n",
      "b76e52db991c4b90a51eb9b8da9fc6ab\n",
      "clean-shoat-943\n",
      "0.95375\n",
      "W_max: 24.18505859375\n",
      "W_min: -11.637207984924316\n",
      "W_mean: 6.22925329208374\n",
      "ba_max: -1.3597970008850098\n",
      "ba_min: -9.108283042907715\n",
      "ba_mean: -3.5385210514068604\n",
      "bq_max: -0.7941178679466248\n",
      "bq_min: -2.499115228652954\n",
      "bq_mean: -1.5260504484176636\n",
      "lama_max: 0.9877815246582031\n",
      "lama_min: 0.2708912193775177\n",
      "lama_mean: 0.6154770255088806\n",
      "lamq_max: 2.4413716793060303\n",
      "lamq_min: 0.4150831401348114\n",
      "lamq_mean: 1.541089415550232\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import mlflow\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "experiment_name = \"ucc-drn-goated-init\"\n",
    "mlflow.set_tracking_uri(\"/Users/tanguanyu/UCC-DRN-Pytorch/mnist/mlruns\")\n",
    "runs = mlflow.search_runs(experiment_names=[experiment_name,], output_format=\"list\")\n",
    "experiment = mlflow.set_experiment(experiment_name=experiment_name)\n",
    "experiment_id = experiment.experiment_id\n",
    "run_ids = [\n",
    "    run.info.run_id for run in runs\n",
    "]\n",
    "run_names = [\n",
    "    run.info.run_name for run in runs\n",
    "]\n",
    "for id, name in zip(run_ids, run_names):\n",
    "    prefix = f\"mlruns/{experiment_id}/{id}\"\n",
    "    try:\n",
    "        with open(f\"{prefix}/metrics/eval_ucc_acc\") as file:\n",
    "            eval_ucc = file.readlines()\n",
    "        final_eval_acc = float(eval_ucc[-1].split(\" \")[1])\n",
    "        if final_eval_acc>0.9:\n",
    "            \n",
    "\n",
    "            # init_model = torch.load(f\"{prefix}/artifacts/init_model/data/model.pth\", weights_only=False)\n",
    "            trained_model = torch.load(f\"{prefix}/artifacts/best_model/data/model.pth\", weights_only=False)\n",
    "            drn_model = trained_model.ucc_classifier\n",
    "            print(id)\n",
    "            print(name)\n",
    "            print(final_eval_acc)\n",
    "            # print(\"\".join(eval_ucc))\n",
    "            param_dict = defaultdict(list)\n",
    "            n_list = [\"W\", \"bq\", \"ba\", \"lama\", \"lamq\"]\n",
    "            for name, param in drn_model.named_parameters():\n",
    "                for n in n_list:\n",
    "                    if n in name:\n",
    "                        param_dict[f\"{n}_max\"].append(param.max().detach().cpu().numpy())\n",
    "                        param_dict[f\"{n}_min\"].append(param.min().detach().cpu().numpy())\n",
    "                        param_dict[f\"{n}_mean\"].append(param.mean().detach().cpu().numpy())\n",
    "            for p, value in param_dict.items():\n",
    "                print(f\"{p}: {np.mean(value)}\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['peaceful-kite-300',\n",
       " 'orderly-elk-390',\n",
       " 'clumsy-flea-932',\n",
       " 'bald-goose-275',\n",
       " 'c7c6e956dc2c4b93b6079c9311bbbe79_resume_2',\n",
       " 'f47d86fa34ab4526b75c4d8525baa366_resume_2',\n",
       " 'wise-smelt-451',\n",
       " 'stylish-bee-110',\n",
       " 'nebulous-shad-766',\n",
       " 'upset-loon-97',\n",
       " 'ccefe815ccf9454b84e9bd69ae0d9ca2_resume_2',\n",
       " 'ccefe815ccf9454b84e9bd69ae0d9ca2_resume',\n",
       " 'ccefe815ccf9454b84e9bd69ae0d9ca2_resume',\n",
       " 'ccefe815ccf9454b84e9bd69ae0d9ca2_resume',\n",
       " '439ed7c180e645bab036bb4c00bcafcd_resume',\n",
       " 'overjoyed-dolphin-1',\n",
       " 'luxuriant-donkey-158',\n",
       " 'treasured-tern-816',\n",
       " '4d2f6b34d5f14599a6569c6f43b44037_resume',\n",
       " 'luminous-perch-450',\n",
       " 'lr-0.0005',\n",
       " 'lr-0.0005',\n",
       " 'lr-0.0005',\n",
       " 'lr-0.0005',\n",
       " 'enchanting-rat-536',\n",
       " 'hilarious-swan-333',\n",
       " 'selective-goose-567',\n",
       " 'marvelous-boar-372',\n",
       " 'bittersweet-cat-414',\n",
       " 'capricious-fox-694',\n",
       " 'ae9704aec54d48729f10dcb726d0125f_resume',\n",
       " '79f73b9140ff4a0ea5b8b6a668cc85d1_resume',\n",
       " '79f73b9140ff4a0ea5b8b6a668cc85d1_resume',\n",
       " 'bittersweet-pig-324',\n",
       " 'wise-rook-554',\n",
       " 'placid-lynx-650',\n",
       " 'capricious-elk-209',\n",
       " 'dapper-bird-23',\n",
       " 'awesome-snake-338',\n",
       " 'secretive-wren-16',\n",
       " 'stylish-rook-883',\n",
       " 'fun-shark-828',\n",
       " 'fearless-lark-906',\n",
       " 'clean-shoat-943',\n",
       " 'illustrious-jay-799',\n",
       " 'mysterious-tern-744']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = \"48ebf24973744164844891aa7584ff54\"\n",
    "trained_model = torch.load(f\"mlruns/{experiment_id}/{run_id}/artifacts/best_model/data/model.pth\", weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([50000, 1, 28, 28])\n",
      "50000 train samples\n",
      "10000 val samples\n",
      "tensor(0.3105)\n",
      "tensor(0.1325)\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from dataset import MnistDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "eval_dataset = MnistDataset(\n",
    "    num_instances= 32,\n",
    "    num_samples_per_class = 5,\n",
    "    digit_arr = list(range(0,10)),\n",
    "    ucc_start= 1,\n",
    "    ucc_end= 4,\n",
    "    mode= \"test\",\n",
    ")\n",
    "eval_dataloader = DataLoader(eval_dataset, 32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 32, 1, 28, 28])\n",
      "torch.return_types.max(\n",
      "values=tensor([1.0000, 0.9899, 0.9494, 0.9989, 0.9999, 0.9876, 0.9553, 0.9988, 1.0000,\n",
      "        0.9919, 0.9987, 0.9964, 0.9991, 0.9896, 0.6986, 0.9981, 1.0000, 0.9911,\n",
      "        0.9813, 0.9988, 1.0000, 0.9915, 0.9570, 0.9988, 1.0000, 0.9874, 0.9723,\n",
      "        0.9938, 0.8732, 0.9916, 0.9988, 0.9984], device='mps:0',\n",
      "       grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 3, 3, 0, 1, 3, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 1, 1, 3, 3], device='mps:0'))\n",
      "tensor([0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3,\n",
      "        0, 1, 2, 3, 0, 1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\")\n",
    "for batch_samples, batch_labels in eval_dataloader:\n",
    "    print(batch_samples.shape)\n",
    "    batch_samples = batch_samples.to(device)\n",
    "    output = trained_model(batch_samples)\n",
    "    print(torch.max(output, dim=1))\n",
    "    print(batch_labels)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "mean = 0.1325\n",
    "std = 0.3105\n",
    "for image in batch_samples[10]:\n",
    "    print(image.shape)\n",
    "    a = Image.fromarray((image.to(\"cpu\").numpy().squeeze()*std+mean)*255)\n",
    "    a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
