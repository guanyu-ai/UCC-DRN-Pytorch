{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34e7acab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'76d45e8fdc07489fbd155c3ac5142008'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row[\"run_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23c4ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to use good initialized model and use original\n",
    "import os\n",
    "from hydra import compose, initialize\n",
    "import omegaconf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import mlflow\n",
    "import optuna\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from omegaconf.omegaconf import OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dataset import MnistDataset\n",
    "from utils import get_or_create_experiment, parse_experiment_runs_to_optuna_study\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "runs = mlflow.search_runs(experiment_ids=[\"823019999500194436\"], filter_string=\"metrics.eval_ucc_acc>0.25\").sort_values(\"metrics.train_ucc_acc\", ascending=False)\n",
    "row = runs.iloc[1]\n",
    "cfg = OmegaConf.load(os.path.join(\"mlruns\", row[\"experiment_id\"], \"e7bd69f493604ce99a968daae16c9822\", \"artifacts/config.yaml\"))\n",
    "cfg.model.alpha = 0.5\n",
    "init_path = os.path.join(\"mlruns\", row[\"experiment_id\"], \"e7bd69f493604ce99a968daae16c9822\", \"artifacts\", \"init_model\", \"data\", \"model.pth\")\n",
    "model_path = os.path.join(\"mlruns\", row[\"experiment_id\"], \"e7bd69f493604ce99a968daae16c9822\", \"artifacts\", \"best_model.pth\", \"data\", \"model.pth\")\n",
    "best_init_model = torch.load(init_path, weights_only=False)\n",
    "model = torch.load(model_path, weights_only=False)\n",
    "model.alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dee658b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'args': {'batch_size': 20, 'dataset': 'mnist', 'learning_rate': 0.005, 'model_dir': 'saved_models/', 'model_name': 'mnist_ucc_drn', 'num_bins': 11, 'num_features': 10, 'num_instances': 32, 'num_samples_per_class': 5, 'num_workers': 4, 'save_interval': 1000, 'seed': 22, 'train_num_steps': 100000, 'ucc_end': 4, 'ucc_start': 1, 'val_num_steps': 200}, 'model': {'decoder': {'block1_num_layer': 1, 'block1_output_channel': 64, 'block2_num_layer': 1, 'block2_output_channel': 32, 'block3_num_layer': 1, 'block3_output_channel': 16, 'linear_size': 6272, 'output_channel': 1, 'reshape_size': [7, 7, 128]}, 'drn': {'hidden_q': 100, 'init_method': 'xavier_uniform', 'num_bins': 11, 'num_layers': 2, 'num_nodes': 9, 'output_bins': 4, 'output_nodes': 1}, 'encoder': {'block1_num_layer': 1, 'block1_output_channel': 321, 'block2_num_layer': 1, 'block2_output_channel': 64, 'block3_num_layer': 1, 'block3_output_channel': 128, 'conv_input_channel': 1, 'conv_output_channel': 16, 'flatten_size': 6272, 'num_features': 10}, 'input_shape': [28, 28, 1], 'kde_model': {'num_bins': 11, 'sigma': 0.1}, 'loss': {'alpha': -1}, 'num_channels': 1, 'ucc_classifier': 'None', 'alpha': 0.5}}\n",
      "x_train shape: torch.Size([50000, 1, 28, 28])\n",
      "50000 train samples\n",
      "10000 val samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/31 15:23:05 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: torch.Size([50000, 1, 28, 28])\n",
      "50000 train samples\n",
      "10000 val samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/31 15:23:26 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/31 15:23:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/05/31 15:23:26 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/31 15:23:33 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/31 15:23:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "  1%|          | 999/100000 [09:33<15:21:15,  1.79it/s]2025/05/31 15:34:14 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1000,eval_ae_loss: 0.11678,eval_ucc_loss: 0.7763,eval_ucc_acc: 0.99975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/31 15:34:23 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/31 15:34:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "  2%|▏         | 1999/100000 [20:20<15:01:47,  1.81it/s] 2025/05/31 15:45:00 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 2000,eval_ae_loss: 0.11312,eval_ucc_loss: 0.77051,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/31 15:45:08 WARNING mlflow.utils.requirements_utils: Found torch version (2.5.1+cu124) contains a local version label (+cu124). MLflow logged a pip requirement for this package as 'torch==2.5.1' without the local version label to make it installable from PyPI. To specify pip requirements containing local version labels, please use `conda_env` or `pip_requirements`.\n",
      "2025/05/31 15:45:08 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "  3%|▎         | 3000/100000 [32:04<542:40:59, 20.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 3000,eval_ae_loss: 0.11155,eval_ucc_loss: 0.76605,eval_ucc_acc: 0.99975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4000/100000 [42:32<539:21:23, 20.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 4000,eval_ae_loss: 0.11115,eval_ucc_loss: 0.76702,eval_ucc_acc: 0.9985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5000/100000 [53:01<532:49:44, 20.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 5000,eval_ae_loss: 0.10646,eval_ucc_loss: 0.7607,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6000/100000 [1:03:30<528:20:43, 20.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 6000,eval_ae_loss: 0.10563,eval_ucc_loss: 0.75862,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7000/100000 [1:14:07<524:05:53, 20.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 7000,eval_ae_loss: 0.10209,eval_ucc_loss: 0.75737,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8000/100000 [1:25:01<518:08:16, 20.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 8000,eval_ae_loss: 0.10112,eval_ucc_loss: 0.75616,eval_ucc_acc: 0.99975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9000/100000 [1:35:38<512:40:13, 20.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 9000,eval_ae_loss: 0.10044,eval_ucc_loss: 0.75473,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10000/100000 [1:46:09<507:23:51, 20.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 10000,eval_ae_loss: 0.10213,eval_ucc_loss: 0.75442,eval_ucc_acc: 0.99975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11000/100000 [1:56:45<502:59:54, 20.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 11000,eval_ae_loss: 0.10019,eval_ucc_loss: 0.75351,eval_ucc_acc: 0.99975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12000/100000 [2:07:28<495:45:12, 20.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 12000,eval_ae_loss: 0.10124,eval_ucc_loss: 0.75276,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13000/100000 [2:18:07<493:43:12, 20.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 13000,eval_ae_loss: 0.10167,eval_ucc_loss: 0.75236,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14000/100000 [2:28:54<476:49:11, 19.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 14000,eval_ae_loss: 0.09864,eval_ucc_loss: 0.75172,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15000/100000 [2:39:09<468:51:48, 19.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 15000,eval_ae_loss: 0.09824,eval_ucc_loss: 0.75114,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16000/100000 [2:49:20<466:49:18, 20.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 16000,eval_ae_loss: 0.09771,eval_ucc_loss: 0.75097,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17000/100000 [2:59:40<463:41:21, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 17000,eval_ae_loss: 0.09494,eval_ucc_loss: 0.75052,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18000/100000 [3:10:28<494:04:47, 21.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 18000,eval_ae_loss: 0.10039,eval_ucc_loss: 0.75192,eval_ucc_acc: 0.99975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19000/100000 [3:21:46<465:59:35, 20.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 19000,eval_ae_loss: 0.09649,eval_ucc_loss: 0.74983,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20000/100000 [3:32:21<442:27:29, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 20000,eval_ae_loss: 0.09501,eval_ucc_loss: 0.74963,eval_ucc_acc: 0.99975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21000/100000 [3:42:51<439:58:15, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 21000,eval_ae_loss: 0.09496,eval_ucc_loss: 0.74976,eval_ucc_acc: 0.99975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22000/100000 [3:53:23<433:44:27, 20.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 22000,eval_ae_loss: 0.09535,eval_ucc_loss: 0.74928,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23000/100000 [4:03:54<428:55:15, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 23000,eval_ae_loss: 0.0955,eval_ucc_loss: 0.74929,eval_ucc_acc: 0.99975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24000/100000 [4:14:30<424:05:53, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 24000,eval_ae_loss: 0.09617,eval_ucc_loss: 0.74865,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25000/100000 [4:25:22<417:47:55, 20.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 25000,eval_ae_loss: 0.09527,eval_ucc_loss: 0.7487,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26000/100000 [4:36:00<411:48:11, 20.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 26000,eval_ae_loss: 0.09451,eval_ucc_loss: 0.74904,eval_ucc_acc: 0.9995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27000/100000 [4:46:34<407:12:49, 20.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 27000,eval_ae_loss: 0.09377,eval_ucc_loss: 0.74847,eval_ucc_acc: 0.99975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28000/100000 [4:57:09<403:22:10, 20.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 28000,eval_ae_loss: 0.09337,eval_ucc_loss: 0.74812,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29000/100000 [5:07:49<397:00:30, 20.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 29000,eval_ae_loss: 0.09375,eval_ucc_loss: 0.74821,eval_ucc_acc: 0.99975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30000/100000 [5:18:30<403:45:54, 20.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 30000,eval_ae_loss: 0.09464,eval_ucc_loss: 0.74783,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31000/100000 [5:29:24<385:06:11, 20.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 31000,eval_ae_loss: 0.09405,eval_ucc_loss: 0.74812,eval_ucc_acc: 0.99925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32000/100000 [5:40:07<379:54:24, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 32000,eval_ae_loss: 0.09522,eval_ucc_loss: 0.74774,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33000/100000 [5:50:48<375:51:05, 20.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 33000,eval_ae_loss: 0.09353,eval_ucc_loss: 0.74754,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34000/100000 [6:01:40<388:29:52, 21.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 34000,eval_ae_loss: 0.09401,eval_ucc_loss: 0.74745,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35000/100000 [6:12:34<363:25:33, 20.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 35000,eval_ae_loss: 0.09469,eval_ucc_loss: 0.74751,eval_ucc_acc: 0.99975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36000/100000 [6:23:39<358:22:17, 20.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 36000,eval_ae_loss: 0.09389,eval_ucc_loss: 0.74733,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37000/100000 [6:34:31<353:58:04, 20.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 37000,eval_ae_loss: 0.09471,eval_ucc_loss: 0.74711,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38000/100000 [6:45:16<345:43:43, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 38000,eval_ae_loss: 0.0936,eval_ucc_loss: 0.74723,eval_ucc_acc: 0.99975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39000/100000 [6:56:05<343:51:01, 20.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 39000,eval_ae_loss: 0.09368,eval_ucc_loss: 0.74693,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40000/100000 [7:06:55<335:55:29, 20.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 40000,eval_ae_loss: 0.09477,eval_ucc_loss: 0.74684,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41000/100000 [7:17:59<333:13:57, 20.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 41000,eval_ae_loss: 0.09339,eval_ucc_loss: 0.74686,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42000/100000 [7:30:51<372:33:44, 23.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 42000,eval_ae_loss: 0.09527,eval_ucc_loss: 0.74668,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43000/100000 [7:43:28<350:32:38, 22.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 43000,eval_ae_loss: 0.1005,eval_ucc_loss: 0.74698,eval_ucc_acc: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 43731/100000 [7:52:19<10:07:44,  1.54it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 239\u001b[0m\n\u001b[0;32m    237\u001b[0m train_loader, val_loader \u001b[38;5;241m=\u001b[39m init_dataloader(args)\n\u001b[0;32m    238\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mpytorch\u001b[38;5;241m.\u001b[39mlog_model(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 239\u001b[0m best_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 128\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(args, model, optimizer, lr_scheduler, train_loader, val_loader, device)\u001b[0m\n\u001b[0;32m    119\u001b[0m ucc_logits, reconstruction\u001b[38;5;241m=\u001b[39m model(batch_samples, batch_labels)\n\u001b[0;32m    120\u001b[0m ce_loss , ae_loss, loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcompute_loss(\n\u001b[0;32m    121\u001b[0m     inputs\u001b[38;5;241m=\u001b[39mbatch_samples,\n\u001b[0;32m    122\u001b[0m     labels\u001b[38;5;241m=\u001b[39mbatch_labels,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m     return_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    126\u001b[0m )\n\u001b[1;32m--> 128\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    132\u001b[0m step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32md:\\UCC-DRN-Pytorch\\.venv\\lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\UCC-DRN-Pytorch\\.venv\\lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\UCC-DRN-Pytorch\\.venv\\lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def init_dataloader(args):\n",
    "    # assert args.dataset in [\n",
    "    #     \"mnist\",\n",
    "    #     \"camelyon\",\n",
    "    # ], \"Mode should be either mnist or camelyon\"\n",
    "    # if args.dataset == \"mnist\":\n",
    "    train_dataset_len = args.train_num_steps * args.batch_size\n",
    "    train_dataset = MnistDataset(\n",
    "        mode=\"train\",\n",
    "        num_instances=args.num_instances,\n",
    "        num_samples_per_class=args.num_samples_per_class,\n",
    "        digit_arr=list(range(args.ucc_end-args.ucc_start+1)),\n",
    "        ucc_start=args.ucc_start,\n",
    "        ucc_end=args.ucc_end,\n",
    "        length=train_dataset_len,\n",
    "    )\n",
    "    val_dataset_len = args.val_num_steps * args.batch_size\n",
    "    val_dataset = MnistDataset(\n",
    "        mode=\"val\",\n",
    "        num_instances=args.num_instances,\n",
    "        num_samples_per_class=args.num_samples_per_class,\n",
    "        digit_arr=list(range(args.ucc_end-args.ucc_start+1)),\n",
    "        ucc_start=args.ucc_start,\n",
    "        ucc_end=args.ucc_end,\n",
    "        length=val_dataset_len,\n",
    "    )\n",
    "    # create dataloader\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        shuffle=False,\n",
    "    )\n",
    "    return train_loader, val_loader\n",
    "\n",
    "def evaluate(model, val_loader, device, ae_mode, clf_mode) -> dict:\n",
    "    model.eval()\n",
    "    val_ae_loss_list = []\n",
    "    val_ucc_loss_list = []\n",
    "    val_acc_list = []\n",
    "    rec_criterion = nn.MSELoss()\n",
    "    with torch.no_grad():\n",
    "        for batch_samples, batch_labels in val_loader:\n",
    "            batch_samples = batch_samples.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "            if ae_mode:\n",
    "                batch_size, num_instances, num_channel, patch_size, _ = batch_samples.shape\n",
    "                x = batch_samples.view(-1, num_channel,\n",
    "                                       batch_samples.shape[-2], batch_samples.shape[-1])\n",
    "                features = model.encoder(x)\n",
    "                reconstruction = model.decoder(features)\n",
    "                reconstruction = reconstruction.view(batch_size, num_instances,\n",
    "                                    1, patch_size, patch_size)\n",
    "                ae_loss = rec_criterion(batch_samples, reconstruction)\n",
    "                val_ae_loss_list.append(ae_loss.item())\n",
    "\n",
    "            if clf_mode:\n",
    "                ucc_logits, _ = model(batch_samples)\n",
    "                ucc_val_loss = F.cross_entropy(ucc_logits, batch_labels)\n",
    "                # acculate accuracy\n",
    "                _, ucc_predicts = torch.max(ucc_logits, dim=1)\n",
    "                acc = torch.sum(\n",
    "                    ucc_predicts == batch_labels).item() / len(batch_labels)\n",
    "                val_acc_list.append(acc)\n",
    "                val_ucc_loss_list.append(ucc_val_loss.item())\n",
    "\n",
    "        if ae_mode and clf_mode:\n",
    "            return {\n",
    "                \"eval_ae_loss\": np.round(np.mean(val_ae_loss_list), 5),\n",
    "                \"eval_ucc_loss\": np.round(np.mean(val_ucc_loss_list), 5),\n",
    "                \"eval_ucc_acc\": np.round(np.mean(val_acc_list), 5)\n",
    "            }\n",
    "        elif ae_mode:\n",
    "            return {\n",
    "                \"eval_ae_loss\": np.round(np.mean(val_ae_loss_list), 5),\n",
    "            }\n",
    "        elif clf_mode:\n",
    "            return {\n",
    "                \"eval_ucc_loss\": np.round(np.mean(val_ucc_loss_list), 5),\n",
    "                \"eval_ucc_acc\": np.round(np.mean(val_acc_list), 5)\n",
    "            }\n",
    "\n",
    "def train(args, model, optimizer, lr_scheduler, train_loader, val_loader, device):\n",
    "    print(\"training\")\n",
    "    # mlflow.pytorch.log_model(model, \"init_model\")\n",
    "    # output_dir = hydra.core.hydra_config.HydraConfig.get().runtime.output_dir\n",
    "    model.train()\n",
    "    step = 0\n",
    "    best_eval_acc = 0\n",
    "    patience = 2\n",
    "    # ae_steps = 500\n",
    "\n",
    "    rec_criterion = nn.MSELoss()\n",
    "    if step == 0:\n",
    "        mlflow.pytorch.log_model(\n",
    "            model,\n",
    "            \"best_model.pth\"\n",
    "        )\n",
    "    for batch_samples, batch_labels in tqdm(train_loader):\n",
    "        batch_samples = batch_samples.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # ucc_logits, reconstruction = model(batch_samples, batch_labels)\n",
    "    \n",
    "    \n",
    "        ucc_logits, reconstruction= model(batch_samples, batch_labels)\n",
    "        ce_loss , ae_loss, loss = model.compute_loss(\n",
    "            inputs=batch_samples,\n",
    "            labels=batch_labels,\n",
    "            output=ucc_logits,\n",
    "            reconstruction=reconstruction,\n",
    "            return_losses = True\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            with torch.no_grad():\n",
    "                metric_dict = {}\n",
    "                grad_log = {name: torch.mean(param.grad).cpu().item(\n",
    "                ) for name, param in model.named_parameters() if isinstance(param.grad, torch.Tensor)}\n",
    "                mlflow.log_metrics(grad_log, step=step)\n",
    "                metric_dict[\"train_ae_loss\"] = np.round(ae_loss.detach().item(), 5)\n",
    "                _, pred = torch.max(ucc_logits, dim=1)\n",
    "                accuracy = torch.sum(pred.flatten() == batch_labels.flatten())/len(batch_labels)\n",
    "                metric_dict[\"train_ucc_loss\"] = np.round(ce_loss.detach().item(), 5)\n",
    "                metric_dict[\"train_ucc_acc\"] = np.round(float(accuracy), 5)\n",
    "                metric_dict[\"loss\"] = np.round(float(loss), 5)\n",
    "            mlflow.log_metrics(metric_dict, step=step)\n",
    "\n",
    "        if step % args.save_interval == 0:\n",
    "            eval_metric_dict = evaluate(\n",
    "                model,\n",
    "                val_loader,\n",
    "                device,\n",
    "                ae_mode=True,\n",
    "                clf_mode=True)\n",
    "            print(f\"step: {step},\" + \",\".join([f\"{key}: {value}\"for key, value in eval_metric_dict.items()]))\n",
    "            mlflow.log_metrics(eval_metric_dict, step=step)\n",
    "            # early stop\n",
    "            eval_acc = eval_metric_dict[\"eval_ucc_acc\"]\n",
    "            if eval_acc > best_eval_acc:\n",
    "                # patience = 2\n",
    "                best_eval_acc = eval_acc\n",
    "                mlflow.pytorch.log_model(\n",
    "                    model,\n",
    "                    \"best_model.pth\"\n",
    "                )\n",
    "            # else:\n",
    "            #     patience -= 1\n",
    "\n",
    "            # if patience <= 0:\n",
    "            #     break\n",
    "            if step == 80000:\n",
    "                break\n",
    "            model.train()\n",
    "\n",
    "    print(\"Training finished!!!\")\n",
    "    return best_eval_acc\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"mlruns\")\n",
    "run_name = \"ucc-drn-multi-step-recreation-same-init\"\n",
    "experiment_id = get_or_create_experiment(experiment_name=run_name)\n",
    "mlflow.set_experiment(experiment_id=experiment_id)\n",
    "with mlflow.start_run(nested=True, run_name=\"melodic-conch-890\"):\n",
    "\n",
    "    defaults = {\n",
    "        # \"init_method\": {\n",
    "        #     \"type\": \"categorical\",\n",
    "        #     \"range\": [\"uniform\", \"normal\", \"xavier_uniform\", \"xavier_normal\", \"kaiming_uniform\", \"kaiming_normal\"],\n",
    "        #     \"aliases\": [\n",
    "        #         \"model.drn.init_method\",\n",
    "        #     ]\n",
    "        # },\n",
    "        # \"num_bins\": {\n",
    "        #     \"type\": \"int\",\n",
    "        #     \"value\": 10,\n",
    "        #     \"range\": [5, 100],\n",
    "        #     \"aliases\": [\n",
    "        #         \"model.drn.num_bins\",\n",
    "        #         \"args.num_bins\",\n",
    "        #         \"model.kde_model.num_bins\"\n",
    "        #     ]\n",
    "        # },\n",
    "        \"lr\": {\n",
    "            \"type\": \"float\",\n",
    "            \"value\": 0.005,\n",
    "            \"range\": [0.008, 0.08],\n",
    "            \"aliases\": [\"args.learning_rate\"]\n",
    "        },\n",
    "        \"hidden_q\": {\n",
    "            \"type\": \"int\",\n",
    "            \"value\": 100,\n",
    "            \"range\": [4, 100],\n",
    "            \"aliases\": [\"model.drn.hidden_q\"]\n",
    "        },\n",
    "        \"num_layers\": {\n",
    "            \"type\": \"int\",\n",
    "            \"value\": 2,\n",
    "            \"range\": [1, 10],\n",
    "            \"aliases\": [\"model.drn.num_layers\"]\n",
    "        },\n",
    "        \"num_nodes\": {\n",
    "            \"type\": \"int\",\n",
    "            \"value\": 9,\n",
    "            \"range\": [1, 10],\n",
    "            \"aliases\": [\"model.drn.num_nodes\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    print(cfg)\n",
    "    mlflow.log_dict(dict(OmegaConf.to_object(cfg)), \"config.yaml\")\n",
    "\n",
    "    args = cfg.args\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=0.001, amsgrad=True)\n",
    "    train_loader, val_loader = init_dataloader(args)\n",
    "    mlflow.pytorch.log_model(model, \"init_model\")\n",
    "    best_acc = train(args, model, optimizer, None,\n",
    "                     train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7e2961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da3c88a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcd4d2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 weights\n",
      "[[ 0.12929279 -0.24679643 -0.3951519  -0.50869083 -0.1545282  -0.50259244\n",
      "   0.34096634  0.53263193  0.4816404  -0.47664326]\n",
      " [-0.10936746  0.32023436  0.15579069  0.46153766  0.24118489 -0.05316174\n",
      "   0.1069783   0.5318013   0.48920268 -0.23420337]\n",
      " [ 0.1459015  -0.5443165  -0.02662891  0.4736374   0.05059469  0.44143683\n",
      "   0.2309137  -0.5014591  -0.1175445  -0.03031945]\n",
      " [-0.42587566 -0.17734405 -0.04971427  0.06673527 -0.23131001  0.10457581\n",
      "   0.01849186  0.43196142  0.21586502 -0.268082  ]\n",
      " [ 0.45593995 -0.33081645  0.00265354 -0.1670514   0.1638146   0.5280388\n",
      "  -0.03166616  0.10945356  0.35259664  0.12462896]\n",
      " [-0.5077368  -0.06593943 -0.3657821  -0.00541192 -0.4278472  -0.2834111\n",
      "  -0.48945418  0.5266476   0.0878678  -0.19442981]\n",
      " [-0.19350737  0.36867696 -0.03424609  0.16475844 -0.47798714  0.07769984\n",
      "  -0.02374071  0.36930096 -0.07794341  0.39444548]\n",
      " [-0.24032155  0.30128026  0.07513559 -0.36390638  0.5397268   0.2302916\n",
      "   0.53798884  0.24895728  0.55028635  0.23712188]\n",
      " [ 0.22981226 -0.14807326  0.33238935 -0.49312308  0.18492925 -0.46698916\n",
      "  -0.3214085  -0.09291223 -0.19730926  0.27282566]]\n",
      "0.55028635\n",
      "-0.5443165\n",
      "0.02648776\n",
      "0.32012227\n",
      "1 weights\n",
      "[[ 0.04234785  0.4723308  -0.20381686  0.13273442 -0.39313367  0.2761321\n",
      "   0.21291304  0.15086412 -0.19938979]\n",
      " [ 0.4771979  -0.26243237 -0.4597609  -0.47532007  0.20790762  0.31339127\n",
      "   0.45825028  0.12811834 -0.20058048]\n",
      " [-0.01071626 -0.13369396  0.4883585  -0.56765276  0.42052722  0.22639954\n",
      "  -0.08965296  0.44957256  0.14630109]\n",
      " [-0.01007402  0.16220719  0.2656715   0.21201062  0.43277395 -0.12422091\n",
      "  -0.08309826 -0.13984483 -0.28142196]\n",
      " [ 0.36326128 -0.09685552 -0.35985923 -0.24056143  0.36223465  0.31957275\n",
      "   0.06091905  0.21690464  0.1952151 ]\n",
      " [ 0.0161528  -0.15088129  0.3262943  -0.57607436  0.22436994  0.05653095\n",
      "  -0.15827927  0.46027184 -0.19557706]\n",
      " [-0.13605317  0.04960209 -0.31159085  0.05844182  0.22324163  0.10110861\n",
      "  -0.29488105  0.44717324 -0.05166268]\n",
      " [ 0.22786385  0.09989136 -0.04595351  0.00422841 -0.46571693 -0.32905614\n",
      "   0.15640968  0.34233153 -0.05149353]\n",
      " [-0.07356507  0.4218186   0.42341244  0.27128023  0.45104492 -0.17187148\n",
      "  -0.2791686  -0.5105906  -0.01083153]]\n",
      "0.4883585\n",
      "-0.57607436\n",
      "0.042101882\n",
      "0.28465572\n",
      "2 weights\n",
      "[[-0.24314266  0.41900098 -0.6498637   0.7684126   0.68759656  0.15268183\n",
      "  -0.22490579 -0.385188   -0.5815945 ]]\n",
      "0.7684126\n",
      "-0.6498637\n",
      "-0.0063336426\n",
      "0.503367\n"
     ]
    }
   ],
   "source": [
    "drn = best_init_model.ucc_classifier\n",
    "layers = list(drn.modules())[1:-1]\n",
    "for index, layer in enumerate(layers):\n",
    "    print(index, \"weights\")\n",
    "    print(layer.W.detach().cpu().numpy())\n",
    "    print(layer.W.detach().cpu().numpy().max())\n",
    "    print(layer.W.detach().cpu().numpy().min())\n",
    "    print(layer.W.detach().cpu().numpy().mean())\n",
    "    print(layer.W.detach().cpu().numpy().std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf94e18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
